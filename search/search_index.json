{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Atomist - How Teams Deliver Software Every serious business has its own development and delivery experience. Most of them aren\u2019t what we want. We want to spend our time and focus solving problems for the business, but to do that well, we need to enact our own blueprint for software delivery. So far, enterprises piece together pipeline tools, configured by a plethora of YAML or by hand in a GUI. For anything interesting, we resort to a Bash script, the lowest common denominator of programming. We enroll myriad chatbots to spam our channels. We write how-to wiki pages and distribute hand-me-down scripts. As our practices improve, older projects languish in prior standards. Meanwhile we shake our heads wistfully over the elegant flow of shiny new delivery tools \u2013 they will never fit our real-world environment. Atomist says, there is a better way. A world beyond pipelines, a world of little YAML and Bash, a world where we code our way to an appropriate delivery experience, with higher coding standards, up-to-date application suites, and continual improvement. And this way begins where we are, not with a big migration. The new world is driven by events, not configuration, and we specify our reactions in a modern programming language. These events are correlated to each other into a coherent model, an API for Software. Developers and automations work together, coordinating in chat. Decisions are for people; consistent execution of tedious tasks is for programs. Escape Bash and YAML Tired of managing CI/CD Bash scripts and YAML config across dozens of repositories? Use Atomist to tame the complexity and execute your best delivery process across all your repositories. What is this better way? Atomist lets you construct your delivery process in code \u2013 but not too much code. A service, a framework, and some libraries take care of the pieces that are common to every development organization. Atomist works atop your existing toolchain, adding functionality and smoothing your experience; then you\u2019re free to improve it. The crux of your development experience lives in your software delivery machine (SDM). This is a service that runs wherever you choose to run it. Start with one of ours, then make it yours. Your SDM is in TypeScript (or JavaScript works too), and comes with a framework designed for software delivery and development automation. Write functions to make decisions or take action, with access to all the code plus the context of the push or build or issue event. All of this is open source. While you can run an SDM independently and in private to help only yourself, the magic happens when it connects to the Atomist service to respond to your whole team or organization. The service provides triggering with rich events and custom commands, interactive chat integration, and built-in automations like sweet chat messages for standard events like code push and issue creation. These chat messages get updated when new information comes in. They include useful buttons to take action: raise a PR, label an issue, or approve the next step in the deploy process. But wait, there\u2019s more! I\u2019ve talked about how your delivery flow can be defined in code instead of Bash, in one open place instead of many narrow pipelines. I mentioned custom commands, where you can ensconce common developer activities in a convenient location, accessible from chat. These commands are code: consistent, shared, versioned. You might have gleaned that because your Software Delivery Machine is code, you\u2019re never limited to plugins, nor to anyone else\u2019s idea of the correct delivery mechanism; your SDM can integrate with your existing tools. Keep the tools that are working for you , and integrate new ones as you wish. Tie these together with an SDM, plus bonuses like automatic CHANGELOG management . Your SDM gives you something else: the ability to manipulate code across all your projects with one command. Atomist libraries help you write code transforms\u2013functions that operate on code\u2013and the API for Software turns those into branches, pull requests, or automatic commits on every deviating push. Bring code up to standards and then keep it there. Your SDM gives you something else: start new projects with the right code and setup, every time. Atomist generators start from a real, working project and use code transforms to construct a starting point in a new repository. Set up any other Your SDM can respond to more events , and to custom events that you send. You can query your correlated events using GraphQL. You can build chat commands, with updating messages and adding action buttons. You can add integrations and commands written by Atomist and the community, and contribute your own. Stories Check out some samples of what an Atomist SDM can do: Upgrade test files to a new standard Enforce custom code formatting Deploy Spring Boot to Kubernetes , and generate new projects, and manage versions of existing projects ( video ) Convert a migration script into a Slack command You might want to know Existing integrations Architecture Security model Try it out If you want to get started using Atomist in your team, with the built-in chat integrations , go to the Using Atomist page to get Atomist installed in your Slack workspace, authorized in GitHub, and connected to your continuous integration system. If you already are using Atomist and are interested in writing your own SDM, you can go to the Developer Guide to learn how to create and run your own SDM.","title":"Introduction"},{"location":"#atomist-how-teams-deliver-software","text":"Every serious business has its own development and delivery experience. Most of them aren\u2019t what we want. We want to spend our time and focus solving problems for the business, but to do that well, we need to enact our own blueprint for software delivery. So far, enterprises piece together pipeline tools, configured by a plethora of YAML or by hand in a GUI. For anything interesting, we resort to a Bash script, the lowest common denominator of programming. We enroll myriad chatbots to spam our channels. We write how-to wiki pages and distribute hand-me-down scripts. As our practices improve, older projects languish in prior standards. Meanwhile we shake our heads wistfully over the elegant flow of shiny new delivery tools \u2013 they will never fit our real-world environment. Atomist says, there is a better way. A world beyond pipelines, a world of little YAML and Bash, a world where we code our way to an appropriate delivery experience, with higher coding standards, up-to-date application suites, and continual improvement. And this way begins where we are, not with a big migration. The new world is driven by events, not configuration, and we specify our reactions in a modern programming language. These events are correlated to each other into a coherent model, an API for Software. Developers and automations work together, coordinating in chat. Decisions are for people; consistent execution of tedious tasks is for programs. Escape Bash and YAML Tired of managing CI/CD Bash scripts and YAML config across dozens of repositories? Use Atomist to tame the complexity and execute your best delivery process across all your repositories.","title":"Atomist - How Teams Deliver Software"},{"location":"#what-is-this-better-way","text":"Atomist lets you construct your delivery process in code \u2013 but not too much code. A service, a framework, and some libraries take care of the pieces that are common to every development organization. Atomist works atop your existing toolchain, adding functionality and smoothing your experience; then you\u2019re free to improve it. The crux of your development experience lives in your software delivery machine (SDM). This is a service that runs wherever you choose to run it. Start with one of ours, then make it yours. Your SDM is in TypeScript (or JavaScript works too), and comes with a framework designed for software delivery and development automation. Write functions to make decisions or take action, with access to all the code plus the context of the push or build or issue event. All of this is open source. While you can run an SDM independently and in private to help only yourself, the magic happens when it connects to the Atomist service to respond to your whole team or organization. The service provides triggering with rich events and custom commands, interactive chat integration, and built-in automations like sweet chat messages for standard events like code push and issue creation. These chat messages get updated when new information comes in. They include useful buttons to take action: raise a PR, label an issue, or approve the next step in the deploy process.","title":"What is this better way?"},{"location":"#but-wait-theres-more","text":"I\u2019ve talked about how your delivery flow can be defined in code instead of Bash, in one open place instead of many narrow pipelines. I mentioned custom commands, where you can ensconce common developer activities in a convenient location, accessible from chat. These commands are code: consistent, shared, versioned. You might have gleaned that because your Software Delivery Machine is code, you\u2019re never limited to plugins, nor to anyone else\u2019s idea of the correct delivery mechanism; your SDM can integrate with your existing tools. Keep the tools that are working for you , and integrate new ones as you wish. Tie these together with an SDM, plus bonuses like automatic CHANGELOG management . Your SDM gives you something else: the ability to manipulate code across all your projects with one command. Atomist libraries help you write code transforms\u2013functions that operate on code\u2013and the API for Software turns those into branches, pull requests, or automatic commits on every deviating push. Bring code up to standards and then keep it there. Your SDM gives you something else: start new projects with the right code and setup, every time. Atomist generators start from a real, working project and use code transforms to construct a starting point in a new repository. Set up any other Your SDM can respond to more events , and to custom events that you send. You can query your correlated events using GraphQL. You can build chat commands, with updating messages and adding action buttons. You can add integrations and commands written by Atomist and the community, and contribute your own.","title":"But wait, there's more!"},{"location":"#stories","text":"Check out some samples of what an Atomist SDM can do: Upgrade test files to a new standard Enforce custom code formatting Deploy Spring Boot to Kubernetes , and generate new projects, and manage versions of existing projects ( video ) Convert a migration script into a Slack command","title":"Stories"},{"location":"#you-might-want-to-know","text":"Existing integrations Architecture Security model","title":"You might want to know"},{"location":"#try-it-out","text":"If you want to get started using Atomist in your team, with the built-in chat integrations , go to the Using Atomist page to get Atomist installed in your Slack workspace, authorized in GitHub, and connected to your continuous integration system. If you already are using Atomist and are interested in writing your own SDM, you can go to the Developer Guide to learn how to create and run your own SDM.","title":"Try it out"},{"location":"lifecycle/","text":"Chat notifications about pushes, builds, pull requests, issues, and issue comments are fewer and far more useful when they\u2019re correlated by Atomist. You get one message per push, and that message updates as new information comes in. Less spam in your channels! Even better, the messages have buttons that make them useful. Linked Channels Section content not yet populated Sorry, we haven\u2019t written this part of the documentation yet. Will you tell us what questions are important to you? We\u2019re happy to help in the #support channel in Atomist community Slack . You can also contribute to this guide with an issue or pull request on the docs repository . Messages Push Section content not yet populated Sorry, we haven\u2019t written this part of the documentation yet. Will you tell us what questions are important to you? We\u2019re happy to help in the #support channel in Atomist community Slack . You can also contribute to this guide with an issue or pull request on the docs repository . Pull Request Section content not yet populated Sorry, we haven\u2019t written this part of the documentation yet. Will you tell us what questions are important to you? We\u2019re happy to help in the #support channel in Atomist community Slack . You can also contribute to this guide with an issue or pull request on the docs repository . Issue Section content not yet populated Sorry, we haven\u2019t written this part of the documentation yet. Will you tell us what questions are important to you? We\u2019re happy to help in the #support channel in Atomist community Slack . You can also contribute to this guide with an issue or pull request on the docs repository . Issue Comment Section content not yet populated Sorry, we haven\u2019t written this part of the documentation yet. Will you tell us what questions are important to you? We\u2019re happy to help in the #support channel in Atomist community Slack . You can also contribute to this guide with an issue or pull request on the docs repository . Build Build status is included on the push notification. If a build fails, the person who made the commit gets a private message with a link to the log. Configuring messages Section content not yet populated Sorry, we haven\u2019t written this part of the documentation yet. Will you tell us what questions are important to you? We\u2019re happy to help in the #support channel in Atomist community Slack . You can also contribute to this guide with an issue or pull request on the docs repository .","title":"Built-in Chat Integrations"},{"location":"lifecycle/#linked-channels","text":"Section content not yet populated Sorry, we haven\u2019t written this part of the documentation yet. Will you tell us what questions are important to you? We\u2019re happy to help in the #support channel in Atomist community Slack . You can also contribute to this guide with an issue or pull request on the docs repository .","title":"Linked Channels"},{"location":"lifecycle/#messages","text":"","title":"Messages"},{"location":"lifecycle/#push","text":"Section content not yet populated Sorry, we haven\u2019t written this part of the documentation yet. Will you tell us what questions are important to you? We\u2019re happy to help in the #support channel in Atomist community Slack . You can also contribute to this guide with an issue or pull request on the docs repository .","title":"Push"},{"location":"lifecycle/#pull-request","text":"Section content not yet populated Sorry, we haven\u2019t written this part of the documentation yet. Will you tell us what questions are important to you? We\u2019re happy to help in the #support channel in Atomist community Slack . You can also contribute to this guide with an issue or pull request on the docs repository .","title":"Pull Request"},{"location":"lifecycle/#issue","text":"Section content not yet populated Sorry, we haven\u2019t written this part of the documentation yet. Will you tell us what questions are important to you? We\u2019re happy to help in the #support channel in Atomist community Slack . You can also contribute to this guide with an issue or pull request on the docs repository .","title":"Issue"},{"location":"lifecycle/#issue-comment","text":"Section content not yet populated Sorry, we haven\u2019t written this part of the documentation yet. Will you tell us what questions are important to you? We\u2019re happy to help in the #support channel in Atomist community Slack . You can also contribute to this guide with an issue or pull request on the docs repository .","title":"Issue Comment"},{"location":"lifecycle/#build","text":"Build status is included on the push notification. If a build fails, the person who made the commit gets a private message with a link to the log.","title":"Build"},{"location":"lifecycle/#configuring-messages","text":"Section content not yet populated Sorry, we haven\u2019t written this part of the documentation yet. Will you tell us what questions are important to you? We\u2019re happy to help in the #support channel in Atomist community Slack . You can also contribute to this guide with an issue or pull request on the docs repository .","title":"Configuring messages"},{"location":"quick-start/","text":"The easiest way to get started with Atomist is to start on your laptop in local mode , working with local commits. Get your own software delivery machine, and then customize it. This Quick Start begins with an SDM for delivering and maintaining Java Spring Boot web services. You\u2019ll need Git , Node.js , and the Java JDK installed. Quick start Install the Atomist command-line utility. npm install -g @atomist/cli Create a local software delivery machine (SDM). This is going to create a new project in the Atomist projects directory (which defaults to $HOME/atomist/ ). Projects are grouped by user. atomist create sdm Select the default machine, spring . When prompted for the name of the target repository, enter quick-sdm . When prompted for a target owner, enter your user name (on GitHub or anywhere). Change into the newly created SDM project. cd ~/atomist/<your user name>/quick-sdm Start your local SDM. atomist start --local The above command will install the project dependencies using NPM, compile the TypeScript, and start your SDM. Depending on your network connection, this may take a minute or more. Leave this terminal window open. Logs will print to this screen. In another terminal, check what your SDM can do. This will print a list of commands supported by your running quick-sdm. atomist show skills Start up the SDM feed so you can see what the SDM is doing. atomist feed Leave this terminal window open. Messages will print here. In another terminal, create a Spring Boot project. atomist create spring This command will connect to your locally running SDM and use its capabilities to create a new Spring Boot project for you. When prompted for the target repository, enter quick-spring . When prompted for group identifier and root package, enter com.me and com.me.spring , respectively. When prompted for the target owner, enter your user name again. If you look in the terminal with the Atomist feed, you will see the SDM cloning the seed repository, cloning it locally, building it, and deploying it locally. The first time you run this, it may take a few minutes as it downloads all the Maven and project dependencies. You can go to the URL provided for the local deployment and verify that your new Spring Boot application is running. Change into your newly created Spring Boot project. cd ~/atomist/<your user name>/quick-spring Change the message in your Spring Boot application. Edit src/main/java/com/me/spring/QuickSpringController.java , changing \u201cworld\u201d to your location. Then commit your change. git add src/main/java/com/me/spring/QuickSpringController.java git commit -m 'Update location' Go back to the Atomist feed to observe your locally running SDM noticing your commit and respond by building and deploying your latest version. Go to the URL again and verify the message contains your location. Next steps Learn more about what you can do with an SDM in the Developer Guide . When you\u2019re ready to put your SDM to work for your whole team, continue with setup .","title":"Developer Quick Start"},{"location":"quick-start/#quick-start","text":"Install the Atomist command-line utility. npm install -g @atomist/cli Create a local software delivery machine (SDM). This is going to create a new project in the Atomist projects directory (which defaults to $HOME/atomist/ ). Projects are grouped by user. atomist create sdm Select the default machine, spring . When prompted for the name of the target repository, enter quick-sdm . When prompted for a target owner, enter your user name (on GitHub or anywhere). Change into the newly created SDM project. cd ~/atomist/<your user name>/quick-sdm Start your local SDM. atomist start --local The above command will install the project dependencies using NPM, compile the TypeScript, and start your SDM. Depending on your network connection, this may take a minute or more. Leave this terminal window open. Logs will print to this screen. In another terminal, check what your SDM can do. This will print a list of commands supported by your running quick-sdm. atomist show skills Start up the SDM feed so you can see what the SDM is doing. atomist feed Leave this terminal window open. Messages will print here. In another terminal, create a Spring Boot project. atomist create spring This command will connect to your locally running SDM and use its capabilities to create a new Spring Boot project for you. When prompted for the target repository, enter quick-spring . When prompted for group identifier and root package, enter com.me and com.me.spring , respectively. When prompted for the target owner, enter your user name again. If you look in the terminal with the Atomist feed, you will see the SDM cloning the seed repository, cloning it locally, building it, and deploying it locally. The first time you run this, it may take a few minutes as it downloads all the Maven and project dependencies. You can go to the URL provided for the local deployment and verify that your new Spring Boot application is running. Change into your newly created Spring Boot project. cd ~/atomist/<your user name>/quick-spring Change the message in your Spring Boot application. Edit src/main/java/com/me/spring/QuickSpringController.java , changing \u201cworld\u201d to your location. Then commit your change. git add src/main/java/com/me/spring/QuickSpringController.java git commit -m 'Update location' Go back to the Atomist feed to observe your locally running SDM noticing your commit and respond by building and deploying your latest version. Go to the URL again and verify the message contains your location.","title":"Quick start"},{"location":"quick-start/#next-steps","text":"Learn more about what you can do with an SDM in the Developer Guide . When you\u2019re ready to put your SDM to work for your whole team, continue with setup .","title":"Next steps"},{"location":"support/","text":"Thanks so much for choosing Atomist! At Atomist, we want all developers to excel. We believe that given the right tools and guidance, all developers can be highly productive. We strive to provide tools that give their users super powers and we\u2019re happy to provide any guidance we can to help you use them most effectively. If you have any questions or need any help of any kind, don\u2019t hesitate to contact us in whatever way is most convenient for you. Chat with us right here Atomist Community Slack support@atomist.com Twitter Issues and pull requests on our open source projects We exist to help you be as productive you can be. Let us know how we can help you. Happy coding!","title":"Support"},{"location":"developer/","text":"How to use this guide With this guide, we aim to provide all the information you need to create and customize a software delivery machine for your organization\u2019s needs. When the information here is not clear or not sufficient, we appreciate your perspective. Ask us questions through the chat icon in the lower-right of this page, or on the Atomist community Slack . You can also contribute to this guide by creating issues or pull requests on the docs repository . If you want to learn by doing, run through the Developer Quick Start first. If you want to start from higher-level concepts, begin reading about the architecture . New superpowers This guide should help you make your SDM: Build your repositories , more flexibly than a pipeline Deploy your code , with interactivity Inspect your code , across projects and automatically on push Transform your code , across projects and automatically on push Respond to builds , from the SDM or external build systems Implement custom commands Create new projects according to your own standards Underlying concepts To do all this, these higher-level concepts are relevant: Setting up your system to develop and run SDMs the atomist command line tool Software Delivery Machine organization Commands Goals the Project interface Advanced topics Crafting sophisticated Slack messages Using GraphQL to subscribe to events Deploying your SDM Once you\u2019ve finished this section, you\u2019ll have everything you need to eliminate the pain points in your development and delivery processes.","title":"About this guide"},{"location":"developer/#how-to-use-this-guide","text":"With this guide, we aim to provide all the information you need to create and customize a software delivery machine for your organization\u2019s needs. When the information here is not clear or not sufficient, we appreciate your perspective. Ask us questions through the chat icon in the lower-right of this page, or on the Atomist community Slack . You can also contribute to this guide by creating issues or pull requests on the docs repository . If you want to learn by doing, run through the Developer Quick Start first. If you want to start from higher-level concepts, begin reading about the architecture .","title":"How to use this guide"},{"location":"developer/#new-superpowers","text":"This guide should help you make your SDM: Build your repositories , more flexibly than a pipeline Deploy your code , with interactivity Inspect your code , across projects and automatically on push Transform your code , across projects and automatically on push Respond to builds , from the SDM or external build systems Implement custom commands Create new projects according to your own standards","title":"New superpowers"},{"location":"developer/#underlying-concepts","text":"To do all this, these higher-level concepts are relevant: Setting up your system to develop and run SDMs the atomist command line tool Software Delivery Machine organization Commands Goals the Project interface","title":"Underlying concepts"},{"location":"developer/#advanced-topics","text":"Crafting sophisticated Slack messages Using GraphQL to subscribe to events Deploying your SDM Once you\u2019ve finished this section, you\u2019ll have everything you need to eliminate the pain points in your development and delivery processes.","title":"Advanced topics"},{"location":"developer/architecture/","text":"It all starts with a software delivery machine of your very own. An Atomist Software Delivery Machine (SDM) provides a high-level interface for you to take action when things happen. In much the same way your CI build kicks off when you push to your repository, Atomist can execute tasks like security scans, documentation publication, release creation, and deployment when different events occur within your development environment. Because you\u2019re using a real programming language, not YAML or Bash, and you have access to a real ecosystem, Node.js, you can create a richer delivery experience than you\u2019ve even imagined. API for Software An SDM links up to the API for software , exposing: What we know : The Atomist cortex, accessible through GraphQL queries and subscription joins What just happened : An event, triggered by a GraphQL subscription, which is contextualized with the existing knowledge What you\u2019re working on : A library that enables you to comprehend and manipulate the source code you\u2019re working on. When a push occurs, the SDM gets all this context and the code. It decides what delivery actions to take, and sets goals accordingly. A push is not the only event that matters in our software development. The Atomist development automation platform ingests events from your software development systems: Source code repositories like GitHub.com and GitHub Enterprise Issue tracking systems like GitHub and Jira Continuous integration platforms like Travis CI , CircleCI , and Jenkins Application frameworks like Spring Runtime platforms like Kubernetes and Cloud Foundry Custom events from any other system you use and makes them available via the Atomist API for software. As Atomist ingests events, typically via webhook JSON payloads, it automatically correlates them to each other: commits to pushes to builds to deployments to running containers. This results in a data model that represents your development flow. The Software Delivery Machine subscribes to the most important events, like a push to source control and a completed build. You can subscribe to more events and take action when they occur, with the data model providing the necessary context so your automations can always do the right thing. The development automation platform also provides a simple yet powerful interface for implementing custom chat bot commands, also executable from your command line. Atomist provides all the infrastructure needed to recognize commands, collect parameters, execute the code, and respond. This lets you focus on writing your command code, not boilerplate code and ceremony around running bots. Instead of shell scripts that are useful to you, write commands that help your whole team. Coding your SDM A software delivery machine uses the @atomist/sdm framework to specify the code delivery process and other automations. You don\u2019t configure your SDM: you code it, by combining or writing functions in TypeScript (or JavaScript). Some common setups, such as deliverying and maintaining Spring Boot apps or npm libraries, are provided in extension packs . You can configure the whole pack, or use functions from the pack in your own setup. Connect your SDM Atomist maintains two implementations of the API for Software: Team mode: a complete, cloud-based service, Local mode: an open-source, filesystem-based version that runs on your laptop. An SDM is most useful when running for your whole team, connected to the Atomist API for software, Slack, and your version control. Run it on your laptop while you\u2019re testing and modifying the SDM, then in your favorite production environment (on-prem or in the cloud) for ongoing use. If you don\u2019t want to subscribe to the Atomist service and hook up Slack and GitHub/BitBucket/GitLab etc, you\u2019re in luck! Run your SDM in local mode, on your own machine. Receive push events from your own local commits, get messages in a terminal feed, and run trigger commands on the command line. An SDM can also run locally, on your laptop. From there, either connect to the Atomist API for software (team mode), or run in local mode: respond to git commits, see messages in a terminal running atomist feed , and send commands to Atomist from the command line. The SDM is a persistent process that runs in the background, whether in local or team mode. While the SDM is most valuable when it is coordinating delivery and performing commands for your whole team, you can also test and operate an SDM in local mode, on your laptop, without connecting to the Atomist API. Check the Developer Quick Start for instructions to get started locally.","title":"Architecture"},{"location":"developer/architecture/#api-for-software","text":"An SDM links up to the API for software , exposing: What we know : The Atomist cortex, accessible through GraphQL queries and subscription joins What just happened : An event, triggered by a GraphQL subscription, which is contextualized with the existing knowledge What you\u2019re working on : A library that enables you to comprehend and manipulate the source code you\u2019re working on. When a push occurs, the SDM gets all this context and the code. It decides what delivery actions to take, and sets goals accordingly. A push is not the only event that matters in our software development. The Atomist development automation platform ingests events from your software development systems: Source code repositories like GitHub.com and GitHub Enterprise Issue tracking systems like GitHub and Jira Continuous integration platforms like Travis CI , CircleCI , and Jenkins Application frameworks like Spring Runtime platforms like Kubernetes and Cloud Foundry Custom events from any other system you use and makes them available via the Atomist API for software. As Atomist ingests events, typically via webhook JSON payloads, it automatically correlates them to each other: commits to pushes to builds to deployments to running containers. This results in a data model that represents your development flow. The Software Delivery Machine subscribes to the most important events, like a push to source control and a completed build. You can subscribe to more events and take action when they occur, with the data model providing the necessary context so your automations can always do the right thing. The development automation platform also provides a simple yet powerful interface for implementing custom chat bot commands, also executable from your command line. Atomist provides all the infrastructure needed to recognize commands, collect parameters, execute the code, and respond. This lets you focus on writing your command code, not boilerplate code and ceremony around running bots. Instead of shell scripts that are useful to you, write commands that help your whole team.","title":"API for Software"},{"location":"developer/architecture/#coding-your-sdm","text":"A software delivery machine uses the @atomist/sdm framework to specify the code delivery process and other automations. You don\u2019t configure your SDM: you code it, by combining or writing functions in TypeScript (or JavaScript). Some common setups, such as deliverying and maintaining Spring Boot apps or npm libraries, are provided in extension packs . You can configure the whole pack, or use functions from the pack in your own setup.","title":"Coding your SDM"},{"location":"developer/architecture/#connect-your-sdm","text":"Atomist maintains two implementations of the API for Software: Team mode: a complete, cloud-based service, Local mode: an open-source, filesystem-based version that runs on your laptop. An SDM is most useful when running for your whole team, connected to the Atomist API for software, Slack, and your version control. Run it on your laptop while you\u2019re testing and modifying the SDM, then in your favorite production environment (on-prem or in the cloud) for ongoing use. If you don\u2019t want to subscribe to the Atomist service and hook up Slack and GitHub/BitBucket/GitLab etc, you\u2019re in luck! Run your SDM in local mode, on your own machine. Receive push events from your own local commits, get messages in a terminal feed, and run trigger commands on the command line. An SDM can also run locally, on your laptop. From there, either connect to the Atomist API for software (team mode), or run in local mode: respond to git commits, see messages in a terminal running atomist feed , and send commands to Atomist from the command line. The SDM is a persistent process that runs in the background, whether in local or team mode. While the SDM is most valuable when it is coordinating delivery and performing commands for your whole team, you can also test and operate an SDM in local mode, on your laptop, without connecting to the Atomist API. Check the Developer Quick Start for instructions to get started locally.","title":"Connect your SDM"},{"location":"developer/autofix/","text":"Section content not yet populated Sorry, we haven\u2019t written this part of the documentation yet. Will you tell us what questions are important to you? We\u2019re happy to help in the #support channel in Atomist community Slack . You can also contribute to this guide with an issue or pull request on the docs repository .","title":"Autofixes"},{"location":"developer/build-event/","text":"Section content not yet populated Sorry, we haven\u2019t written this part of the documentation yet. Will you tell us what questions are important to you? We\u2019re happy to help in the #support channel in Atomist community Slack . You can also contribute to this guide with an issue or pull request on the docs repository .","title":"Reacting to Builds"},{"location":"developer/build/","text":"Section content not yet populated Sorry, we haven\u2019t written this part of the documentation yet. Will you tell us what questions are important to you? We\u2019re happy to help in the #support channel in Atomist community Slack . You can also contribute to this guide with an issue or pull request on the docs repository .","title":"Build Goal"},{"location":"developer/cli/","text":"The Atomist command line is useful for starting SDMs and configuring your connection. In local mode , the atomist command line runs commands in your SDM. help Run atomist --help to see a list of options. Since atomist can run multi-word commands, only the first word of each is listed in the help. Drill down by asking for more specific help. For instance, atomist --help yields (among other lines): atomist show ... 2 commands To find out what you can show, use atomist show --help . Commands: atomist show sdms Show connected sdms atomist show skills Show skills atomist start Section content not yet populated Sorry, we haven\u2019t written this part of the documentation yet. Will you tell us what questions are important to you? We\u2019re happy to help in the #support channel in Atomist community Slack . You can also contribute to this guide with an issue or pull request on the docs repository . atomist feed Section content not yet populated Sorry, we haven\u2019t written this part of the documentation yet. Will you tell us what questions are important to you? We\u2019re happy to help in the #support channel in Atomist community Slack . You can also contribute to this guide with an issue or pull request on the docs repository . Section content not yet populated Sorry, we haven\u2019t written this part of the documentation yet. Will you tell us what questions are important to you? We\u2019re happy to help in the #support channel in Atomist community Slack . You can also contribute to this guide with an issue or pull request on the docs repository .","title":"Command Line Interface"},{"location":"developer/cli/#help","text":"Run atomist --help to see a list of options. Since atomist can run multi-word commands, only the first word of each is listed in the help. Drill down by asking for more specific help. For instance, atomist --help yields (among other lines): atomist show ... 2 commands To find out what you can show, use atomist show --help . Commands: atomist show sdms Show connected sdms atomist show skills Show skills","title":"help"},{"location":"developer/cli/#atomist-start","text":"Section content not yet populated Sorry, we haven\u2019t written this part of the documentation yet. Will you tell us what questions are important to you? We\u2019re happy to help in the #support channel in Atomist community Slack . You can also contribute to this guide with an issue or pull request on the docs repository .","title":"atomist start"},{"location":"developer/cli/#atomist-feed","text":"Section content not yet populated Sorry, we haven\u2019t written this part of the documentation yet. Will you tell us what questions are important to you? We\u2019re happy to help in the #support channel in Atomist community Slack . You can also contribute to this guide with an issue or pull request on the docs repository .","title":"atomist feed"},{"location":"developer/commands/","text":"Section content not yet populated Sorry, we haven\u2019t written this part of the documentation yet. Will you tell us what questions are important to you? We\u2019re happy to help in the #support channel in Atomist community Slack . You can also contribute to this guide with an issue or pull request on the docs repository . Run your command Section content not yet populated Sorry, we haven\u2019t written this part of the documentation yet. Will you tell us what questions are important to you? We\u2019re happy to help in the #support channel in Atomist community Slack . You can also contribute to this guide with an issue or pull request on the docs repository .","title":"Commands"},{"location":"developer/commands/#run-your-command","text":"Section content not yet populated Sorry, we haven\u2019t written this part of the documentation yet. Will you tell us what questions are important to you? We\u2019re happy to help in the #support channel in Atomist community Slack . You can also contribute to this guide with an issue or pull request on the docs repository .","title":"Run your command"},{"location":"developer/config/","text":"Configure your SDM with connection parameters for the Atomist API for software, and for anything else that your particular delivery automations need. Initialize your SDM configuration by running atomist config as instructed in prerequisites . The configuration file, typically located under your home/user profile directory at .atomist/client.config.json . It is a standard JSON file. To connect to the Atomist service, it will look something like: { \"apiKey\" : \"ABCDEF0123456789ABCDEF0123456789ABCDEF0123456789\" , \"workspaceIds\" : [ \"A0421WAYA\" , ] } The apiKey is your Atomist API key and workspaceIds are the Atomist IDs of the workspaces where you want to run your team SDMs. If you want to change the API key or add/remove workspaces, you can edit this file directly. The configuration values in the atomist.config.ts file will override those from your user configuration. Project root Section content not yet populated Sorry, we haven\u2019t written this part of the documentation yet. Will you tell us what questions are important to you? We\u2019re happy to help in the #support channel in Atomist community Slack . You can also contribute to this guide with an issue or pull request on the docs repository .","title":"SDM Configuration"},{"location":"developer/config/#project-root","text":"Section content not yet populated Sorry, we haven\u2019t written this part of the documentation yet. Will you tell us what questions are important to you? We\u2019re happy to help in the #support channel in Atomist community Slack . You can also contribute to this guide with an issue or pull request on the docs repository .","title":"Project root"},{"location":"developer/create/","text":"Automated project creation saves time and ensures that you start new services, libraries and other projects with good solid code that meets your standards and includes the components you need, configured the way you like them. In Atomist, you automate project creation using a generator, a type of command. Generators typically copy their code from a known-good repository called a seed, and then modify the code in certain ways, such as renaming classes so that it\u2019s ready to use without lots of manual find and replace. Generators frequently also configure supporting systems, for example, by creating a dedicated Slack channel, setting up issue tracking, and so on. To make your own generator, get an SDM of your own. Then take a look at a generator that makes a Spring 5 project \u2013 it declares a starting point and customizes that code . The SDM hooks your generator up to Slack. You can also add a custom form to serve project creation to your team or organization. A generator is one kind of command handler , so you can make it do as much as you want.","title":"Project Generators"},{"location":"developer/deploy/","text":"Section content not yet populated Sorry, we haven\u2019t written this part of the documentation yet. Will you tell us what questions are important to you? We\u2019re happy to help in the #support channel in Atomist community Slack . You can also contribute to this guide with an issue or pull request on the docs repository .","title":"Deploys"},{"location":"developer/events/","text":"SDM supported events Section content not yet populated Sorry, we haven\u2019t written this part of the documentation yet. Will you tell us what questions are important to you? We\u2019re happy to help in the #support channel in Atomist community Slack . You can also contribute to this guide with an issue or pull request on the docs repository . Subscribing to more events Section content not yet populated Sorry, we haven\u2019t written this part of the documentation yet. Will you tell us what questions are important to you? We\u2019re happy to help in the #support channel in Atomist community Slack . You can also contribute to this guide with an issue or pull request on the docs repository . Creating your own events Section content not yet populated Sorry, we haven\u2019t written this part of the documentation yet. Will you tell us what questions are important to you? We\u2019re happy to help in the #support channel in Atomist community Slack . You can also contribute to this guide with an issue or pull request on the docs repository .","title":"Events"},{"location":"developer/events/#sdm-supported-events","text":"Section content not yet populated Sorry, we haven\u2019t written this part of the documentation yet. Will you tell us what questions are important to you? We\u2019re happy to help in the #support channel in Atomist community Slack . You can also contribute to this guide with an issue or pull request on the docs repository .","title":"SDM supported events"},{"location":"developer/events/#subscribing-to-more-events","text":"Section content not yet populated Sorry, we haven\u2019t written this part of the documentation yet. Will you tell us what questions are important to you? We\u2019re happy to help in the #support channel in Atomist community Slack . You can also contribute to this guide with an issue or pull request on the docs repository .","title":"Subscribing to more events"},{"location":"developer/events/#creating-your-own-events","text":"Section content not yet populated Sorry, we haven\u2019t written this part of the documentation yet. Will you tell us what questions are important to you? We\u2019re happy to help in the #support channel in Atomist community Slack . You can also contribute to this guide with an issue or pull request on the docs repository .","title":"Creating your own events"},{"location":"developer/goal/","text":"The most important SDM functionality relates to what happens on a push to a repository. An SDM allows you to process a push in any way you choose, but typically you want it to initiate a delivery flow. An SDM allows you to set goals on push. Goals correspond to the actions that make up a delivery flow, such as build and deployment. Goals are not necessarily sequential\u2013some may be executed in parallel\u2013but certain goals, such as deployment, have preconditions (goals that must have previously completed successfully). In Slack, a push notification with several goals looks like this: Set goals wherever you configure your SDM, probably in lib/machine/machine.ts . This example comes from a Spring SDM . You can instantiate create goals and add implementations to them. Here, an Autofix goal has one autofix registered on it; it will add license headers to any code file that doesn\u2019t have one yet, and make a commit. const autofix = new Autofix (). with ( AddLicenseFile ); You can group goals into sets. Here, two goals are grouped: code inspection (but no code inspections are registered) and the Autofix goal. const BaseGoals = goals ( \"checks\" ) . plan ( new AutoCodeInspection ()) . plan ( autofix ); You can specify ordering, if some goals should wait for others to succeed. Here, we don\u2019t want to start the build until after Autofixes have completed. If the autofixes do anything, they\u2019ll make a new commit, and we don\u2019t bother building this one. const BuildGoals = goals(\"build\") .plan(new Build().with({ builder: mavenBuilder() })) .after(autofix); Finally, you can tell the SDM which goal sets to run on . Here, we set the BaseGoals (inspection and autofix) on every push. Then if this is a Maven project (identified by having a pom.xml), we do the build as well. sdm.addGoalContributions(goalContributors( onAnyPush().setGoals(BaseGoals), whenPushSatisfies(IsMaven).setGoals(BuildGoals), )); Check the page about Setting Goals for more details. Built-in Goals A goal object has some identifying information, code to fulfill the goal, and sometimes preconditions (goals that need to complete before this one can go). Some common ones have their own constructors: AutoInspect Run an inspection on the code; if the code doesn\u2019t pass, you can fail the goals or require approval (a button push). To use it, you\u2019ll need to create one, set it on each push, and register inspections on it. Instantiate an empty one: export const codeInspection = new AutoCodeInspection (); And set it when you want it to run on a push. Here\u2019s the shortest way to run this goal on every push: sdm . addGoalContributions ( goalContributors ( onAnyPush (). setGoals ( goals ( \"Inspections\" ). plan ( codeInspection )))) Now the fun part: register inspections on it. Check the Inspections page for more on how to write inspections. Once you have an AutoInspectRegistration , register it on your goal: codeInspection . with ( MyAutoInspectRegistration ) . with ( AnotherInspectRegistration ); You can register any number of inspections. You can call with on the goal at any point in SDM configuration. If no inspections are registered, the goal will succeed. If any registration\u2019s onInspectionResult returns \u201cfail\u201d, the goal will fail. If none return \u201cfail\u201d but one returns \u201crequire approval\u201d, the goal will go to Waiting for Approval state until someone clicks the Approve button in Slack or on the Atomist dashboard. Autofix Section content not yet populated Sorry, we haven\u2019t written this part of the documentation yet. Will you tell us what questions are important to you? We\u2019re happy to help in the #support channel in Atomist community Slack . You can also contribute to this guide with an issue or pull request on the docs repository . PushImpact Section content not yet populated Sorry, we haven\u2019t written this part of the documentation yet. Will you tell us what questions are important to you? We\u2019re happy to help in the #support channel in Atomist community Slack . You can also contribute to this guide with an issue or pull request on the docs repository . Build Section content not yet populated Sorry, we haven\u2019t written this part of the documentation yet. Will you tell us what questions are important to you? We\u2019re happy to help in the #support channel in Atomist community Slack . You can also contribute to this guide with an issue or pull request on the docs repository . Fingerprint Section content not yet populated Sorry, we haven\u2019t written this part of the documentation yet. Will you tell us what questions are important to you? We\u2019re happy to help in the #support channel in Atomist community Slack . You can also contribute to this guide with an issue or pull request on the docs repository . Custom Goals Section content not yet populated Sorry, we haven\u2019t written this part of the documentation yet. Will you tell us what questions are important to you? We\u2019re happy to help in the #support channel in Atomist community Slack . You can also contribute to this guide with an issue or pull request on the docs repository .","title":"About Goals"},{"location":"developer/goal/#built-in-goals","text":"A goal object has some identifying information, code to fulfill the goal, and sometimes preconditions (goals that need to complete before this one can go). Some common ones have their own constructors:","title":"Built-in Goals"},{"location":"developer/goal/#autoinspect","text":"Run an inspection on the code; if the code doesn\u2019t pass, you can fail the goals or require approval (a button push). To use it, you\u2019ll need to create one, set it on each push, and register inspections on it. Instantiate an empty one: export const codeInspection = new AutoCodeInspection (); And set it when you want it to run on a push. Here\u2019s the shortest way to run this goal on every push: sdm . addGoalContributions ( goalContributors ( onAnyPush (). setGoals ( goals ( \"Inspections\" ). plan ( codeInspection )))) Now the fun part: register inspections on it. Check the Inspections page for more on how to write inspections. Once you have an AutoInspectRegistration , register it on your goal: codeInspection . with ( MyAutoInspectRegistration ) . with ( AnotherInspectRegistration ); You can register any number of inspections. You can call with on the goal at any point in SDM configuration. If no inspections are registered, the goal will succeed. If any registration\u2019s onInspectionResult returns \u201cfail\u201d, the goal will fail. If none return \u201cfail\u201d but one returns \u201crequire approval\u201d, the goal will go to Waiting for Approval state until someone clicks the Approve button in Slack or on the Atomist dashboard.","title":"AutoInspect"},{"location":"developer/goal/#autofix","text":"Section content not yet populated Sorry, we haven\u2019t written this part of the documentation yet. Will you tell us what questions are important to you? We\u2019re happy to help in the #support channel in Atomist community Slack . You can also contribute to this guide with an issue or pull request on the docs repository .","title":"Autofix"},{"location":"developer/goal/#pushimpact","text":"Section content not yet populated Sorry, we haven\u2019t written this part of the documentation yet. Will you tell us what questions are important to you? We\u2019re happy to help in the #support channel in Atomist community Slack . You can also contribute to this guide with an issue or pull request on the docs repository .","title":"PushImpact"},{"location":"developer/goal/#build","text":"Section content not yet populated Sorry, we haven\u2019t written this part of the documentation yet. Will you tell us what questions are important to you? We\u2019re happy to help in the #support channel in Atomist community Slack . You can also contribute to this guide with an issue or pull request on the docs repository .","title":"Build"},{"location":"developer/goal/#fingerprint","text":"Section content not yet populated Sorry, we haven\u2019t written this part of the documentation yet. Will you tell us what questions are important to you? We\u2019re happy to help in the #support channel in Atomist community Slack . You can also contribute to this guide with an issue or pull request on the docs repository .","title":"Fingerprint"},{"location":"developer/goal/#custom-goals","text":"Section content not yet populated Sorry, we haven\u2019t written this part of the documentation yet. Will you tell us what questions are important to you? We\u2019re happy to help in the #support channel in Atomist community Slack . You can also contribute to this guide with an issue or pull request on the docs repository .","title":"Custom Goals"},{"location":"developer/graphql/","text":"GraphQL is a powerful query language that you use to query and mutate your data in the Atomist automation platform. Besides being a great query language, GraphQL provides great tool support based on strongly-typed schemas, type generation for TypeScript, and many other advantages. The Atomist SDM includes many of the GraphQL queries that are most useful in automating software delivery. You can also create your own. The following sections tell you how to use GraphQL to query your data, how to use subscriptions to get notifications when new data is ingested, and how to mutate data. Accessing data with Graph i QL For development purposes it is often helpful to test GraphQL queries using a user interface. The Atomist web application provides the Graph i QL GraphQL client, which allows you write and run queries, displaying the shape of the resulting data. Graph i QL also provides access to the data model documentation. Queries You can execute queries from command and event handlers when running an Atomist API client using the GraphClient.query() function. A GraphClient is available from the HandlerContext included in listener invocations via its graphClient property. The query() function takes a single argument: a QueryOptions object. The actual GraphQL query can be supplied as a string via the query property of QueryOptions , as the path to a file containing the query via the path property, or as the name of a query in the project\u2019s GraphQL query files via the name property. The path property can be an absolute or relative path, the latter being resolved against the path of the calling script. The name should be the name of a GraphQL query operation found within a file with a .graphql extension in a graphql/query folder in the directory of the calling script or one of its parents. Note Externalizing queries in files makes it possible to generate types for use in your TypeScript code. More on that later. The following example shows you how to query for pushes and see all corresponding continuous integration builds. Start by creating the query. The sample query includes a variable and a predicate that matches only failed builds. This example assumes the query is saved in a file called pushesWithFailedBuilds.graphql . query PushesWithFailedBuilds ($name: String!) { Push { repo(name: $name) { name owner } builds(status: failed) { name status buildUrl } } } Once the query is defined, you can use it with the GraphClient to execute a query. const result = await invocation . context . graphClient . query ({ name : \"PushesWithFailedBuilds\" , variables : { name : \"demo-service\" }, }) } The query method takes the name of the query as the name property of its first parameter. The name provided matches that in the GraphQL file. The variables property in the above example is used to provide the value for the query variable. Custom Event Handlers TODO: document Subscriptions As detailed in the section on event handlers, GraphQL subscriptions can be used to subscribe to events as they get ingested into the Atomist platform. Subscriptions can\u2019t be executed with the GraphClient ; instead they can only be used from an event handler. Many of these are included in the SDM. There are two ways to declare subscriptions on event handlers: either by embedded strings or by referencing external files, which is more reusable. This example demonstrates subscribing using an external file: subscription PushesWithFailedBuilds { Push { repo { name owner } builds(status: failed) { name status buildUrl } } } A GraphQL subscription begins with the keyword subscription followed by a name for the subscription, PushesWithFailedBuilds in this case. After the opening brace, you specify the type of the top-level event you are subscribing to, Push in this example. Your subscription then defines the structured data you want to receive for each such event, navigating the data model\u2019s properties and relationships to connect related data elements like pushes, repositories, and CI builds. !!! note When specifying the filename, the `.graphql` extension is optional. ## Mutations Most of the data in the Atomist platform is ingested via Webhooks and is read-only. There are however a small number of very useful GraphQL mutations available. | Mutation | Description | |----------|-------------| | `createSlackChannel` | Create a new public channel in Slack | | `addBotToSlackChannel` | Invite the Atomist bot user into the given channel | | `inviteUserToSlackChannel` | Invite any user into the given channel | | `linkSlackChannelToRepo` | [Link a GitHub repository to a Slack channel][repo-link] | | `setTeamPreference` | Set preference data on the team entity | | `setUserPreference` | Set preference data on the user entity | [repo-link]: ../user/slack.md (Link GitHub Repository to Slack Channel) Like queries, mutations can be loaded from files and executed with the `GraphClient`. Here is an example showing how to create a new channel in Slack. Here's the GraphQL file containing the mutation: ```graphql mutation CreateSlackChannel($name: String!) { createSlackChannel(name: $name) { id } } This invokes the mutation from the GraphQL file: await invocation . context . graphClient . mutate ({ name : \"CreateSlackChannel\" , variables : { name : \"random\" }, }) Strongly-typed GraphQL queries One nice side-effect of using GraphQL as the query layer is that you can generate types for use with TypeScript from the schema and your queries, subscriptions, and mutations. To generate types for your externalized GraphQL operations, run npm run gql:gen . This creates a file called types.ts in src/typings/ . Now you can change the earlier query to use those types: import * as graphql from \"./typings/types\" ; //... const result = await invocation . context . graphClient . query < graphql . PushesWithFailedBuilds . Query , graphql . PushesWithFailedBuilds . Variables > ({ name : \"PushesWithFailedBuilds\" , variables : { name : \"demo-service\" }, }); // .... }","title":"Custom GraphQL Queries"},{"location":"developer/graphql/#accessing-data-with-graphiql","text":"For development purposes it is often helpful to test GraphQL queries using a user interface. The Atomist web application provides the Graph i QL GraphQL client, which allows you write and run queries, displaying the shape of the resulting data. Graph i QL also provides access to the data model documentation.","title":"Accessing data with GraphiQL"},{"location":"developer/graphql/#queries","text":"You can execute queries from command and event handlers when running an Atomist API client using the GraphClient.query() function. A GraphClient is available from the HandlerContext included in listener invocations via its graphClient property. The query() function takes a single argument: a QueryOptions object. The actual GraphQL query can be supplied as a string via the query property of QueryOptions , as the path to a file containing the query via the path property, or as the name of a query in the project\u2019s GraphQL query files via the name property. The path property can be an absolute or relative path, the latter being resolved against the path of the calling script. The name should be the name of a GraphQL query operation found within a file with a .graphql extension in a graphql/query folder in the directory of the calling script or one of its parents. Note Externalizing queries in files makes it possible to generate types for use in your TypeScript code. More on that later. The following example shows you how to query for pushes and see all corresponding continuous integration builds. Start by creating the query. The sample query includes a variable and a predicate that matches only failed builds. This example assumes the query is saved in a file called pushesWithFailedBuilds.graphql . query PushesWithFailedBuilds ($name: String!) { Push { repo(name: $name) { name owner } builds(status: failed) { name status buildUrl } } } Once the query is defined, you can use it with the GraphClient to execute a query. const result = await invocation . context . graphClient . query ({ name : \"PushesWithFailedBuilds\" , variables : { name : \"demo-service\" }, }) } The query method takes the name of the query as the name property of its first parameter. The name provided matches that in the GraphQL file. The variables property in the above example is used to provide the value for the query variable.","title":"Queries"},{"location":"developer/graphql/#custom-event-handlers","text":"TODO: document","title":"Custom Event Handlers"},{"location":"developer/graphql/#subscriptions","text":"As detailed in the section on event handlers, GraphQL subscriptions can be used to subscribe to events as they get ingested into the Atomist platform. Subscriptions can\u2019t be executed with the GraphClient ; instead they can only be used from an event handler. Many of these are included in the SDM. There are two ways to declare subscriptions on event handlers: either by embedded strings or by referencing external files, which is more reusable. This example demonstrates subscribing using an external file: subscription PushesWithFailedBuilds { Push { repo { name owner } builds(status: failed) { name status buildUrl } } } A GraphQL subscription begins with the keyword subscription followed by a name for the subscription, PushesWithFailedBuilds in this case. After the opening brace, you specify the type of the top-level event you are subscribing to, Push in this example. Your subscription then defines the structured data you want to receive for each such event, navigating the data model\u2019s properties and relationships to connect related data elements like pushes, repositories, and CI builds. !!! note When specifying the filename, the `.graphql` extension is optional. ## Mutations Most of the data in the Atomist platform is ingested via Webhooks and is read-only. There are however a small number of very useful GraphQL mutations available. | Mutation | Description | |----------|-------------| | `createSlackChannel` | Create a new public channel in Slack | | `addBotToSlackChannel` | Invite the Atomist bot user into the given channel | | `inviteUserToSlackChannel` | Invite any user into the given channel | | `linkSlackChannelToRepo` | [Link a GitHub repository to a Slack channel][repo-link] | | `setTeamPreference` | Set preference data on the team entity | | `setUserPreference` | Set preference data on the user entity | [repo-link]: ../user/slack.md (Link GitHub Repository to Slack Channel) Like queries, mutations can be loaded from files and executed with the `GraphClient`. Here is an example showing how to create a new channel in Slack. Here's the GraphQL file containing the mutation: ```graphql mutation CreateSlackChannel($name: String!) { createSlackChannel(name: $name) { id } } This invokes the mutation from the GraphQL file: await invocation . context . graphClient . mutate ({ name : \"CreateSlackChannel\" , variables : { name : \"random\" }, })","title":"Subscriptions"},{"location":"developer/graphql/#strongly-typed-graphql-queries","text":"One nice side-effect of using GraphQL as the query layer is that you can generate types for use with TypeScript from the schema and your queries, subscriptions, and mutations. To generate types for your externalized GraphQL operations, run npm run gql:gen . This creates a file called types.ts in src/typings/ . Now you can change the earlier query to use those types: import * as graphql from \"./typings/types\" ; //... const result = await invocation . context . graphClient . query < graphql . PushesWithFailedBuilds . Query , graphql . PushesWithFailedBuilds . Variables > ({ name : \"PushesWithFailedBuilds\" , variables : { name : \"demo-service\" }, }); // .... }","title":"Strongly-typed GraphQL queries"},{"location":"developer/http/","text":"Section content not yet populated Sorry, we haven\u2019t written this part of the documentation yet. Will you tell us what questions are important to you? We\u2019re happy to help in the #support channel in Atomist community Slack . You can also contribute to this guide with an issue or pull request on the docs repository .","title":"HTTP Calls in an SDM"},{"location":"developer/inspect/","text":"Evaluate all your code according to your own standards. Code inspections let you locate problems and measure how closely standards are followed. Run them on one repository or all repositories. Run them after every commit, so that developers are notified of the status of the code whenever they work in a repository. Installing an inspection from a Pack Some code inspections are available as part of published SDM functionality. TODO: list some Custom Inspections An inspection looks at a repository and produces some report. It is implemented as a function from Project to an inspection result, plus a separate function to react to these results. You decide what an inspection result contains, how to populate it, and how to react to them. Create your inspection and a command to run it on demand in any project or projects. Then you can add it as an automatic inspection to every commit, if you like. Declare a result type Start by deciding what your inspection wants to say about a repository. For instance, your inspection might look for files with too many lines. Your result might contain the paths of files that have too many lines in them. Here, the type is defined as a string array. export type FilesWithTooManyLines = string []; Create an inspection function The CodeInspection is a function from a project (and optionally, inspection parameters) to an inspection result. The Project is an Atomist abstraction over a repository directory and the files inside it. Your inspection can call functions on the Project to determine the result. For instance, this one gathers all the file paths where the content is over 1000 lines: const InspectFileLengths : CodeInspection < FilesWithTooManyLines , NoParameters > = async ( p : Project ) => { // this sample code returns the paths to TypeScript files with over 1000 lines const longFiles = await gatherFromFiles ( p , \"**/*.ts\" , async f => { const c = await f . getContent (); const lineCount = c . split ( \"\\n\" ). length ; if ( lineCount > 1000 ) { return f . path ; } else { return undefined ; } }); return longFiles . filter ( path => path !== undefined ); } Create a function to react to this result Usually when you run a code inspection, you want to report back to yourself or your team what the results were. Since your inspection returns a custom type, you have to define what to do with it. We need a function that reacts to the inspection results. It takes an input an array of CodeInspectionResult which includes information about the repository that was inspected and the results of the inspection. For instance, the following reaction function sends a message containing the identifying information of the project and a summary of the results: async function onInspectionResults ( results : CodeInspectionResult < FilesWithTooManyLines > [], inv : CommandListenerInvocation ) { const message = results . map ( r => ` ${ r . repoId . owner } / ${ r . repoId . repo } There are ${ r . result . length } files with too many lines` ) . join ( \"\\n\" ); return inv . addressChannels ( message ); } Create a command to run the inspection and react to it Combine the inspection and the reaction into an object, a command registration. The intent is what you\u2019ll type to get Atomist to run the inspection. export const InspectFileLengthsCommand : CodeInspectionRegistration < FilesWithTooManyLines , NoParameters > = { name : \"InspectFileLengths\" , description : \"Files should be under 1000 lines\" , intent : \"inspect file lengths\" , inspection : InspectFileLengths , onInspectionResults , } Register the command on your SDM Finally, teach the SDM about your command. In machine.ts , or wherever you configure your SDM, add sdm . addCodeInspectionCommand ( InspectFileLengthsCommand ); Run the inspection Recompile and restart your SDM. Depending on the context where you run @atomist inspect file lengths , you\u2019ll receive a response for one or many projects. For local mode: run it within a repository directory to inspect one project, or one directory up (within an owner directory) to inspect all repositories under that owner, or anywhere else to inspect all repositories. For team mode, in Slack: address Atomist in a channel linked to a repository to inspect that repository: @atomist inspect file lengths . Or, specify a regular expression of repository names to check them all: @atomist inspect file lengths targets.repos=\".*\" . Create an AutoInspect You may use your inspection to find places in the code that need to change, and then change them. But how will you know when the file lengths creep back up? Make an AutoInspect run on every push. (Or in local mode, on every commit.) Then you can point out when a file has reached 1000 lines. You can point this out with a message, or by failing the goal, or by asking people to push a button to approve the unorthodox file length. Decide what should happen: onInspectionResult What qualifies as a failed inspection? and what should happen when an inspection fails? Decide this in a function from your inspection result type to a PushReactionResponse: \u201cproceed\u201d, \u201cfail\u201d, or \u201crequire approval\u201d. You also get access to an invocation object, in case you want to post a message as well. async function failIfAnyFileIsTooLong ( result : FilesWithTooManyLines , inv : ParametersInvocation < NoParameters > ) { if ( result . length === 0 ) { return PushReactionResponse . proceed ; } await inv . addressChannels ( \"The following files have more than 1000 lines:\\n\" + result . join ( \"\\n\" )); return PushReactionResponse . failGoals ; } AutoInspectRegistration Assemble the inspection and the onInspectionResult into a registration: export const AutoInspectFileLengths : AutoInspectRegistration < FilesWithTooManyLines , NoParameters > = { name : \"AutoInspectFileLengths\" , inspection : inspectFileLengths , onInspectionResult : failIfAnyFileIsTooLong , } AutoInspect goal Finally, register this on your AutoCodeInspection goal: const codeInspection = new AutoCodeInspection (); codeInspection . with ( AutoInspectFileLengths ); Activate your AutoCodeInspection by setting the goal when a push happens. See AutoInspect goal for details.","title":"Code Inspections"},{"location":"developer/inspect/#installing-an-inspection-from-a-pack","text":"Some code inspections are available as part of published SDM functionality. TODO: list some","title":"Installing an inspection from a Pack"},{"location":"developer/inspect/#custom-inspections","text":"An inspection looks at a repository and produces some report. It is implemented as a function from Project to an inspection result, plus a separate function to react to these results. You decide what an inspection result contains, how to populate it, and how to react to them. Create your inspection and a command to run it on demand in any project or projects. Then you can add it as an automatic inspection to every commit, if you like.","title":"Custom Inspections"},{"location":"developer/inspect/#declare-a-result-type","text":"Start by deciding what your inspection wants to say about a repository. For instance, your inspection might look for files with too many lines. Your result might contain the paths of files that have too many lines in them. Here, the type is defined as a string array. export type FilesWithTooManyLines = string [];","title":"Declare a result type"},{"location":"developer/inspect/#create-an-inspection-function","text":"The CodeInspection is a function from a project (and optionally, inspection parameters) to an inspection result. The Project is an Atomist abstraction over a repository directory and the files inside it. Your inspection can call functions on the Project to determine the result. For instance, this one gathers all the file paths where the content is over 1000 lines: const InspectFileLengths : CodeInspection < FilesWithTooManyLines , NoParameters > = async ( p : Project ) => { // this sample code returns the paths to TypeScript files with over 1000 lines const longFiles = await gatherFromFiles ( p , \"**/*.ts\" , async f => { const c = await f . getContent (); const lineCount = c . split ( \"\\n\" ). length ; if ( lineCount > 1000 ) { return f . path ; } else { return undefined ; } }); return longFiles . filter ( path => path !== undefined ); }","title":"Create an inspection function"},{"location":"developer/inspect/#create-a-function-to-react-to-this-result","text":"Usually when you run a code inspection, you want to report back to yourself or your team what the results were. Since your inspection returns a custom type, you have to define what to do with it. We need a function that reacts to the inspection results. It takes an input an array of CodeInspectionResult which includes information about the repository that was inspected and the results of the inspection. For instance, the following reaction function sends a message containing the identifying information of the project and a summary of the results: async function onInspectionResults ( results : CodeInspectionResult < FilesWithTooManyLines > [], inv : CommandListenerInvocation ) { const message = results . map ( r => ` ${ r . repoId . owner } / ${ r . repoId . repo } There are ${ r . result . length } files with too many lines` ) . join ( \"\\n\" ); return inv . addressChannels ( message ); }","title":"Create a function to react to this result"},{"location":"developer/inspect/#create-a-command-to-run-the-inspection-and-react-to-it","text":"Combine the inspection and the reaction into an object, a command registration. The intent is what you\u2019ll type to get Atomist to run the inspection. export const InspectFileLengthsCommand : CodeInspectionRegistration < FilesWithTooManyLines , NoParameters > = { name : \"InspectFileLengths\" , description : \"Files should be under 1000 lines\" , intent : \"inspect file lengths\" , inspection : InspectFileLengths , onInspectionResults , }","title":"Create a command to run the inspection and react to it"},{"location":"developer/inspect/#register-the-command-on-your-sdm","text":"Finally, teach the SDM about your command. In machine.ts , or wherever you configure your SDM, add sdm . addCodeInspectionCommand ( InspectFileLengthsCommand );","title":"Register the command on your SDM"},{"location":"developer/inspect/#run-the-inspection","text":"Recompile and restart your SDM. Depending on the context where you run @atomist inspect file lengths , you\u2019ll receive a response for one or many projects. For local mode: run it within a repository directory to inspect one project, or one directory up (within an owner directory) to inspect all repositories under that owner, or anywhere else to inspect all repositories. For team mode, in Slack: address Atomist in a channel linked to a repository to inspect that repository: @atomist inspect file lengths . Or, specify a regular expression of repository names to check them all: @atomist inspect file lengths targets.repos=\".*\" .","title":"Run the inspection"},{"location":"developer/inspect/#create-an-autoinspect","text":"You may use your inspection to find places in the code that need to change, and then change them. But how will you know when the file lengths creep back up? Make an AutoInspect run on every push. (Or in local mode, on every commit.) Then you can point out when a file has reached 1000 lines. You can point this out with a message, or by failing the goal, or by asking people to push a button to approve the unorthodox file length.","title":"Create an AutoInspect"},{"location":"developer/inspect/#decide-what-should-happen-oninspectionresult","text":"What qualifies as a failed inspection? and what should happen when an inspection fails? Decide this in a function from your inspection result type to a PushReactionResponse: \u201cproceed\u201d, \u201cfail\u201d, or \u201crequire approval\u201d. You also get access to an invocation object, in case you want to post a message as well. async function failIfAnyFileIsTooLong ( result : FilesWithTooManyLines , inv : ParametersInvocation < NoParameters > ) { if ( result . length === 0 ) { return PushReactionResponse . proceed ; } await inv . addressChannels ( \"The following files have more than 1000 lines:\\n\" + result . join ( \"\\n\" )); return PushReactionResponse . failGoals ; }","title":"Decide what should happen: onInspectionResult"},{"location":"developer/inspect/#autoinspectregistration","text":"Assemble the inspection and the onInspectionResult into a registration: export const AutoInspectFileLengths : AutoInspectRegistration < FilesWithTooManyLines , NoParameters > = { name : \"AutoInspectFileLengths\" , inspection : inspectFileLengths , onInspectionResult : failIfAnyFileIsTooLong , }","title":"AutoInspectRegistration"},{"location":"developer/inspect/#autoinspect-goal","text":"Finally, register this on your AutoCodeInspection goal: const codeInspection = new AutoCodeInspection (); codeInspection . with ( AutoInspectFileLengths ); Activate your AutoCodeInspection by setting the goal when a push happens. See AutoInspect goal for details.","title":"AutoInspect goal"},{"location":"developer/local/","text":"When you run an SDM in local mode, it operates in the privacy of your laptop. Everything is open source. This SDM can: run goals in respond to a commit. the SDM can run your tests in the background deploy locally, and be sure that you\u2019re doing manual testing on committed code apply autofixes directly in your repository check code inspections and tell you when you\u2019ve violated them execute commands generate new projects perform transforms on one repository or on many repositories do inspections on one or many repositories Directory structure Section content not yet populated Sorry, we haven\u2019t written this part of the documentation yet. Will you tell us what questions are important to you? We\u2019re happy to help in the #support channel in Atomist community Slack . You can also contribute to this guide with an issue or pull request on the docs repository . Differences from team mode No connection to the Atomist service Push events come from git hooks on each commit Repositories are cloned from the local filesystem Messages go to the terminal running atomist feed (and for commands, also where you ran them) Nothing happens in GitHub, only locally","title":"Local Mode"},{"location":"developer/local/#directory-structure","text":"Section content not yet populated Sorry, we haven\u2019t written this part of the documentation yet. Will you tell us what questions are important to you? We\u2019re happy to help in the #support channel in Atomist community Slack . You can also contribute to this guide with an issue or pull request on the docs repository .","title":"Directory structure"},{"location":"developer/local/#differences-from-team-mode","text":"No connection to the Atomist service Push events come from git hooks on each commit Repositories are cloned from the local filesystem Messages go to the terminal running atomist feed (and for commands, also where you ran them) Nothing happens in GitHub, only locally","title":"Differences from team mode"},{"location":"developer/prerequisites/","text":"You can run a Software Delivery Machine (SDM) locally without any signup or authentication. See the Developer Quick Start to get started. This document describes the prerequisites for running an SDM for your whole team , connecting to your source control manager, chat system, and continuous integration tools. Before you begin developing and running your own software deliver machine (SDM), you need an Atomist account and several other prerequisites. Atomist workspace As part of creating an account with Atomist, you created an Atomist workspace. To run SDMs, you will need the ID of your Atomist workspace. You can find your Atomist workspace ID on your workspace\u2019s settings page in the Atomist web application . Node.js The reference implementation of the Atomist SDM is implemented in TypeScript , a superset of JavaScript . To develop and run it, you must install Node.js. The easiest way to install Node.js is to go to the Node.js web site and follow the installation instructions for your platform. This makes the node and npm programs available on your system. Alternatively, macOS users with Homebrew can install Node.js with the following command: brew install node Once you have node and npm available, it is a good idea to update to the latest version of NPM using the following command. npm install -g npm Git Atomist supports software development using Git and uses the Git command-line tool to perform many of its actions. You must have the Git CLI installed for Atomist tools to function properly. Atomist CLI The Atomist CLI performs several useful functions that are referred to throughout this documentation. Once you have Node.js installed, install the Atomist CLI with the following command: npm install -g @atomist/cli Installation on GNU/Linux On GNU/Linux systems, including when running in a Docker environment, you may need to add the --unsafe-perm=true --allow-root command-line options to the above command to avoid permission errors and successfully install. Atomist API key To start your own SDM, you will need an Atomist API key so the client can properly register with the API. You can generate an Atomist API key on the API key page of the Atomist web application . You will need an Atomist API key in the next section when running configure. Configure There are a few ways you can configure Atomist SDMs. While any of the approaches below will work in any scenario, some approaches are better for some use cases than others. If you are developing an SDM and running it locally on your workstation or laptop, user configuration is likely your best choice. If you are running an SDM on a server in a testing or production environment, you will likely want to use the environment variable approach. Regardless of the approach you take, the minimum information required to successfully start an SDM is an API key and a workspace ID . Depending on the SDM or other client you are trying to run, you may need to provide more configuration values. User configuration If you have a user configuration file on your system, it will be read and merged with any client-specific configuration whenever you start an SDM. In other words, it serves as a base configuration for all SDMs you run on your system. Run the following command to create and persist a user configuration on your local system. atomist config The above command will prompt you for your Atomist API key and workspace ID. The user configuration is a JSON-formatted object saved in the file $HOME/.atomist/client.config.json on Unix-like operating systems including macOS and %USERPROFILE%\\.atomist\\client.config.json on MS Windows operating systems. After running the above command, the contents of the user configuration file will look something like: { \"apiKey\" : \"API_KEY\" , \"workspaceIds\" : [ \"WORKSPACE_ID\" ] } with API_KEY and WORKSPACE_ID replaced with your Atomist API key and workspace ID, respectively. If you are in multiple Atomist workspaces and want to run your SDMs in all of them, simply add all of their workspace IDs to the workspaceIds array in the user configuration file. Environment variable When running an SDM on a server, especially when running in a containerized environment, it is typically better to provide the necessary configuration using environment variables. When an SDM starts up, it will attempt to parse a JSON-formatted configuration object from the ATOMIST_CONFIG environment variable and from the file provided by the ATOMIST_CONFIG_PATH environment variable. For example, to use the ATOMIST_CONFIG environment variable to provide the same configuration as that shown above in the user configuration section, you could run the following commands to set the environment variable and start the client. export ATOMIST_CONFIG='{\"apiKey\":\"API_KEY\",\"workspaceIds\":[\"WORKSPACE_ID\"]}' atomist start Similarly, if you created a file with the same contents as that show above in the user configuration section at /opt/sdm/sdm-config.json , then you tell the SDM to load that file by setting the following environment variable prior to starting the SDM. export ATOMIST_CONFIG_PATH=/opt/sdm/sdm-config.json atomist start If both environment variables are defined, their configuration values are merged with values in the ATOMIST_CONFIG environment variable taking precedence over those defined in the ATOMIST_CONFIG_PATH file. If the user configuration file also exists, its values are also merged in with lower precedence than either environment variable.","title":"Prerequisites"},{"location":"developer/prerequisites/#atomist-workspace","text":"As part of creating an account with Atomist, you created an Atomist workspace. To run SDMs, you will need the ID of your Atomist workspace. You can find your Atomist workspace ID on your workspace\u2019s settings page in the Atomist web application .","title":"Atomist workspace"},{"location":"developer/prerequisites/#nodejs","text":"The reference implementation of the Atomist SDM is implemented in TypeScript , a superset of JavaScript . To develop and run it, you must install Node.js. The easiest way to install Node.js is to go to the Node.js web site and follow the installation instructions for your platform. This makes the node and npm programs available on your system. Alternatively, macOS users with Homebrew can install Node.js with the following command: brew install node Once you have node and npm available, it is a good idea to update to the latest version of NPM using the following command. npm install -g npm","title":"Node.js"},{"location":"developer/prerequisites/#git","text":"Atomist supports software development using Git and uses the Git command-line tool to perform many of its actions. You must have the Git CLI installed for Atomist tools to function properly.","title":"Git"},{"location":"developer/prerequisites/#atomist-cli","text":"The Atomist CLI performs several useful functions that are referred to throughout this documentation. Once you have Node.js installed, install the Atomist CLI with the following command: npm install -g @atomist/cli Installation on GNU/Linux On GNU/Linux systems, including when running in a Docker environment, you may need to add the --unsafe-perm=true --allow-root command-line options to the above command to avoid permission errors and successfully install.","title":"Atomist CLI"},{"location":"developer/prerequisites/#atomist-api-key","text":"To start your own SDM, you will need an Atomist API key so the client can properly register with the API. You can generate an Atomist API key on the API key page of the Atomist web application . You will need an Atomist API key in the next section when running configure.","title":"Atomist API key"},{"location":"developer/prerequisites/#configure","text":"There are a few ways you can configure Atomist SDMs. While any of the approaches below will work in any scenario, some approaches are better for some use cases than others. If you are developing an SDM and running it locally on your workstation or laptop, user configuration is likely your best choice. If you are running an SDM on a server in a testing or production environment, you will likely want to use the environment variable approach. Regardless of the approach you take, the minimum information required to successfully start an SDM is an API key and a workspace ID . Depending on the SDM or other client you are trying to run, you may need to provide more configuration values.","title":"Configure"},{"location":"developer/prerequisites/#user-configuration","text":"If you have a user configuration file on your system, it will be read and merged with any client-specific configuration whenever you start an SDM. In other words, it serves as a base configuration for all SDMs you run on your system. Run the following command to create and persist a user configuration on your local system. atomist config The above command will prompt you for your Atomist API key and workspace ID. The user configuration is a JSON-formatted object saved in the file $HOME/.atomist/client.config.json on Unix-like operating systems including macOS and %USERPROFILE%\\.atomist\\client.config.json on MS Windows operating systems. After running the above command, the contents of the user configuration file will look something like: { \"apiKey\" : \"API_KEY\" , \"workspaceIds\" : [ \"WORKSPACE_ID\" ] } with API_KEY and WORKSPACE_ID replaced with your Atomist API key and workspace ID, respectively. If you are in multiple Atomist workspaces and want to run your SDMs in all of them, simply add all of their workspace IDs to the workspaceIds array in the user configuration file.","title":"User configuration"},{"location":"developer/prerequisites/#environment-variable","text":"When running an SDM on a server, especially when running in a containerized environment, it is typically better to provide the necessary configuration using environment variables. When an SDM starts up, it will attempt to parse a JSON-formatted configuration object from the ATOMIST_CONFIG environment variable and from the file provided by the ATOMIST_CONFIG_PATH environment variable. For example, to use the ATOMIST_CONFIG environment variable to provide the same configuration as that shown above in the user configuration section, you could run the following commands to set the environment variable and start the client. export ATOMIST_CONFIG='{\"apiKey\":\"API_KEY\",\"workspaceIds\":[\"WORKSPACE_ID\"]}' atomist start Similarly, if you created a file with the same contents as that show above in the user configuration section at /opt/sdm/sdm-config.json , then you tell the SDM to load that file by setting the following environment variable prior to starting the SDM. export ATOMIST_CONFIG_PATH=/opt/sdm/sdm-config.json atomist start If both environment variables are defined, their configuration values are merged with values in the ATOMIST_CONFIG environment variable taking precedence over those defined in the ATOMIST_CONFIG_PATH file. If the user configuration file also exists, its values are also merged in with lower precedence than either environment variable.","title":"Environment variable"},{"location":"developer/project/","text":"Section content not yet populated Sorry, we haven\u2019t written this part of the documentation yet. Will you tell us what questions are important to you? We\u2019re happy to help in the #support channel in Atomist community Slack . You can also contribute to this guide with an issue or pull request on the docs repository .","title":"Project"},{"location":"developer/registration/","text":"Registrations on Goals Many of the provided goals accept registrations as specific instructions of what to do. A registration includes a name (for diagnostics), and some specific action (a transform, an inspection, or a listener, depending on the built-in goal). Many registrations also include an optional PushTest , narrowing on particular pushes. Listeners Some actions can be triggered by something other than goals. These listeners can be registered directly on the SDM. Each listener is an asynchronous function from an invocation to a Promise of some type (usually any ). For example, the following listener observes a build, notifying any linked Slack channels of its status: sdm . addBuildListeners ( async br => br . addressChannels ( `Build of ${ br . id . repo } has status ${ br . build . status } ` )); Summary SDM listeners are a layer above GraphQL subscriptions and event handlers that simplify common scenarios, and enable most functionality to be naturally expressed in terms of the problem domain. Listener implementations are also testable. Available Listener Interfaces The following listener interfaces are available: ArtifactListener : Invoked when a new binary has been created BuildListener : Invoked when a build is complete. ChannelLinkListenerInvocation : Invoked when a channel is linked to a repo ClosedIssueListener : Invoked when an issue is closed DeploymentListener : Invoked when a deployment has succeeded FingerprintDifferenceListener : Invoked when a fingerprint has changed GoalsSetListener : Invoked when goals are set on a push NewIssueListener : Invoked when an issue has been created PullRequestListener : Invoked when a pull request is raised RepoCreationListener : Invoked when a repository has been created TagListener : Invoked when a repo is created UpdatedIssueListener : Invoked when an issue has been updated UserJoiningChannelListener : Invoked when a user joins a channel Invocations These objects, passed to listener functions, contain properties useful for learning about the project and for sending messages. As with all good frameworks, we\u2019ve tried to make the API consistent. All listener invocations include at least the following generally useful information: export interface SdmContext { /** * If available, provides a way to address the channel(s) related to this event. * This is usually, but not always, the channels linked to a repo * In local mode, this sends to `atomist feed` * In some cases, such as repo creation or a push to a repo where there is no linked channel, * addressChannels will go to dev/null without error. */ addressChannels : AddressChannels ; /** * Credentials for use with source control hosts such as GitHub * (team mode only) */ credentials : ProjectOperationCredentials ; /** * Context of the Atomist EventHandler invocation. Use to run GraphQL * queries, use the messageClient directly and find * the workspace and correlation id */ context : HandlerContext ; } Most events concern a specific repository, and hence most listener invocations extend RepoContext : export interface RepoContext extends SdmContext { /** * The repo this relates to. Fields include `owner`, `repo`, `sha` and `branch` */ id : RemoteRepoRef ; } Many repo-specific listeners are given access to the repository source, via the Project abstraction: export interface ProjectListenerInvocation extends RepoListenerInvocation { /** * The project to which this event relates. It will have been cloned * prior to this invocation. Modifications made during listener invocation will * not be committed back to the project (although they are acceptable if necessary, for * example to run particular commands against the project). * As well as working with * project files using the Project superinterface, we can use git-related * functionality fro the GitProject subinterface: For example to check * for previous shas. * We can also easily run shell commands against the project using its baseDir. */ project : GitProject ; } The Project interface provides an abstraction to the present repository, with Atomist taking care of Git cloning and (if necessary) writing back any changes via a push. It is abstracted from the file system, making it easy to unit test with mocked repository contents, using the InMemoryProject and InMemoryFile classes. Note The Project API and sophisticated parsing functionality available on top of it is a core Atomist capability. Many events can only be understood in the context of the impacted code, and many actions are achieved by modifying code. Push listeners also have access to the details of the relevant push: export interface PushListenerInvocation extends ProjectListenerInvocation { /** * Information about the push, including repo and commit */ readonly push : OnPushToAnyBranch.Push ; }","title":"Registrations"},{"location":"developer/registration/#registrations-on-goals","text":"Many of the provided goals accept registrations as specific instructions of what to do. A registration includes a name (for diagnostics), and some specific action (a transform, an inspection, or a listener, depending on the built-in goal). Many registrations also include an optional PushTest , narrowing on particular pushes.","title":"Registrations on Goals"},{"location":"developer/registration/#listeners","text":"Some actions can be triggered by something other than goals. These listeners can be registered directly on the SDM. Each listener is an asynchronous function from an invocation to a Promise of some type (usually any ). For example, the following listener observes a build, notifying any linked Slack channels of its status: sdm . addBuildListeners ( async br => br . addressChannels ( `Build of ${ br . id . repo } has status ${ br . build . status } ` )); Summary SDM listeners are a layer above GraphQL subscriptions and event handlers that simplify common scenarios, and enable most functionality to be naturally expressed in terms of the problem domain. Listener implementations are also testable.","title":"Listeners"},{"location":"developer/registration/#available-listener-interfaces","text":"The following listener interfaces are available: ArtifactListener : Invoked when a new binary has been created BuildListener : Invoked when a build is complete. ChannelLinkListenerInvocation : Invoked when a channel is linked to a repo ClosedIssueListener : Invoked when an issue is closed DeploymentListener : Invoked when a deployment has succeeded FingerprintDifferenceListener : Invoked when a fingerprint has changed GoalsSetListener : Invoked when goals are set on a push NewIssueListener : Invoked when an issue has been created PullRequestListener : Invoked when a pull request is raised RepoCreationListener : Invoked when a repository has been created TagListener : Invoked when a repo is created UpdatedIssueListener : Invoked when an issue has been updated UserJoiningChannelListener : Invoked when a user joins a channel","title":"Available Listener Interfaces"},{"location":"developer/registration/#invocations","text":"These objects, passed to listener functions, contain properties useful for learning about the project and for sending messages. As with all good frameworks, we\u2019ve tried to make the API consistent. All listener invocations include at least the following generally useful information: export interface SdmContext { /** * If available, provides a way to address the channel(s) related to this event. * This is usually, but not always, the channels linked to a repo * In local mode, this sends to `atomist feed` * In some cases, such as repo creation or a push to a repo where there is no linked channel, * addressChannels will go to dev/null without error. */ addressChannels : AddressChannels ; /** * Credentials for use with source control hosts such as GitHub * (team mode only) */ credentials : ProjectOperationCredentials ; /** * Context of the Atomist EventHandler invocation. Use to run GraphQL * queries, use the messageClient directly and find * the workspace and correlation id */ context : HandlerContext ; } Most events concern a specific repository, and hence most listener invocations extend RepoContext : export interface RepoContext extends SdmContext { /** * The repo this relates to. Fields include `owner`, `repo`, `sha` and `branch` */ id : RemoteRepoRef ; } Many repo-specific listeners are given access to the repository source, via the Project abstraction: export interface ProjectListenerInvocation extends RepoListenerInvocation { /** * The project to which this event relates. It will have been cloned * prior to this invocation. Modifications made during listener invocation will * not be committed back to the project (although they are acceptable if necessary, for * example to run particular commands against the project). * As well as working with * project files using the Project superinterface, we can use git-related * functionality fro the GitProject subinterface: For example to check * for previous shas. * We can also easily run shell commands against the project using its baseDir. */ project : GitProject ; } The Project interface provides an abstraction to the present repository, with Atomist taking care of Git cloning and (if necessary) writing back any changes via a push. It is abstracted from the file system, making it easy to unit test with mocked repository contents, using the InMemoryProject and InMemoryFile classes. Note The Project API and sophisticated parsing functionality available on top of it is a core Atomist capability. Many events can only be understood in the context of the impacted code, and many actions are achieved by modifying code. Push listeners also have access to the details of the relevant push: export interface PushListenerInvocation extends ProjectListenerInvocation { /** * Information about the push, including repo and commit */ readonly push : OnPushToAnyBranch.Push ; }","title":"Invocations"},{"location":"developer/sdm-concepts/","text":"The Software Delivery Machine, or SDM, is your interface for using Atomist to deliver your software your way, but better. An SDM automates all steps in the flow from project creation to production, and many other actions, using the consistent model provided by the Atomist API for software . Core Concepts An SDM builds on other Atomist core functionality available from global automations, such as Atomist lifecycle messages showing commit, pull request, and other activity through actionable messages in your chat client. GraphQL The Atomist automation API provides you access to the events and data from your development platforms using GraphQL , a widely-used query language and runtime for APIs. You can use GraphQL with the Atomist automation API for: Queries that fetch data directly Subscriptions to register the types of events you want to receive Mutations to change data and make connections WebSockets An Atomist SDM must maintain contact with the API server so that it can receive the events and commands it\u2019s interested in as they occur. SDMs access the Atomist automation API via a WebSocket connection. WebSockets allow the API server to send events and commands to the SDM without constant polling via HTTP calls. The WebSocket connection is initiated by the SDM when it starts up, establishing a persistent two-way communication channel between the SDM and API that is resilient to interruptions in connectivity. Events The heart of Atomist is its event handling. As your code flows from commit through to deployment and beyond, Atomist receives events, correlates the incoming data with its previous knowledge, and invokes your event handlers with rich context. This enables your automations to perform tasks such as: Scanning code for security or quality issues on every push Driving deployments and promotion between environments Performing custom actions on deployment, such as kicking off integration test suites. The Atomist correlated event model also enables Atomist to provide you with visibility throughout the commit to deployment flow, in Slack or through the Atomist web dashboard. See Events for more information. Event handlers subscribe to events using GraphQL subscriptions against the Atomist cortex. The following GraphQL subscribes to completed builds, returning related data such as the last commit and any linked Slack channels: subscription OnBuildComplete { Build { buildId buildUrl compareUrl name status commit { sha message repo { name owner gitHubId allowRebaseMerge channels { name id } } statuses { context description state targetUrl } } } } When using TypeScript (our recommended language), an event handler can subscribe to such events with the benefit of strong typing. For example, this Atomist event handler can respond to the above GraphQL subscription: @EventHandler ( \"Set status on build complete\" , GraphQL . subscriptionFromFile ( \"graphql/subscription/OnBuildComplete.graphql\" )) export class SetStatusOnBuildComplete implements HandleEvent < OnBuildComplete . Subscription > { public async handle ( event : EventFired < OnBuildComplete . Subscription > , ctx : HandlerContext , params : this ) : Promise < HandlerResult > { This underlying GraphQL/event handler infrastructure is generic and powerful. However, many things are better done at a higher level. This project provides a framework above this infrastructure that makes typical tasks far easier, while not preventing you from breaking out into lower level functionality. Listeners We\u2019ll return to push tests shortly, but first let\u2019s consider the SDM listener concept. Push Mappings Let\u2019s now return to push mappings and goal setting. The PushMapping interface is used to decide how to handle pushes. Normally it is used via the DSL we\u2019ve seen. export interface PushMapping < V > { /** * Name of the PushMapping. Must be unique */ readonly name : string ; /** * Compute a value for the given push. Return undefined * if we don't find a mapped value. * Return DoNotSetAnyGoals (null) to shortcut evaluation of the present set of rules, * terminating evaluation and guarantee the return of undefined if we've reached this point. * Only do so if you are sure * that this evaluation must be short circuited if it has reached this point. * If a previous rule has matched, it will still be used. * The value may be static * or computed on demand, depending on the implementation. * @param {PushListenerInvocation} p * @return {Promise<V | undefined | NeverMatch>} */ valueForPush ( p : PushListenerInvocation ) : Promise < V | undefined | NeverMatch > ; } PushMapping is a central interface used in many places. A GoalSetter is a PushMapping that returns Goals . A PushTest is simply a PushMapping that returns boolean . Code Examples Let\u2019s look at some examples of listeners. Issue Creation When a new issue is created, you may want to notify people or perform an action. Listener interfaces NewIssueListener : NewIssueListener Examples The following example notifies any user who raises an issue with insufficient detail in the body, via a direct message in Slack, and provides them with a helpful link to the issue. Note that we make use of the person available via the openedBy field: export async function requestDescription ( inv : NewIssueInvocation ) { if ( ! inv . issue . body || inv . issue . body . length < 10 ) { await inv . context . messageClient . addressUsers ( `Please add a description for new issue ${ inv . issue . number } : _ ${ inv . issue . title } _: ${ inv . id . url } /issues/ ${ inv . issue . number } ` , inv . issue . openedBy . person . chatId . screenName ); } } This is registed with a SoftwareDeliveryMachine instance as follows: sdm . addNewIssueListeners ( requestDescription ) Using the credentials on the NewIssueInvocation , you can easily use the GitHub API to modify the issue, for example correcting spelling errors. Repo Creation We frequently want to respond to the creation of a new repository: For example, we may want to notify people, provision infrastructure, or tag it with GitHub topics based on its contents. Listener interfaces There are two scenarios to consider: The creation of a new repository. RepoCreationListener : RepoCreationListener The first push to a repository, which uses the more generic ProjectListener The second scenario is usually more important, as it is possible to create a repository without any source code or a master branch, which isn\u2019t enough to work with for common actions. Examples The following example publishes a message to the #general channel in Slack when a new repo has been created: export const PublishNewRepo : SdmListener = ( i : ListenerInvocation ) => { return i . context . messageClient . addressChannels ( `A new repo was created: \\` ${ i . id . owner } : ${ i . id . repo } \\`` , \"general\" ); }; Tagging a repo with topics based on its content is a useful action. tagRepo is a convenient function to construct a ProjectListener for this. It tags as an argument a Tagger , which looks at the project content and returns a Tags object. The following example from atomist.config.ts tags Spring Boot repos, using a Tagger from the spring-automation project, in addition to suggesting the addition of a Cloud Foundry manifest, and publishing the repo using the listener previously shown: sdm . addNewRepoWithCodeActions ( tagRepo ( springBootTagger ), suggestAddingCloudFoundryManifest , PublishNewRepo ) CodeActionRegistration interface This registration allows you to react to the code, with information about the changes in the given push. For example, the following function lists changed files to any linked Slack channels for the repo: export const listChangedFiles : PushReactionRegistration = { action ( i : PushImpactListenerInvocation ) { return i . addressChannels ( `Files changed: \\ n ${ i . filesChanged . map ( n => \"- `\" + n + \"`\" ). join ( \"\\n\" ) } ` ); }, name : \"List files changed\" , }; If you don\u2019t have a custom name or PushTest, you can use the following shorthand: export const listChangedFiles = i => i . addressChannels ( `Files changed: \\ n ${ i . filesChanged . map ( n => \"- `\" + n + \"`\" ). join ( \"\\n\" ) } ` ); Add in an SDM definition as follows: sdm . addPushReactions ( listChangedFiles ) If your reaction is essentially a review\u2013for example, it\u2019s associated with a known problem in a particular file location\u2013use a ReviewerRegistration rather than a PushReactionRegistration . Important You must have set a PushReactionGoal for push reactions to be invoked Fingerprints A special kind of push listener relates to fingerprints . Fingerprints are data computed against a push. Think of them as snapshots. Typically they reflect the state of the repository\u2019s source code after the push; they can also take into account other characteristics of the commit. Fingerprinting is valuable because: It enables us to assess the impact of a particular commit, through providing a semantic diff . For example, did the commit change dependencies? Did it change some particularly sensitive files that necessitate closer than usual review? It enables us to understand the evolution of a code base over time. Atomist persists fingerprints, so we can trace over time anything we fingerprint, and report against it. For example, what is happening to code quality metrics over time? Atomist ships some out of the box fingerprints, such as Maven and npm dependency fingerprints. But it\u2019s easy to write your own. Fingerprint registrations are like other listener registrations, specifying a name and PushTest . The following example is the complete code for fingerprinting dependencies specified in a package-lock.json file: export class PackageLockFingerprinter implements FingerprinterRegistration { public readonly name = \"PackageLockFingerprinter\" ; public readonly pushTest : PushTest = IsNode ; public async action ( cri : PushImpactListenerInvocation ) : Promise < FingerprinterResult > { const lockFile = await cri . project . getFile ( \"package-lock.json\" ); if ( ! lockFile ) { return []; } try { const content = await lockFile . getContent (); const json = JSON . parse ( content ); const deps = json . dependencies ; const dstr = JSON . stringify ( deps ); return { name : \"dependencies\" , abbreviation : \"deps\" , version : \"0.1\" , sha : computeShaOf ( dstr ), data : json , }; } catch ( err ) { logger . warn ( \"Unable to compute package-lock.json fingerprint: %s\" , err . message ); return []; } } } Fingerprinters can be added to an SDM as follows: sdm . addFingerprinterRegistrations ( new PackageLockFingerprinter ()); Fingerprinting will only occur if a FingerprintGoal is selected when goals are set. Generators Another important concern is project creation. Consistent project creation is important to governance and provides a way of sharing knowledge across a team. Atomist\u2019s unique take on project generation starts from a seed project \u2013a kind of golden master, that is version controlled using your regular repository hosting solution. A seed project doesn\u2019t need to include template content: It\u2019s a regular project in whatever stack, and Atomist transforms it to be a unique, custom project based on the parameters supplied at the time of project creation. This allows freedom to evolve the seed project with regular development tools. Generators can be registered with an SDM as follows: sdm . addGenerators (() => springBootGenerator ({ ... CommonJavaGeneratorConfig , seedRepo : \"spring-rest-seed\" , intent : \"create spring\" , })) The springBootGenerator function used here is provided in sample-sdm , but it\u2019s easy enough to write your own transformation using the Project API. Here\u2019s most of the code in our real Node generator: export function nodeGenerator ( config : GeneratorConfig , details : Partial < GeneratorCommandDetails < NodeProjectCreationParameters >> = {}) : HandleCommand { return generatorHandler < NodeProjectCreationParameters > ( transformSeed , () => new NodeProjectCreationParameters ( config ), `nodeGenerator- ${ config . seedRepo } ` , { tags : [ \"node\" , \"typescript\" , \"generator\" ], ... details , intent : config.intent , }); } function transformSeed ( params : NodeProjectCreationParameters , ctx : HandlerContext ) { return chainEditors ( updatePackageJsonIdentification ( params . appName , params . target . description , params . version , params . screenName , params . target ), updateReadmeTitle ( params . appName , params . target . description ), ); } You can invoke such a generator from Slack, like this: Note how the repo was automatically tagged with GitHub topics after creation. This was the work of a listener, specified as follows: sdm . addNewRepoWithCodeActions ( tagRepo ( springBootTagger ), ); With Atomist ChatOps supports, you can follow along in a linked channel like this: Note the suggestion to add a Cloud Foundry manifest. This is the work of another listener, which reacts to finding new code in a repo. Listeners and commands such as generators work hand in hand for Atomist. Editors Another core concept is a project editor . An editor is a command that transforms project content. Atomist infrastructure can help persist such transformations through branch commits or pull requests, with clean diffs. A Simple Editor As you\u2019d expect, editors also use th Project API. Here\u2019s an example of a simple editor that takes as a parameter the path of a file to remove from a repository. @Parameters () export class RemoveFileParams { @Parameter () public path : string ; } export const removeFileEditor : HandleCommand = editorCommand < RemoveFileParams > ( () => removeFile , \"remove file\" , RemoveFileParams , { editMode : params => commitToMaster ( `You asked me to remove file ${ params . path } !` ), }); async function removeFile ( p : Project , ctx : HandlerContext , params : RemoveFileParams ) { return p . deleteFile ( params . path ); } Editors can be registered with an SDM as follows: sdm . addEditors ( () => removeFileEditor , ); Dry Run Editors More elaborate editors use helper APIs on top of the Project API such as Atomist\u2019s microgrammar API and ANTLR integration. There\u2019s also an important capability called \u201cdry run editing\u201d: Performing an edit on a branch, and then either raising either a PR or an issue, depending on build success or failure. This allows us to safely apply edits across many repositories. There\u2019s a simple wrapper function to enable this: export const tryToUpgradeSpringBootVersion : HandleCommand = dryRunEditor < UpgradeSpringBootParameters > ( params => setSpringBootVersionEditor ( params . desiredBootVersion ), UpgradeSpringBootParameters , \"boot-upgrade\" , { description : `Upgrade Spring Boot version` , intent : \"try to upgrade Spring Boot\" , }, ); This editor will upgrade the Spring Boot version in one or more projects, then wait to see if the builds succeed. Output will look like this (in the case of success): Tip Dry run editing is another example of how commands and events can work hand in hand with Atomist to provide a uniquely powerful solution. Arbitrary Commands Both generators and editors are special cases of Atomist command handlers , which can be invoked via Slack or HTTP. You can write commands to ensure that anything that needs to be repeated gets done the right way each time, and that the solution isn\u2019t hidden on someone\u2019s machine. Pulling it All Together: The SoftwareDeliveryMachine class Your ideal delivery blueprint spans delivery flow, generators, editors and other commands. All we need is something to pull it together. Your event listeners need to be invoked by Atomist handlers. The SoftwareDeliveryMachine takes care of this, ensuring that the correct handlers are emitted for use in atomist.config.ts , without you needing to worry about the event handler registrations on underlying GraphQL. The SoftwareDeliveryMachine class offers a fluent builder approach to adding command handlers, generators and editors. Example For example: const sdm = createSoftwareDeliveryMachine ( { builder : K8sBuildOnSuccessStatus , deployers : [ K8sStagingDeployOnSuccessStatus , K8sProductionDeployOnSuccessStatus , ], artifactStore , }, whenPushSatisfies ( PushToDefaultBranch , IsMaven , IsSpringBoot , HasK8Spec , PushToPublicRepo ) . setGoals ( HttpServiceGoals ), whenPushSatisfies ( not ( PushFromAtomist ), IsMaven , IsSpringBoot ) . setGoals ( LocalDeploymentGoals ), whenPushSatisfies ( IsMaven , MaterialChangeToJavaRepo ) . setGoals ( LibraryGoals ), whenPushSatisfies ( IsNode ). setGoals ( NpmGoals ), ); sdm . addNewRepoWithCodeActions ( suggestAddingK8sSpec ) . addSupportingCommands (() => addK8sSpec ) . addSupportingEvents (() => NoticeK8sTestDeployCompletion , () => NoticeK8sProdDeployCompletion ) . addEndpointVerificationListeners ( lookFor200OnEndpointRootGet ({ retries : 15 , maxTimeout : 5000 , minTimeout : 3000 , }), ); sdm . addNewIssueListeners ( requestDescription ) . addEditors (() => tryToUpgradeSpringBootVersion ) . addGenerators (() => springBootGenerator ({ seedOwner : \"spring-team\" , seedRepo : \"spring-rest-seed\" , groupId : \"myco\" , })) . addNewRepoWithCodeActions ( tagRepo ( springBootTagger ), suggestAddingCloudFoundryManifest , PublishNewRepo ) . addProjectReviewers ( logReview ) . addPushReactions ( listChangedFiles ) . addFingerprinters ( mavenFingerprinter ) . addDeploymentListeners ( PostToDeploymentsChannel ) . addEndpointVerificationListeners ( LookFor200OnEndpointRootGet ) . addVerifiedDeploymentListeners ( presentPromotionButton ) . addSupersededListeners ( inv => { logger . info ( \"Will undeploy application %j\" , inv . id ); return LocalMavenDeployer . deployer . undeploy ( inv . id ); }) . addSupportingCommands ( () => addCloudFoundryManifest , DescribeStagingAndProd , () => disposeProjectHandler , ) . addSupportingEvents ( OnDryRunBuildComplete ); The SoftwareDeliveryMachine instance will create the necessary Atomist event handlers to export. In atomist.config.ts you can bring them in simply as follows: commands : assembled.commandHandlers , events : assembled.eventHandlers , Plugging in Third Party Tools In addition to the core capabilities of the Atomist platform, an SDM can integrate with third-party tools to execute goals and commands. Integrating CI tools One of the tools you are most likely to integrate is Continuous Integration (CI). For example, you can integrate Jenkins, Travis or Circle CI with Atomist so that these tools are responsible for build. This has potential advantages in terms of scheduling and repeatability of environments. Integrating a CI tool with Atomist is simple. Simply invoke Atomist hooks to send events around build and artifact creation. If integrating CI tools, we recommend the following: CI tools are great for building and generating artifacts. They are often abused as a PaaS for bash . If you find your CI usage has you programming in bash or YML, consider whether invoking such operations from Atomist event handlers might be a better model. Use Atomist generators to create your CI files, and Atomist editors to keep them in synch, minimizing inconsistency. Integrating with Static Analysis Tools Any tool that runs on code, such as Checkstyle, can easily be integrated. If the tool doesn\u2019t have a Node API (which Checkstyle doesn\u2019t as it\u2019s written in Java), you can invoke it via Node spawn , as Node excels at working with child processes. Advanced Push Rules Computed Values You can use computed boolean values or the results of synchronous or asynchronous functions returning boolean in the DSL, making it possible to bring in any state you wish. For example: whenPushSatisfies ( IsMaven , HasSpringBootApplicationClass , deploymentsToday < 25 ) . itMeans ( \"Not tired of deploying Spring apps yet\" ) . setGoals ( LocalDeploymentGoals ), Decision Trees You can write decision trees in push rules or other push mappings. These can be nested to arbitrary depth, and can use computed state. For example: let count = 0 ; const pm : PushMapping < Goals > = given < Goals > ( IsNode ) // Compute a value we'll use later . init (() => count = 0 ) . itMeans ( \"node\" ) . then ( given < Goals > ( IsExpress ). itMeans ( \"express\" ) . compute (() => count ++ ) // Go into tree branch rule set . then ( whenPushSatisfies ( count > 0 ). itMeans ( \"nope\" ). setGoals ( NoGoals ), whenPushSatisfies ( TruePushTest ). itMeans ( \"yes\" ). setGoals ( HttpServiceGoals ), ), );","title":"SDM Concepts"},{"location":"developer/sdm-concepts/#core-concepts","text":"An SDM builds on other Atomist core functionality available from global automations, such as Atomist lifecycle messages showing commit, pull request, and other activity through actionable messages in your chat client.","title":"Core Concepts"},{"location":"developer/sdm-concepts/#graphql","text":"The Atomist automation API provides you access to the events and data from your development platforms using GraphQL , a widely-used query language and runtime for APIs. You can use GraphQL with the Atomist automation API for: Queries that fetch data directly Subscriptions to register the types of events you want to receive Mutations to change data and make connections","title":"GraphQL"},{"location":"developer/sdm-concepts/#websockets","text":"An Atomist SDM must maintain contact with the API server so that it can receive the events and commands it\u2019s interested in as they occur. SDMs access the Atomist automation API via a WebSocket connection. WebSockets allow the API server to send events and commands to the SDM without constant polling via HTTP calls. The WebSocket connection is initiated by the SDM when it starts up, establishing a persistent two-way communication channel between the SDM and API that is resilient to interruptions in connectivity.","title":"WebSockets"},{"location":"developer/sdm-concepts/#events","text":"The heart of Atomist is its event handling. As your code flows from commit through to deployment and beyond, Atomist receives events, correlates the incoming data with its previous knowledge, and invokes your event handlers with rich context. This enables your automations to perform tasks such as: Scanning code for security or quality issues on every push Driving deployments and promotion between environments Performing custom actions on deployment, such as kicking off integration test suites. The Atomist correlated event model also enables Atomist to provide you with visibility throughout the commit to deployment flow, in Slack or through the Atomist web dashboard. See Events for more information. Event handlers subscribe to events using GraphQL subscriptions against the Atomist cortex. The following GraphQL subscribes to completed builds, returning related data such as the last commit and any linked Slack channels: subscription OnBuildComplete { Build { buildId buildUrl compareUrl name status commit { sha message repo { name owner gitHubId allowRebaseMerge channels { name id } } statuses { context description state targetUrl } } } } When using TypeScript (our recommended language), an event handler can subscribe to such events with the benefit of strong typing. For example, this Atomist event handler can respond to the above GraphQL subscription: @EventHandler ( \"Set status on build complete\" , GraphQL . subscriptionFromFile ( \"graphql/subscription/OnBuildComplete.graphql\" )) export class SetStatusOnBuildComplete implements HandleEvent < OnBuildComplete . Subscription > { public async handle ( event : EventFired < OnBuildComplete . Subscription > , ctx : HandlerContext , params : this ) : Promise < HandlerResult > { This underlying GraphQL/event handler infrastructure is generic and powerful. However, many things are better done at a higher level. This project provides a framework above this infrastructure that makes typical tasks far easier, while not preventing you from breaking out into lower level functionality.","title":"Events"},{"location":"developer/sdm-concepts/#listeners","text":"We\u2019ll return to push tests shortly, but first let\u2019s consider the SDM listener concept.","title":"Listeners"},{"location":"developer/sdm-concepts/#push-mappings","text":"Let\u2019s now return to push mappings and goal setting. The PushMapping interface is used to decide how to handle pushes. Normally it is used via the DSL we\u2019ve seen. export interface PushMapping < V > { /** * Name of the PushMapping. Must be unique */ readonly name : string ; /** * Compute a value for the given push. Return undefined * if we don't find a mapped value. * Return DoNotSetAnyGoals (null) to shortcut evaluation of the present set of rules, * terminating evaluation and guarantee the return of undefined if we've reached this point. * Only do so if you are sure * that this evaluation must be short circuited if it has reached this point. * If a previous rule has matched, it will still be used. * The value may be static * or computed on demand, depending on the implementation. * @param {PushListenerInvocation} p * @return {Promise<V | undefined | NeverMatch>} */ valueForPush ( p : PushListenerInvocation ) : Promise < V | undefined | NeverMatch > ; } PushMapping is a central interface used in many places. A GoalSetter is a PushMapping that returns Goals . A PushTest is simply a PushMapping that returns boolean .","title":"Push Mappings"},{"location":"developer/sdm-concepts/#code-examples","text":"Let\u2019s look at some examples of listeners.","title":"Code Examples"},{"location":"developer/sdm-concepts/#issue-creation","text":"When a new issue is created, you may want to notify people or perform an action.","title":"Issue Creation"},{"location":"developer/sdm-concepts/#listener-interfaces","text":"NewIssueListener : NewIssueListener","title":"Listener interfaces"},{"location":"developer/sdm-concepts/#examples","text":"The following example notifies any user who raises an issue with insufficient detail in the body, via a direct message in Slack, and provides them with a helpful link to the issue. Note that we make use of the person available via the openedBy field: export async function requestDescription ( inv : NewIssueInvocation ) { if ( ! inv . issue . body || inv . issue . body . length < 10 ) { await inv . context . messageClient . addressUsers ( `Please add a description for new issue ${ inv . issue . number } : _ ${ inv . issue . title } _: ${ inv . id . url } /issues/ ${ inv . issue . number } ` , inv . issue . openedBy . person . chatId . screenName ); } } This is registed with a SoftwareDeliveryMachine instance as follows: sdm . addNewIssueListeners ( requestDescription ) Using the credentials on the NewIssueInvocation , you can easily use the GitHub API to modify the issue, for example correcting spelling errors.","title":"Examples"},{"location":"developer/sdm-concepts/#repo-creation","text":"We frequently want to respond to the creation of a new repository: For example, we may want to notify people, provision infrastructure, or tag it with GitHub topics based on its contents.","title":"Repo Creation"},{"location":"developer/sdm-concepts/#listener-interfaces_1","text":"There are two scenarios to consider: The creation of a new repository. RepoCreationListener : RepoCreationListener The first push to a repository, which uses the more generic ProjectListener The second scenario is usually more important, as it is possible to create a repository without any source code or a master branch, which isn\u2019t enough to work with for common actions.","title":"Listener interfaces"},{"location":"developer/sdm-concepts/#examples_1","text":"The following example publishes a message to the #general channel in Slack when a new repo has been created: export const PublishNewRepo : SdmListener = ( i : ListenerInvocation ) => { return i . context . messageClient . addressChannels ( `A new repo was created: \\` ${ i . id . owner } : ${ i . id . repo } \\`` , \"general\" ); }; Tagging a repo with topics based on its content is a useful action. tagRepo is a convenient function to construct a ProjectListener for this. It tags as an argument a Tagger , which looks at the project content and returns a Tags object. The following example from atomist.config.ts tags Spring Boot repos, using a Tagger from the spring-automation project, in addition to suggesting the addition of a Cloud Foundry manifest, and publishing the repo using the listener previously shown: sdm . addNewRepoWithCodeActions ( tagRepo ( springBootTagger ), suggestAddingCloudFoundryManifest , PublishNewRepo )","title":"Examples"},{"location":"developer/sdm-concepts/#codeactionregistration-interface","text":"This registration allows you to react to the code, with information about the changes in the given push. For example, the following function lists changed files to any linked Slack channels for the repo: export const listChangedFiles : PushReactionRegistration = { action ( i : PushImpactListenerInvocation ) { return i . addressChannels ( `Files changed: \\ n ${ i . filesChanged . map ( n => \"- `\" + n + \"`\" ). join ( \"\\n\" ) } ` ); }, name : \"List files changed\" , }; If you don\u2019t have a custom name or PushTest, you can use the following shorthand: export const listChangedFiles = i => i . addressChannels ( `Files changed: \\ n ${ i . filesChanged . map ( n => \"- `\" + n + \"`\" ). join ( \"\\n\" ) } ` ); Add in an SDM definition as follows: sdm . addPushReactions ( listChangedFiles ) If your reaction is essentially a review\u2013for example, it\u2019s associated with a known problem in a particular file location\u2013use a ReviewerRegistration rather than a PushReactionRegistration . Important You must have set a PushReactionGoal for push reactions to be invoked","title":"CodeActionRegistration interface"},{"location":"developer/sdm-concepts/#fingerprints","text":"A special kind of push listener relates to fingerprints . Fingerprints are data computed against a push. Think of them as snapshots. Typically they reflect the state of the repository\u2019s source code after the push; they can also take into account other characteristics of the commit. Fingerprinting is valuable because: It enables us to assess the impact of a particular commit, through providing a semantic diff . For example, did the commit change dependencies? Did it change some particularly sensitive files that necessitate closer than usual review? It enables us to understand the evolution of a code base over time. Atomist persists fingerprints, so we can trace over time anything we fingerprint, and report against it. For example, what is happening to code quality metrics over time? Atomist ships some out of the box fingerprints, such as Maven and npm dependency fingerprints. But it\u2019s easy to write your own. Fingerprint registrations are like other listener registrations, specifying a name and PushTest . The following example is the complete code for fingerprinting dependencies specified in a package-lock.json file: export class PackageLockFingerprinter implements FingerprinterRegistration { public readonly name = \"PackageLockFingerprinter\" ; public readonly pushTest : PushTest = IsNode ; public async action ( cri : PushImpactListenerInvocation ) : Promise < FingerprinterResult > { const lockFile = await cri . project . getFile ( \"package-lock.json\" ); if ( ! lockFile ) { return []; } try { const content = await lockFile . getContent (); const json = JSON . parse ( content ); const deps = json . dependencies ; const dstr = JSON . stringify ( deps ); return { name : \"dependencies\" , abbreviation : \"deps\" , version : \"0.1\" , sha : computeShaOf ( dstr ), data : json , }; } catch ( err ) { logger . warn ( \"Unable to compute package-lock.json fingerprint: %s\" , err . message ); return []; } } } Fingerprinters can be added to an SDM as follows: sdm . addFingerprinterRegistrations ( new PackageLockFingerprinter ()); Fingerprinting will only occur if a FingerprintGoal is selected when goals are set.","title":"Fingerprints"},{"location":"developer/sdm-concepts/#generators","text":"Another important concern is project creation. Consistent project creation is important to governance and provides a way of sharing knowledge across a team. Atomist\u2019s unique take on project generation starts from a seed project \u2013a kind of golden master, that is version controlled using your regular repository hosting solution. A seed project doesn\u2019t need to include template content: It\u2019s a regular project in whatever stack, and Atomist transforms it to be a unique, custom project based on the parameters supplied at the time of project creation. This allows freedom to evolve the seed project with regular development tools. Generators can be registered with an SDM as follows: sdm . addGenerators (() => springBootGenerator ({ ... CommonJavaGeneratorConfig , seedRepo : \"spring-rest-seed\" , intent : \"create spring\" , })) The springBootGenerator function used here is provided in sample-sdm , but it\u2019s easy enough to write your own transformation using the Project API. Here\u2019s most of the code in our real Node generator: export function nodeGenerator ( config : GeneratorConfig , details : Partial < GeneratorCommandDetails < NodeProjectCreationParameters >> = {}) : HandleCommand { return generatorHandler < NodeProjectCreationParameters > ( transformSeed , () => new NodeProjectCreationParameters ( config ), `nodeGenerator- ${ config . seedRepo } ` , { tags : [ \"node\" , \"typescript\" , \"generator\" ], ... details , intent : config.intent , }); } function transformSeed ( params : NodeProjectCreationParameters , ctx : HandlerContext ) { return chainEditors ( updatePackageJsonIdentification ( params . appName , params . target . description , params . version , params . screenName , params . target ), updateReadmeTitle ( params . appName , params . target . description ), ); } You can invoke such a generator from Slack, like this: Note how the repo was automatically tagged with GitHub topics after creation. This was the work of a listener, specified as follows: sdm . addNewRepoWithCodeActions ( tagRepo ( springBootTagger ), ); With Atomist ChatOps supports, you can follow along in a linked channel like this: Note the suggestion to add a Cloud Foundry manifest. This is the work of another listener, which reacts to finding new code in a repo. Listeners and commands such as generators work hand in hand for Atomist.","title":"Generators"},{"location":"developer/sdm-concepts/#editors","text":"Another core concept is a project editor . An editor is a command that transforms project content. Atomist infrastructure can help persist such transformations through branch commits or pull requests, with clean diffs.","title":"Editors"},{"location":"developer/sdm-concepts/#a-simple-editor","text":"As you\u2019d expect, editors also use th Project API. Here\u2019s an example of a simple editor that takes as a parameter the path of a file to remove from a repository. @Parameters () export class RemoveFileParams { @Parameter () public path : string ; } export const removeFileEditor : HandleCommand = editorCommand < RemoveFileParams > ( () => removeFile , \"remove file\" , RemoveFileParams , { editMode : params => commitToMaster ( `You asked me to remove file ${ params . path } !` ), }); async function removeFile ( p : Project , ctx : HandlerContext , params : RemoveFileParams ) { return p . deleteFile ( params . path ); } Editors can be registered with an SDM as follows: sdm . addEditors ( () => removeFileEditor , );","title":"A Simple Editor"},{"location":"developer/sdm-concepts/#dry-run-editors","text":"More elaborate editors use helper APIs on top of the Project API such as Atomist\u2019s microgrammar API and ANTLR integration. There\u2019s also an important capability called \u201cdry run editing\u201d: Performing an edit on a branch, and then either raising either a PR or an issue, depending on build success or failure. This allows us to safely apply edits across many repositories. There\u2019s a simple wrapper function to enable this: export const tryToUpgradeSpringBootVersion : HandleCommand = dryRunEditor < UpgradeSpringBootParameters > ( params => setSpringBootVersionEditor ( params . desiredBootVersion ), UpgradeSpringBootParameters , \"boot-upgrade\" , { description : `Upgrade Spring Boot version` , intent : \"try to upgrade Spring Boot\" , }, ); This editor will upgrade the Spring Boot version in one or more projects, then wait to see if the builds succeed. Output will look like this (in the case of success): Tip Dry run editing is another example of how commands and events can work hand in hand with Atomist to provide a uniquely powerful solution.","title":"Dry Run Editors"},{"location":"developer/sdm-concepts/#arbitrary-commands","text":"Both generators and editors are special cases of Atomist command handlers , which can be invoked via Slack or HTTP. You can write commands to ensure that anything that needs to be repeated gets done the right way each time, and that the solution isn\u2019t hidden on someone\u2019s machine.","title":"Arbitrary Commands"},{"location":"developer/sdm-concepts/#pulling-it-all-together-the-softwaredeliverymachine-class","text":"Your ideal delivery blueprint spans delivery flow, generators, editors and other commands. All we need is something to pull it together. Your event listeners need to be invoked by Atomist handlers. The SoftwareDeliveryMachine takes care of this, ensuring that the correct handlers are emitted for use in atomist.config.ts , without you needing to worry about the event handler registrations on underlying GraphQL. The SoftwareDeliveryMachine class offers a fluent builder approach to adding command handlers, generators and editors.","title":"Pulling it All Together: The SoftwareDeliveryMachine class"},{"location":"developer/sdm-concepts/#example","text":"For example: const sdm = createSoftwareDeliveryMachine ( { builder : K8sBuildOnSuccessStatus , deployers : [ K8sStagingDeployOnSuccessStatus , K8sProductionDeployOnSuccessStatus , ], artifactStore , }, whenPushSatisfies ( PushToDefaultBranch , IsMaven , IsSpringBoot , HasK8Spec , PushToPublicRepo ) . setGoals ( HttpServiceGoals ), whenPushSatisfies ( not ( PushFromAtomist ), IsMaven , IsSpringBoot ) . setGoals ( LocalDeploymentGoals ), whenPushSatisfies ( IsMaven , MaterialChangeToJavaRepo ) . setGoals ( LibraryGoals ), whenPushSatisfies ( IsNode ). setGoals ( NpmGoals ), ); sdm . addNewRepoWithCodeActions ( suggestAddingK8sSpec ) . addSupportingCommands (() => addK8sSpec ) . addSupportingEvents (() => NoticeK8sTestDeployCompletion , () => NoticeK8sProdDeployCompletion ) . addEndpointVerificationListeners ( lookFor200OnEndpointRootGet ({ retries : 15 , maxTimeout : 5000 , minTimeout : 3000 , }), ); sdm . addNewIssueListeners ( requestDescription ) . addEditors (() => tryToUpgradeSpringBootVersion ) . addGenerators (() => springBootGenerator ({ seedOwner : \"spring-team\" , seedRepo : \"spring-rest-seed\" , groupId : \"myco\" , })) . addNewRepoWithCodeActions ( tagRepo ( springBootTagger ), suggestAddingCloudFoundryManifest , PublishNewRepo ) . addProjectReviewers ( logReview ) . addPushReactions ( listChangedFiles ) . addFingerprinters ( mavenFingerprinter ) . addDeploymentListeners ( PostToDeploymentsChannel ) . addEndpointVerificationListeners ( LookFor200OnEndpointRootGet ) . addVerifiedDeploymentListeners ( presentPromotionButton ) . addSupersededListeners ( inv => { logger . info ( \"Will undeploy application %j\" , inv . id ); return LocalMavenDeployer . deployer . undeploy ( inv . id ); }) . addSupportingCommands ( () => addCloudFoundryManifest , DescribeStagingAndProd , () => disposeProjectHandler , ) . addSupportingEvents ( OnDryRunBuildComplete ); The SoftwareDeliveryMachine instance will create the necessary Atomist event handlers to export. In atomist.config.ts you can bring them in simply as follows: commands : assembled.commandHandlers , events : assembled.eventHandlers ,","title":"Example"},{"location":"developer/sdm-concepts/#plugging-in-third-party-tools","text":"In addition to the core capabilities of the Atomist platform, an SDM can integrate with third-party tools to execute goals and commands.","title":"Plugging in Third Party Tools"},{"location":"developer/sdm-concepts/#integrating-ci-tools","text":"One of the tools you are most likely to integrate is Continuous Integration (CI). For example, you can integrate Jenkins, Travis or Circle CI with Atomist so that these tools are responsible for build. This has potential advantages in terms of scheduling and repeatability of environments. Integrating a CI tool with Atomist is simple. Simply invoke Atomist hooks to send events around build and artifact creation. If integrating CI tools, we recommend the following: CI tools are great for building and generating artifacts. They are often abused as a PaaS for bash . If you find your CI usage has you programming in bash or YML, consider whether invoking such operations from Atomist event handlers might be a better model. Use Atomist generators to create your CI files, and Atomist editors to keep them in synch, minimizing inconsistency.","title":"Integrating CI tools"},{"location":"developer/sdm-concepts/#integrating-with-static-analysis-tools","text":"Any tool that runs on code, such as Checkstyle, can easily be integrated. If the tool doesn\u2019t have a Node API (which Checkstyle doesn\u2019t as it\u2019s written in Java), you can invoke it via Node spawn , as Node excels at working with child processes.","title":"Integrating with Static Analysis Tools"},{"location":"developer/sdm-concepts/#advanced-push-rules","text":"","title":"Advanced Push Rules"},{"location":"developer/sdm-concepts/#computed-values","text":"You can use computed boolean values or the results of synchronous or asynchronous functions returning boolean in the DSL, making it possible to bring in any state you wish. For example: whenPushSatisfies ( IsMaven , HasSpringBootApplicationClass , deploymentsToday < 25 ) . itMeans ( \"Not tired of deploying Spring apps yet\" ) . setGoals ( LocalDeploymentGoals ),","title":"Computed Values"},{"location":"developer/sdm-concepts/#decision-trees","text":"You can write decision trees in push rules or other push mappings. These can be nested to arbitrary depth, and can use computed state. For example: let count = 0 ; const pm : PushMapping < Goals > = given < Goals > ( IsNode ) // Compute a value we'll use later . init (() => count = 0 ) . itMeans ( \"node\" ) . then ( given < Goals > ( IsExpress ). itMeans ( \"express\" ) . compute (() => count ++ ) // Go into tree branch rule set . then ( whenPushSatisfies ( count > 0 ). itMeans ( \"nope\" ). setGoals ( NoGoals ), whenPushSatisfies ( TruePushTest ). itMeans ( \"yes\" ). setGoals ( HttpServiceGoals ), ), );","title":"Decision Trees"},{"location":"developer/sdm-construct/","text":"Section content not yet populated Sorry, we haven\u2019t written this part of the documentation yet. Will you tell us what questions are important to you? We\u2019re happy to help in the #support channel in Atomist community Slack . You can also contribute to this guide with an issue or pull request on the docs repository .","title":"Adding Functionality"},{"location":"developer/sdm-debug/","text":"Section content not yet populated Sorry, we haven\u2019t written this part of the documentation yet. Will you tell us what questions are important to you? We\u2019re happy to help in the #support channel in Atomist community Slack . You can also contribute to this guide with an issue or pull request on the docs repository .","title":"Debugging an SDM"},{"location":"developer/sdm-deploy/","text":"You can run Software Delivery Machines (SDMs) in many different environments, ranging from your laptop or data center to Platform-as-a-Service offerings like Heroku and Pivotal Cloud Foundry. Atomist also supports running SDMs as Docker containers. This allows you to operate them in Kubernetes clusters or Google Container Engine, for example. This document explains various ways to run SDMs. Running locally The easiest way to run an SDM is to start it up on your local development machine. Running the SDM locally is extremely helpful during development of your automations. You can debug commands and event handlers using local development tools like Visual Studio Code and Google Chrome. You can iterate rapidly because there is no deployment and only a minimal build process. To connect to the Atomist API and respond to events in your team and commands in your team chat, start the SDM by running the following commands: npm run compile && npm start Note The SDM requires an open internet connection to https://automation.atomist.com to successfully register event subscriptions and commands. To receive only your personal commits and commands that you initiate in your terminal, run in local mode: npm run compile && npm start --local Production When running in a production environment, you typically want to avoid NPM and run Node.js directly to ensure signals get delivered properly and you can provide guidance to Node.js\u2019s memory management subsystem. Here\u2019s an example startup command for production environments: node $NODE_DEBUG_OPTION --trace-warnings --expose_gc --optimize_for_size \\ --always_compact --max_old_space_size=384 node_modules/.bin/atomist start See node --help and node --v8-options for more detail on these options. Cloud Foundry To push your SDM to an instance of Pivotal Cloud Foundry, you need an account on the instance you want to target and you must have the Cloud Foundry CLI installed. For detailed information about the deployment process, consult the Cloud Foundry documentation . A push to Cloud Foundry needs some additional metadata in your project. First you need to create a manifest.yml file in the root of your SDM project: applications : - name : my-sdm command : node node_modules/.bin/atm-start memory : 128M routes : - route : my-sdm.mycompany.net buildpack : https://github.com/cloudfoundry/nodejs-buildpack env : SUPPRESS_NO_CONFIG_WARNING : true NODE_ENV : production Note Technically a manifest.yml is not required but it makes things simpler. Next add an \"engines\" top-level entry to your package.json file: \"engines\" : { \"node\" : \"8.x.x\" , \"npm\" : \"5.x.x\" } Finally, start the deployment with: cf push Docker Shipping your SDM as a Docker image allows you to package up all required tools and dependencies. This is especially useful if you plan on reusing existing scripts or command line tools in your automations. To set up a Docker image build, you need a Dockerfile . Read the documentation on building Docker images for more details. FROM node:8 # Create application directory RUN mkdir -p /app WORKDIR /app # Install application dependencies COPY package.json /app/ RUN npm install # Bundle app source COPY . /app ENV SUPPRESS_NO_CONFIG_WARNING true ENV NPM_CONFIG_LOGLEVEL warn ENV NODE_ENV production EXPOSE 2866 CMD [ \"npm\", \"start\" ] Be sure to create .dockerignore to exclude files and directories that aren\u2019t needed at runtime. /node_modules With the Dockerfile in place, you can now start the actual Docker build: npm run compile && \\ docker build . -t lifecycle-automation:0.1.0 After the build completes successfully, you can push the image to any Docker image registry: docker push lifecycle-automation:0.1.0","title":"Deploying your SDM"},{"location":"developer/sdm-deploy/#running-locally","text":"The easiest way to run an SDM is to start it up on your local development machine. Running the SDM locally is extremely helpful during development of your automations. You can debug commands and event handlers using local development tools like Visual Studio Code and Google Chrome. You can iterate rapidly because there is no deployment and only a minimal build process. To connect to the Atomist API and respond to events in your team and commands in your team chat, start the SDM by running the following commands: npm run compile && npm start Note The SDM requires an open internet connection to https://automation.atomist.com to successfully register event subscriptions and commands. To receive only your personal commits and commands that you initiate in your terminal, run in local mode: npm run compile && npm start --local","title":"Running locally"},{"location":"developer/sdm-deploy/#production","text":"When running in a production environment, you typically want to avoid NPM and run Node.js directly to ensure signals get delivered properly and you can provide guidance to Node.js\u2019s memory management subsystem. Here\u2019s an example startup command for production environments: node $NODE_DEBUG_OPTION --trace-warnings --expose_gc --optimize_for_size \\ --always_compact --max_old_space_size=384 node_modules/.bin/atomist start See node --help and node --v8-options for more detail on these options.","title":"Production"},{"location":"developer/sdm-deploy/#cloud-foundry","text":"To push your SDM to an instance of Pivotal Cloud Foundry, you need an account on the instance you want to target and you must have the Cloud Foundry CLI installed. For detailed information about the deployment process, consult the Cloud Foundry documentation . A push to Cloud Foundry needs some additional metadata in your project. First you need to create a manifest.yml file in the root of your SDM project: applications : - name : my-sdm command : node node_modules/.bin/atm-start memory : 128M routes : - route : my-sdm.mycompany.net buildpack : https://github.com/cloudfoundry/nodejs-buildpack env : SUPPRESS_NO_CONFIG_WARNING : true NODE_ENV : production Note Technically a manifest.yml is not required but it makes things simpler. Next add an \"engines\" top-level entry to your package.json file: \"engines\" : { \"node\" : \"8.x.x\" , \"npm\" : \"5.x.x\" } Finally, start the deployment with: cf push","title":"Cloud Foundry"},{"location":"developer/sdm-deploy/#docker","text":"Shipping your SDM as a Docker image allows you to package up all required tools and dependencies. This is especially useful if you plan on reusing existing scripts or command line tools in your automations. To set up a Docker image build, you need a Dockerfile . Read the documentation on building Docker images for more details. FROM node:8 # Create application directory RUN mkdir -p /app WORKDIR /app # Install application dependencies COPY package.json /app/ RUN npm install # Bundle app source COPY . /app ENV SUPPRESS_NO_CONFIG_WARNING true ENV NPM_CONFIG_LOGLEVEL warn ENV NODE_ENV production EXPOSE 2866 CMD [ \"npm\", \"start\" ] Be sure to create .dockerignore to exclude files and directories that aren\u2019t needed at runtime. /node_modules With the Dockerfile in place, you can now start the actual Docker build: npm run compile && \\ docker build . -t lifecycle-automation:0.1.0 After the build completes successfully, you can push the image to any Docker image registry: docker push lifecycle-automation:0.1.0","title":"Docker"},{"location":"developer/sdm/","text":"The software delivery machine is a service that runs automations in response to events like pushes and builds. See architecture for a high-level view. This section documents creating, building, and running an SDM, discusses each part of the SDM lifecycle, and details the structure and organization of a typical SDM project. To get started in local mode , make sure you have: Git Installed Node.js Installed the Atomist CLI Before you run in team mode , check the prerequisites page. Creating an SDM project There are a few ways to create a new SDM project. We suggest using the blank-sdm project as a seed for your project. You can do this locally with the Atomist CLI: atomist create sdm Choose \u201cblank\u201d to start with an empty SDM, or \u201cspring\u201d to start with an SDM that does useful things for Java Spring services. Slack If your team uses the Atomist service and Slack integration, you can create your very own SDM project using the Atomist bot. This will make a repository in your version control (GitHub, BitBucket, or GitLab). You can run this bot command with the following message to the Atomist bot: @atomist create sdm The bot will ask you where you want to create it and what you want to name it. Once creation is complete, the bot will tell you where you can find it. GitHub If you prefer the manual route, fixing up the project metadata yourself, you can always fork the blank-sdm project on GitHub. Building an SDM SDM projects are written in TypeScript and run on Node.js . Building an SDM is the same as any standard TypeScript or JavaScript project. First you install the project\u2019s dependencies: npm install then build the project, linting the TypeScript, compiling the TypeScript into JavaScript, generating other required files, and running tests: npm run build Looking at the code Section content not yet populated Sorry, we haven\u2019t written this part of the documentation yet. Will you tell us what questions are important to you? We\u2019re happy to help in the #support channel in Atomist community Slack . You can also contribute to this guide with an issue or pull request on the docs repository . Starting an SDM There are a few different ways to start the SDM, depending on how you are running it. If you are running the SDM locally, you can use the standard NPM start command. npm start If you are writing your own SDMs, you probably want a more responsive testing environment, having the client restart any time you make changes to the source code. This development flow is available with the autostart command. npm run autostart When you deploy your SDM to production, check the recommendations under Deploying your SDM . SDM process lifecycle The SDM lifecycle will be familiar to those developing persistent applications. Authentication - When the SDM starts up, it connects to the Atomist API and authenticates using the API key you have provided in your configuration file. Registration - Once your identity has been established, the client registers its automations, i.e., the bot commands it provides and the events it wants to receive, with the Atomist workspaces specified in your configuration. If Atomist does not recognize your workspace ID or the provided API key is not connected to any member of that workspace, registration will fail and the SDM will exit with an unsuccessful status. Listening - After authentication and registration is completed successfully, the WebSocket connection is established and the client begins listening for incoming messages from the API: bot commands and events fired. Shutdown - When the client receives a shutdown signal, typically SIGINT delivered by the PaaS or Ctrl-C , it de-registers with the API and gracefully shuts down. SDM state An SDM, once registered, will continue to receive all the events it has subscribed to until shuts down or one of the following scenarios occurs. Multiple identical SDMs register If another client with the same name and version (typically obtained from the package.json \u201cname\u201d and \u201cversion\u201d properties) registers, then all of the registered identical SDMs will receive the events in a round-robin fashion. Each event will only be sent to one of the identical SDMs. This allows you to horizontally scale. A different version registers If another SDM having the same name but different version registers, it will begin receiving all of the events for the client and any previously registered versions cease receiving events. Note that no version comparisons are done: the last registration wins . If the new client has registered with a policy of \u201cephemeral\u201d and the prior client was registered with a policy of \u201cdurable\u201d, then when the new client shuts down, events again be sent to the \u201cdurable\u201d registration clients. The reason for this logic is to allow for production, testing, and local use to all coexist without taking the same action multiple times. For example, if you are running an SDM in production but want to test something, you can run it locally, steal events for a bit, kill the local process, and then traffic will return to the production instance. If you want the same events to be sent to multiple SDMs, just make sure the SDMs have different names. Custom Ingestion Any custom ingestion types can only be registered once within an Atomist workspace. Therefore it is recommended to register these in a dedicated API client. Project structure SDM projects are organized and behave like any standard TypeScript project. package.json The package.json file defines the metadata and dependencies for the project. In addition, this file defines the standard \u201cNPM package scripts\u201d, i.e., npm run commands, typically available in Node.js projects. Here\u2019s a summary of the NPM package scripts available in most SDM projects. Command Description npm install install all the required packages npm run autostart run, refreshing when files change npm run autotest run tests every time files change npm run build lint, compile, and test npm run clean remove stray compiled JavaScript files and build directory npm run compile compile all TypeScript into JavaScript npm run lint run tslint against the TypeScript npm run lint:fix run tslint --fix against the TypeScript npm start start the SDM npm test run tests lib The lib directory contains the TypeScript source code. atomist.config.ts The lib/atomist.config.ts file contains project-specific configuration. This is the starting point when you want to look at what this SDM might do. lib/graphql The graphql directory contains .graphql files defining your GraphQL queries, subscriptions, and mutations. This directory is optional, as you can define your GraphQL in strings within the source code. That said, it is recommended that you define your GraphQL in .graphql files so you can realize the full benefit of its type bindings in TypeScript. lib/typings The lib/typings directory contains the auto-generated TypeScript types for your GraphQL queries, subscriptions, and mutations. node_modules The node_modules directory contains all the project dependencies, as defined in the package.json and installed by NPM. scripts The scripts directory contains various ancillary scripts. For example, this directory might have scripts for building the project on CI, publishing the project as an Node.js package, and publishing the project\u2019s TypeDoc . test The test directory contains the automated tests for the project. Typically these are unit tests written using mocha and power-assert . Stop Control-C will stop the client. Restart it after code changes with atomist start again.","title":"About the SDM"},{"location":"developer/sdm/#creating-an-sdm-project","text":"There are a few ways to create a new SDM project. We suggest using the blank-sdm project as a seed for your project. You can do this locally with the Atomist CLI: atomist create sdm Choose \u201cblank\u201d to start with an empty SDM, or \u201cspring\u201d to start with an SDM that does useful things for Java Spring services.","title":"Creating an SDM project"},{"location":"developer/sdm/#slack","text":"If your team uses the Atomist service and Slack integration, you can create your very own SDM project using the Atomist bot. This will make a repository in your version control (GitHub, BitBucket, or GitLab). You can run this bot command with the following message to the Atomist bot: @atomist create sdm The bot will ask you where you want to create it and what you want to name it. Once creation is complete, the bot will tell you where you can find it.","title":"Slack"},{"location":"developer/sdm/#github","text":"If you prefer the manual route, fixing up the project metadata yourself, you can always fork the blank-sdm project on GitHub.","title":"GitHub"},{"location":"developer/sdm/#building-an-sdm","text":"SDM projects are written in TypeScript and run on Node.js . Building an SDM is the same as any standard TypeScript or JavaScript project. First you install the project\u2019s dependencies: npm install then build the project, linting the TypeScript, compiling the TypeScript into JavaScript, generating other required files, and running tests: npm run build","title":"Building an SDM"},{"location":"developer/sdm/#looking-at-the-code","text":"Section content not yet populated Sorry, we haven\u2019t written this part of the documentation yet. Will you tell us what questions are important to you? We\u2019re happy to help in the #support channel in Atomist community Slack . You can also contribute to this guide with an issue or pull request on the docs repository .","title":"Looking at the code"},{"location":"developer/sdm/#starting-an-sdm","text":"There are a few different ways to start the SDM, depending on how you are running it. If you are running the SDM locally, you can use the standard NPM start command. npm start If you are writing your own SDMs, you probably want a more responsive testing environment, having the client restart any time you make changes to the source code. This development flow is available with the autostart command. npm run autostart When you deploy your SDM to production, check the recommendations under Deploying your SDM .","title":"Starting an SDM"},{"location":"developer/sdm/#sdm-process-lifecycle","text":"The SDM lifecycle will be familiar to those developing persistent applications. Authentication - When the SDM starts up, it connects to the Atomist API and authenticates using the API key you have provided in your configuration file. Registration - Once your identity has been established, the client registers its automations, i.e., the bot commands it provides and the events it wants to receive, with the Atomist workspaces specified in your configuration. If Atomist does not recognize your workspace ID or the provided API key is not connected to any member of that workspace, registration will fail and the SDM will exit with an unsuccessful status. Listening - After authentication and registration is completed successfully, the WebSocket connection is established and the client begins listening for incoming messages from the API: bot commands and events fired. Shutdown - When the client receives a shutdown signal, typically SIGINT delivered by the PaaS or Ctrl-C , it de-registers with the API and gracefully shuts down.","title":"SDM process lifecycle"},{"location":"developer/sdm/#sdm-state","text":"An SDM, once registered, will continue to receive all the events it has subscribed to until shuts down or one of the following scenarios occurs.","title":"SDM state"},{"location":"developer/sdm/#multiple-identical-sdms-register","text":"If another client with the same name and version (typically obtained from the package.json \u201cname\u201d and \u201cversion\u201d properties) registers, then all of the registered identical SDMs will receive the events in a round-robin fashion. Each event will only be sent to one of the identical SDMs. This allows you to horizontally scale.","title":"Multiple identical SDMs register"},{"location":"developer/sdm/#a-different-version-registers","text":"If another SDM having the same name but different version registers, it will begin receiving all of the events for the client and any previously registered versions cease receiving events. Note that no version comparisons are done: the last registration wins . If the new client has registered with a policy of \u201cephemeral\u201d and the prior client was registered with a policy of \u201cdurable\u201d, then when the new client shuts down, events again be sent to the \u201cdurable\u201d registration clients. The reason for this logic is to allow for production, testing, and local use to all coexist without taking the same action multiple times. For example, if you are running an SDM in production but want to test something, you can run it locally, steal events for a bit, kill the local process, and then traffic will return to the production instance. If you want the same events to be sent to multiple SDMs, just make sure the SDMs have different names. Custom Ingestion Any custom ingestion types can only be registered once within an Atomist workspace. Therefore it is recommended to register these in a dedicated API client.","title":"A different version registers"},{"location":"developer/sdm/#project-structure","text":"SDM projects are organized and behave like any standard TypeScript project.","title":"Project structure"},{"location":"developer/sdm/#packagejson","text":"The package.json file defines the metadata and dependencies for the project. In addition, this file defines the standard \u201cNPM package scripts\u201d, i.e., npm run commands, typically available in Node.js projects. Here\u2019s a summary of the NPM package scripts available in most SDM projects. Command Description npm install install all the required packages npm run autostart run, refreshing when files change npm run autotest run tests every time files change npm run build lint, compile, and test npm run clean remove stray compiled JavaScript files and build directory npm run compile compile all TypeScript into JavaScript npm run lint run tslint against the TypeScript npm run lint:fix run tslint --fix against the TypeScript npm start start the SDM npm test run tests","title":"package.json"},{"location":"developer/sdm/#lib","text":"The lib directory contains the TypeScript source code.","title":"lib"},{"location":"developer/sdm/#atomistconfigts","text":"The lib/atomist.config.ts file contains project-specific configuration. This is the starting point when you want to look at what this SDM might do.","title":"atomist.config.ts"},{"location":"developer/sdm/#libgraphql","text":"The graphql directory contains .graphql files defining your GraphQL queries, subscriptions, and mutations. This directory is optional, as you can define your GraphQL in strings within the source code. That said, it is recommended that you define your GraphQL in .graphql files so you can realize the full benefit of its type bindings in TypeScript.","title":"lib/graphql"},{"location":"developer/sdm/#libtypings","text":"The lib/typings directory contains the auto-generated TypeScript types for your GraphQL queries, subscriptions, and mutations.","title":"lib/typings"},{"location":"developer/sdm/#node_modules","text":"The node_modules directory contains all the project dependencies, as defined in the package.json and installed by NPM.","title":"node_modules"},{"location":"developer/sdm/#scripts","text":"The scripts directory contains various ancillary scripts. For example, this directory might have scripts for building the project on CI, publishing the project as an Node.js package, and publishing the project\u2019s TypeDoc .","title":"scripts"},{"location":"developer/sdm/#test","text":"The test directory contains the automated tests for the project. Typically these are unit tests written using mocha and power-assert .","title":"test"},{"location":"developer/sdm/#stop","text":"Control-C will stop the client. Restart it after code changes with atomist start again.","title":"Stop"},{"location":"developer/security/","text":"Section content not yet populated Sorry, we haven\u2019t written this part of the documentation yet. Will you tell us what questions are important to you? We\u2019re happy to help in the #support channel in Atomist community Slack . You can also contribute to this guide with an issue or pull request on the docs repository .","title":"Security Model"},{"location":"developer/set-goals/","text":"The most important higher level SDM functionality relates to what happens on a push to a repository. An SDM allows you to process a push in any way you choose, but typically you want it to initiate a delivery flow. An SDM allows you to set goals on push. Goals correspond to the actions that make up a delivery flow, such as build and deployment. Goals are not necessarily sequential\u2013some may be executed in parallel\u2013but certain goals, such as deployment, have preconditions (goals that must have previously completed successfully). Contributing goals Goals are set using rules , which are typically expressed in a simple internal DSL. For example, the following rules use PushTest predicates such as ToDefaultBranch and IsMaven to determine what goals to set for incoming pushes: Push Tests Push test predicates are easy to write using the Atomist API. For example: export const IsMaven : PredicatePushTest = predicatePushTest ( \"Is Maven\" , async p => !! ( await p . getFile ( \"pom.xml\" ))); Goal Sets Section content not yet populated Sorry, we haven\u2019t written this part of the documentation yet. Will you tell us what questions are important to you? We\u2019re happy to help in the #support channel in Atomist community Slack . You can also contribute to this guide with an issue or pull request on the docs repository . Preconditions Section content not yet populated Sorry, we haven\u2019t written this part of the documentation yet. Will you tell us what questions are important to you? We\u2019re happy to help in the #support channel in Atomist community Slack . You can also contribute to this guide with an issue or pull request on the docs repository .","title":"Setting Goals"},{"location":"developer/set-goals/#contributing-goals","text":"Goals are set using rules , which are typically expressed in a simple internal DSL. For example, the following rules use PushTest predicates such as ToDefaultBranch and IsMaven to determine what goals to set for incoming pushes:","title":"Contributing goals"},{"location":"developer/set-goals/#push-tests","text":"Push test predicates are easy to write using the Atomist API. For example: export const IsMaven : PredicatePushTest = predicatePushTest ( \"Is Maven\" , async p => !! ( await p . getFile ( \"pom.xml\" )));","title":"Push Tests"},{"location":"developer/set-goals/#goal-sets","text":"Section content not yet populated Sorry, we haven\u2019t written this part of the documentation yet. Will you tell us what questions are important to you? We\u2019re happy to help in the #support channel in Atomist community Slack . You can also contribute to this guide with an issue or pull request on the docs repository .","title":"Goal Sets"},{"location":"developer/set-goals/#preconditions","text":"Section content not yet populated Sorry, we haven\u2019t written this part of the documentation yet. Will you tell us what questions are important to you? We\u2019re happy to help in the #support channel in Atomist community Slack . You can also contribute to this guide with an issue or pull request on the docs repository .","title":"Preconditions"},{"location":"developer/slack/","text":"Atomist supports sending rich , actionable and updatable Slack messages. Messages can be sent by an event handler or a command handler. Rich messages take full advantage of Slack\u2019s native message formatting capabilities Actionable messages contain buttons and menus that trigger new commands on behalf of the user who clicked them Updatable messages can be rewritten with new content over time in response to new events and actions. This helps reduce the number of messages from the Atomist bot in a Slack channel. Here\u2019s an example of a message with different Attachments and Actions from the Atomist open source community Slack workspace. If you\u2019re not familiar with the main concepts of Slack message formatting, you may want to read Slack\u2019s documentation before you read the following sections. MessageClient interface Let\u2019s take a look at the MessageClient interface. export interface MessageClient { respond ( msg : string | SlackMessage , options? : MessageOptions ) : Promise < any > ; addressUsers ( msg : string | SlackMessage , userNames : string | string [], options? : MessageOptions ) : Promise < any > ; addressChannels ( msg : string | SlackMessage , channelNames : string | string [], options? : MessageOptions ) : Promise < any > ; ... } The MessageClient provides access to methods for sending messages to Slack. It allows you to address messages to users or channels by name or to simply send a response message. Generally the MessageClient is available from the HandlerContext parameter to the handle method of command and event handlers. Response messages A response message is a message that is sent while handling a request to run a certain command; they can therefore only be sent by command handlers. Use the respond method to sending a response message. The Atomist platform takes care of delivering the message into the right conversation in Slack. The following example shows how to send a response message from a command handler. export class HelloWorld implements HandleCommand { public handle ( ctx : HandlerContext ) : Promise < HandlerResult > { return ctx . messageClient . respond ( \"Hello from Atomist\" ) . then (() => Success , failure ); } } User and channel messages Address messages to users by calling the addressUsers method, providing one or more names of Slack users. To send a message to one or more channels, call the addressChannels method. Note If you want to send a direct message to a user in your Slack workspace, use the addressUsers method with the user name of the recipient. Here is an example of sending a simple message into the #general channel of your Slack workspace: export class HelloWorld implements HandleCommand { public handle ( ctx : HandlerContext ) : Promise < HandlerResult > { return ctx . messageClient . addressChannels ( \"Hello from Atomist\" , \"general\" ) . then (() => Success , failure ); } } In this example, you are sending the message only to the #general channel. It is possible to send the same message into more than one channel by simply providing an array of channel names to the addressChannels method. The same works for addressUsers . Formatting messages In the previous section you saw how to address and send messages to Slack. This section covers formatting simple and complex Slack messages. It also demonstrates how to add buttons and menus to messages. Simple messages The addressUsers , addressChannels and respond methods accept a string message as first argument. A simple string message can still have some basic formatting. Here are a couple of examples of simple messages: Code Output messageClient.respond(\"This is a plain message\"); This is a plan message messageClient.respond(\"This some *bold* text\"); This is some bold text messageClient.respond(\"This some _italics_ text\"); This is some italics text messageClient.respond(\"Some multiline\\ntext\"); Some multiline text More details on Slack text formatting can be found their the documentation . Rich messages For more complex, rich messages, Atomist provides the SlackMessage type as part of the @atomist/slack-messages NPM module. The SlackMessage type can have Attachments and Actions . More details on those concepts can be found in the Slack documentation . In order to create a formatted Slack message, simply build an instance of SlackMessage with all desired properties. Here is an example: import * as slack from \"@atomist/slack-messages\" ; const message : slack.SlackMessage = { attachments : [{ fallback : \"How to filter by parent or ancestor directory with sysdig\" , author_name : \"Janek Bogucki\" , author_link : \"https://stackoverflow.com/users/148440/janek-bogucki\" , author_icon : \"https://www.gravatar.com/avatar/5ccd05d83049593205406ac74eacb323?s=128&d=identicon&r=PG\" , title : \"How to filter by parent or ancestor directory withsysdig\" , title_link : \"https://stackoverflow.com/questions/41827350/how-to-filter-by-parent-or-ancestor-directory-with-sysdig\" , thumb_url : \"https://slack-imgs.com/?c=1&o1=wi75.he75&url=https%3A%2F%2Fcdn.sstatic.net%2FSites%2Fstackoverflow%2Fimg%2Fapple-touch-icon%402.png%3Fv%3D73d79a89bded\" , footer : \"file, sysdig\" , ts : 1485258115 }, { fallback : \"Show more...\" , title : \"Show more...\" , title_link : \"http://stackoverflow.com/search?order=desc&sort=relevance&q=atomist\" }] }; Once the SlackMessage is created you can send it via the MessageClient : ctx . messageClient . respond ( message ); This renders the following in Slack: Adding message buttons In the previous section you saw how rich messages can be created and posted to Slack. Now you\u2019ll see how to turn this message into an actionable message by adding a button to it. With Atomist, it\u2019s easy to bind Slack action buttons to command handlers. Such a binding consists of three parts: the specification of the button as required by Slack, a reference to the command handler , and optional parameters that should be pre-populated when invoking the command. The button specification is defined by Slack in the field guide . Here is an example of a button with a confirmation pop-up: import { ButtonSpecification } from \"@atomist/sdm\" ; const buttonSpec : ButtonSpecification = { text : \"Search Again\" , confirm : { title : \"Search Again?\" , text : \"Do you really want to run the search again?\" , dismiss_text : \"No\" , ok_text : \"Yes\" }, }; With the following, you\u2019re preparing a command handler and its parameter to be bound to the button. This example uses the SearchStackOverflow command handler from the Atomist blog series . const handler = new SearchStackOverflow (); handler . q = \"atomist\" ; Now that you have the ButtonSpecification and the command handler, you can bring this all together into a Slack message button and send the message. Create the action button by calling the buttonForCommand function, passing the ButtonSpecification and the command handler instance: import { buttonForCommand } from \"@atomist/sdm\" ; const message : slack.SlackMessage = { attachments : [{ // ... }, { fallback : \"Show more...\" , title : \"Show more...\" , title_link : \"http://stackoverflow.com/search?order=desc&sort=relevance&q=atomist\" , actions : [ buttonForCommand ( buttonSpec , handler ), ], }], }; return ctx . messageClient . respond ( message ) . then (() => Success , failure ); Adding message menus Message menus are very similar to message buttons in the way they are created and added to the message. The main difference is that menus are defined with a MenuSpecification instead of a ButtonSpecification . Besides the name of the menu, a MenuSpecification allows you to define menu options and option groups. See the following example: import { MenuSpecification } from \"@atomist/sdm\" ; const menuSpec : MenuSpecification = { text : \"Issue Labels\" , options : [{ text : \"Bug\" , value : \"bug\" , }, { text : \"Enhancement\" , value : \"enhancement\" , }, { text : \"Invalid\" , value : \"invalid\" , }], }; const message : slack.SlackMessage = { attachments : [{ // ... actions : [ menuForCommand ( menuSpec , handler , \"label\" ), ], }], }; To create the menu, menuForCommand is called with the menu details, the reference to the command handler and the name of the parameter on the command handler that the selected value of the menu should be bound to; in this example, the value of the option will be bound to the label parameter. Message options With MessageOptions actionable Slack message can be turned into updatable messages; the MessageOptions interface provides important options to handle and tune message updates and rewrites in Slack. The following section describes the properties on the MessageOptions interface and what they can be used for. But first, here is the interface: export interface MessageOptions { /** * Unique message id per channel and workspace. This is required * if you wish to re-write a message at a later time. */ id? : string ; /** * Timestamp of the message. The timestamp needs to be * sortable lexicographically. Should be in milliseconds and * defaults to Date.now(). * * This is only applicable if id is set too. */ ts? : number ; /** * Time to live for a posted message. If ts + ttl of the * existing message with ts is < as a new incoming message * with the same id, the message will be re-written. */ ttl? : number ; /** * If update_only is given, this message will only be posted * if a previous message with the same id exists. */ post ?: \"update_only\" | \"always\" ; } The id property uniquely identifies a message in a channel or direct message. It therefore must be unique in the scope of a channel or direct message. ts specifies the time in milliseconds of the message. If not set, it defaults to the current time. This property is important to maintain correct order of messages: the Atomist bot will not post a message with a ts if there is a message for the same id but a later ts already in the channel or direct message. ttl or time-to-live defines the amount of time in milliseconds that a message can be updated, after which a new instance of the message is posted to the bottom of the Slack stream. So, when a message is received by the bot, it compares the ts + ttl of the existing message with ts of the new message; if ts + ttl is smaller, a new message ia posted to the bottom of the Slack stream and the existing message is not rewritten. As long ts + ttl is greater then ts of the new message, the existing message will be overwritten. Lastly, the post property specifies whether a message should be posted only if it is an update to a previously posted message with the same id . If post === \"always\" , the message is always posted as a new message and never rewrites a previous message. will never rewrite a previous message.","title":"Chat Messages"},{"location":"developer/slack/#messageclient-interface","text":"Let\u2019s take a look at the MessageClient interface. export interface MessageClient { respond ( msg : string | SlackMessage , options? : MessageOptions ) : Promise < any > ; addressUsers ( msg : string | SlackMessage , userNames : string | string [], options? : MessageOptions ) : Promise < any > ; addressChannels ( msg : string | SlackMessage , channelNames : string | string [], options? : MessageOptions ) : Promise < any > ; ... } The MessageClient provides access to methods for sending messages to Slack. It allows you to address messages to users or channels by name or to simply send a response message. Generally the MessageClient is available from the HandlerContext parameter to the handle method of command and event handlers.","title":"MessageClient interface"},{"location":"developer/slack/#response-messages","text":"A response message is a message that is sent while handling a request to run a certain command; they can therefore only be sent by command handlers. Use the respond method to sending a response message. The Atomist platform takes care of delivering the message into the right conversation in Slack. The following example shows how to send a response message from a command handler. export class HelloWorld implements HandleCommand { public handle ( ctx : HandlerContext ) : Promise < HandlerResult > { return ctx . messageClient . respond ( \"Hello from Atomist\" ) . then (() => Success , failure ); } }","title":"Response messages"},{"location":"developer/slack/#user-and-channel-messages","text":"Address messages to users by calling the addressUsers method, providing one or more names of Slack users. To send a message to one or more channels, call the addressChannels method. Note If you want to send a direct message to a user in your Slack workspace, use the addressUsers method with the user name of the recipient. Here is an example of sending a simple message into the #general channel of your Slack workspace: export class HelloWorld implements HandleCommand { public handle ( ctx : HandlerContext ) : Promise < HandlerResult > { return ctx . messageClient . addressChannels ( \"Hello from Atomist\" , \"general\" ) . then (() => Success , failure ); } } In this example, you are sending the message only to the #general channel. It is possible to send the same message into more than one channel by simply providing an array of channel names to the addressChannels method. The same works for addressUsers .","title":"User and channel messages"},{"location":"developer/slack/#formatting-messages","text":"In the previous section you saw how to address and send messages to Slack. This section covers formatting simple and complex Slack messages. It also demonstrates how to add buttons and menus to messages.","title":"Formatting messages"},{"location":"developer/slack/#simple-messages","text":"The addressUsers , addressChannels and respond methods accept a string message as first argument. A simple string message can still have some basic formatting. Here are a couple of examples of simple messages: Code Output messageClient.respond(\"This is a plain message\"); This is a plan message messageClient.respond(\"This some *bold* text\"); This is some bold text messageClient.respond(\"This some _italics_ text\"); This is some italics text messageClient.respond(\"Some multiline\\ntext\"); Some multiline text More details on Slack text formatting can be found their the documentation .","title":"Simple messages"},{"location":"developer/slack/#rich-messages","text":"For more complex, rich messages, Atomist provides the SlackMessage type as part of the @atomist/slack-messages NPM module. The SlackMessage type can have Attachments and Actions . More details on those concepts can be found in the Slack documentation . In order to create a formatted Slack message, simply build an instance of SlackMessage with all desired properties. Here is an example: import * as slack from \"@atomist/slack-messages\" ; const message : slack.SlackMessage = { attachments : [{ fallback : \"How to filter by parent or ancestor directory with sysdig\" , author_name : \"Janek Bogucki\" , author_link : \"https://stackoverflow.com/users/148440/janek-bogucki\" , author_icon : \"https://www.gravatar.com/avatar/5ccd05d83049593205406ac74eacb323?s=128&d=identicon&r=PG\" , title : \"How to filter by parent or ancestor directory withsysdig\" , title_link : \"https://stackoverflow.com/questions/41827350/how-to-filter-by-parent-or-ancestor-directory-with-sysdig\" , thumb_url : \"https://slack-imgs.com/?c=1&o1=wi75.he75&url=https%3A%2F%2Fcdn.sstatic.net%2FSites%2Fstackoverflow%2Fimg%2Fapple-touch-icon%402.png%3Fv%3D73d79a89bded\" , footer : \"file, sysdig\" , ts : 1485258115 }, { fallback : \"Show more...\" , title : \"Show more...\" , title_link : \"http://stackoverflow.com/search?order=desc&sort=relevance&q=atomist\" }] }; Once the SlackMessage is created you can send it via the MessageClient : ctx . messageClient . respond ( message ); This renders the following in Slack:","title":"Rich messages"},{"location":"developer/slack/#adding-message-buttons","text":"In the previous section you saw how rich messages can be created and posted to Slack. Now you\u2019ll see how to turn this message into an actionable message by adding a button to it. With Atomist, it\u2019s easy to bind Slack action buttons to command handlers. Such a binding consists of three parts: the specification of the button as required by Slack, a reference to the command handler , and optional parameters that should be pre-populated when invoking the command. The button specification is defined by Slack in the field guide . Here is an example of a button with a confirmation pop-up: import { ButtonSpecification } from \"@atomist/sdm\" ; const buttonSpec : ButtonSpecification = { text : \"Search Again\" , confirm : { title : \"Search Again?\" , text : \"Do you really want to run the search again?\" , dismiss_text : \"No\" , ok_text : \"Yes\" }, }; With the following, you\u2019re preparing a command handler and its parameter to be bound to the button. This example uses the SearchStackOverflow command handler from the Atomist blog series . const handler = new SearchStackOverflow (); handler . q = \"atomist\" ; Now that you have the ButtonSpecification and the command handler, you can bring this all together into a Slack message button and send the message. Create the action button by calling the buttonForCommand function, passing the ButtonSpecification and the command handler instance: import { buttonForCommand } from \"@atomist/sdm\" ; const message : slack.SlackMessage = { attachments : [{ // ... }, { fallback : \"Show more...\" , title : \"Show more...\" , title_link : \"http://stackoverflow.com/search?order=desc&sort=relevance&q=atomist\" , actions : [ buttonForCommand ( buttonSpec , handler ), ], }], }; return ctx . messageClient . respond ( message ) . then (() => Success , failure );","title":"Adding message buttons"},{"location":"developer/slack/#adding-message-menus","text":"Message menus are very similar to message buttons in the way they are created and added to the message. The main difference is that menus are defined with a MenuSpecification instead of a ButtonSpecification . Besides the name of the menu, a MenuSpecification allows you to define menu options and option groups. See the following example: import { MenuSpecification } from \"@atomist/sdm\" ; const menuSpec : MenuSpecification = { text : \"Issue Labels\" , options : [{ text : \"Bug\" , value : \"bug\" , }, { text : \"Enhancement\" , value : \"enhancement\" , }, { text : \"Invalid\" , value : \"invalid\" , }], }; const message : slack.SlackMessage = { attachments : [{ // ... actions : [ menuForCommand ( menuSpec , handler , \"label\" ), ], }], }; To create the menu, menuForCommand is called with the menu details, the reference to the command handler and the name of the parameter on the command handler that the selected value of the menu should be bound to; in this example, the value of the option will be bound to the label parameter.","title":"Adding message menus"},{"location":"developer/slack/#message-options","text":"With MessageOptions actionable Slack message can be turned into updatable messages; the MessageOptions interface provides important options to handle and tune message updates and rewrites in Slack. The following section describes the properties on the MessageOptions interface and what they can be used for. But first, here is the interface: export interface MessageOptions { /** * Unique message id per channel and workspace. This is required * if you wish to re-write a message at a later time. */ id? : string ; /** * Timestamp of the message. The timestamp needs to be * sortable lexicographically. Should be in milliseconds and * defaults to Date.now(). * * This is only applicable if id is set too. */ ts? : number ; /** * Time to live for a posted message. If ts + ttl of the * existing message with ts is < as a new incoming message * with the same id, the message will be re-written. */ ttl? : number ; /** * If update_only is given, this message will only be posted * if a previous message with the same id exists. */ post ?: \"update_only\" | \"always\" ; } The id property uniquely identifies a message in a channel or direct message. It therefore must be unique in the scope of a channel or direct message. ts specifies the time in milliseconds of the message. If not set, it defaults to the current time. This property is important to maintain correct order of messages: the Atomist bot will not post a message with a ts if there is a message for the same id but a later ts already in the channel or direct message. ttl or time-to-live defines the amount of time in milliseconds that a message can be updated, after which a new instance of the message is posted to the bottom of the Slack stream. So, when a message is received by the bot, it compares the ts + ttl of the existing message with ts of the new message; if ts + ttl is smaller, a new message ia posted to the bottom of the Slack stream and the existing message is not rewritten. As long ts + ttl is greater then ts of the new message, the existing message will be overwritten. Lastly, the post property specifies whether a message should be posted only if it is an update to a previously posted message with the same id . If post === \"always\" , the message is always posted as a new message and never rewrites a previous message. will never rewrite a previous message.","title":"Message options"},{"location":"developer/team/","text":"Section content not yet populated Sorry, we haven\u2019t written this part of the documentation yet. Will you tell us what questions are important to you? We\u2019re happy to help in the #support channel in Atomist community Slack . You can also contribute to this guide with an issue or pull request on the docs repository .","title":"Team Mode"},{"location":"developer/transform/","text":"As developers, we change code. When we know exactly how we want to change the code, we can automate that. Compared to doing it by hand, automation is consistent and repeatable. Atomist gives us the superpower to change code on demand, in one project or hundreds, and in response to events. These changes become commits, branches, or pull requests. Begin with a Code Transform: a function that acts on a project. You write this part, and test it with unit tests. Turn that into a command to run on demand, then an Autofix to run on every push. This page shows how to: Create a code transform that runs on-demand Require parameters to your code transform Customize the automated pull request Make Atomist wait for a build to succeed before creating the pull request Make Atomist merge the PR automatically when a build succeeds After that, you might want to make your code transform into an Autofix . Create a code transform Code transforms are functions that receive the project as an input and changes the content of the project as a result. Assume we want to add an Apache licence file to the project. The transform would retrieve the license content and add a LICENSE file with that content. export const AddApacheLicenseFileTransform : CodeTransform < NoParameters > = async ( p : Project ) => { const httpClient = DefaultHttpClientFactory . create (); const license = await httpClient . exchange ( \"https://www.apache.org/licenses/LICENSE-2.0.txt\" ); return p . addFile ( \"LICENSE\" , license . body as string ); }; See also: HTTP calls in an SDM the Project interface Creating a command for a transform A code transform can be called through various means. One of those means is directly through issuing a command. This command needs to be defined and the transform needs to be referenced in that definition. export const AddApacheLicenseFile : CodeTransformRegistration < NoParameters > = { transform : AddApacheLicenseFileTransform , name : \"add apache license file\" , description : `Add Apache 2.0 license file` , intent : [ \"add apache license file\" , \"add license file\" ], }; Each intent acts as an alias for invoking the command. The description is going to be the title of an automatic pull request. The transform\u2019s name will appear in the branch. See also: CodeTransformRegistration API doc Adding the transform command to the SDM Tell the SDM about the command. In order to achieve this you need to register the command with the SDM. In your SDM definition where you have access to the SDM instance, add the following registration: sdm . addCodeTransformCommand ( AddApacheLicenseFile ); See also: Adding functionality to your SDM Calling the command Local To test your command, run your SDM in local mode and then atomist start --local then, in a separate terminal, change directory to one of your repositories under your Atomist project root (usually $HOME/atomist). Then: atomist add apache license file Atomist will create a new branch with the changed code on it. List all your branches to find it: git branch Team When you run your SDM in team mode , your command will be available in chat. Go to a channel associated with a repository , and talk to the Atomist bot: @atomist add apache license file Atomist will create a branch and apply the code transform on that branch. It will also create a pull request for the commits generated by that branch. By default, the name of the pull request will be the description of the code transform. See also: Invoking commands Adding parameters to the code transform command Sometimes you need additional input after issuing the command to transform a certain piece of code. Say that we wish to make the license file transformation a bit more flexible and allow of different types of licences. First we need to define the data structure that will hold the parameters. @Parameters () class AddApacheLicenseFileParameters { @Parameter ({ displayName : \"License type\" , validInput : \"apache20, gpl, lgpl\" , pattern : /(apache20|gpl|lgpl)/ , required : false , }) public license : \"apache20\" | \"gpl\" | \"lgpl\" = \"apache20\" ; } Next we need to make the transform aware of the new parameters and alter the internal logic in order to take those parameters into account. export const AddApacheLicenseFileTransform : CodeTransform < AddApacheLicenseFileParameters > = async ( p , params ) => { const licenses = { apache20 : \"https://www.apache.org/licenses/LICENSE-2.0.txt\" , gpl : \"https://www.gnu.org/licenses/gpl-2.0.txt\" , lgpl : \"https://www.gnu.org/licenses/lgpl-3.0.txt\" , }; const httpClient = DefaultHttpClientFactory . create (); const license = await httpClient . exchange ( licenses [ params . parameters . license ]); return p . addFile ( \"LICENSE\" , license . body as string ); }; Finally, we need to alter the command registration so that it recognizes the command parameters and prompt for their values if they are required. export const AddApacheLicenseFile : CodeTransformRegistration < AddApacheLicenseFileParameters > = { transform : AddApacheLicenseFileTransform , paramsMaker : AddApacheLicenseFileParameters , name : \"add apache license file\" , description : `Add Apache 2.0 license file` , intent : [ \"add apache license file\" , \"add license file\" ], }; When issuing the command, it will prompt for the parameters values that are required. You can still issue the values for non-required parameters like this: @atomist add apache license file license=gpl Changing the branch and generated pull request If you want, you can alter the contents of the pull request by defining a transformPresentation on the code transform. export const AddApacheLicenseFile: CodeTransformRegistration<AddApacheLicenseFileParameters> = { transform: AddApacheLicenseFileTransform, paramsMaker: AddApacheLicenseFileParameters, name: \"add apache license file\", description: `Add Apache 2.0 license file`, intent: [\"add apache license file\", \"add license file\"], transformPresentation: () => new editModes.PullRequest(\"license-file\", \"Add license file\"), }; This will cause the transform to be run on the license-file branch and the resulting pull request have Add license file as a title. Defer pull request creation based on build outcome Atomist will automatically create a pull request when executing a code transform. However, the goal set execution can still fail. To mitigate unneeded unstable pull request creation, you can wrap your code transform registration in the makeBuildAware function. export const AddApacheLicenseFile : CodeTransformRegistration < AddApacheLicenseFileParameters > = makeBuildAware ({ transform : AddApacheLicenseFileTransform , paramsMaker : AddApacheLicenseFileParameters , name : \"add apache license file\" , description : `Add Apache 2.0 license file` , intent : [ \"add apache license file\" , \"add license file\" ], }); Enabling auto merge of pull request based on build outcome By default, you still need to manually merge the pull request. You can however configure code transforms to auto merge on a successful goalset execution. You can achieve this by pressing the Enable Auto Merge button that is shown in Slack in the pull request message. This will add a certain label ( auto-merge:on-check-success ) to the pull request, which indicates to Atomist that the pull request needs to be merged on a succesful goalset execution. You can also add that label manually in Github if you want to. Adding labels to Github If the labels are missing in Github, issue the @atomist add auto merge labels command in the channel linked to a repository Changing merge behavior of pull requests By default, Atomist will merge a pull request by adding the commits to the target branch using a merge commit. It is however also capable of using different merge strategies, like rebase or squash. In order to do this, you can add different labels to the pull request. The following labels are supported: auto-merge-method:merge : use a merge commit auto-merge-method:rebase : rebase the commits onto the target branch * auto-merge-method:squash : squash all the commits into a single commit In the event of a squash, the commit message of the new commit will be the title of the pull request. Adding labels to Github If the labels are missing in Github, issue the @atomist add auto merge labels command in the channel linked to a repository","title":"Transforms"},{"location":"developer/transform/#create-a-code-transform","text":"Code transforms are functions that receive the project as an input and changes the content of the project as a result. Assume we want to add an Apache licence file to the project. The transform would retrieve the license content and add a LICENSE file with that content. export const AddApacheLicenseFileTransform : CodeTransform < NoParameters > = async ( p : Project ) => { const httpClient = DefaultHttpClientFactory . create (); const license = await httpClient . exchange ( \"https://www.apache.org/licenses/LICENSE-2.0.txt\" ); return p . addFile ( \"LICENSE\" , license . body as string ); }; See also: HTTP calls in an SDM the Project interface","title":"Create a code transform"},{"location":"developer/transform/#creating-a-command-for-a-transform","text":"A code transform can be called through various means. One of those means is directly through issuing a command. This command needs to be defined and the transform needs to be referenced in that definition. export const AddApacheLicenseFile : CodeTransformRegistration < NoParameters > = { transform : AddApacheLicenseFileTransform , name : \"add apache license file\" , description : `Add Apache 2.0 license file` , intent : [ \"add apache license file\" , \"add license file\" ], }; Each intent acts as an alias for invoking the command. The description is going to be the title of an automatic pull request. The transform\u2019s name will appear in the branch. See also: CodeTransformRegistration API doc","title":"Creating a command for a transform"},{"location":"developer/transform/#adding-the-transform-command-to-the-sdm","text":"Tell the SDM about the command. In order to achieve this you need to register the command with the SDM. In your SDM definition where you have access to the SDM instance, add the following registration: sdm . addCodeTransformCommand ( AddApacheLicenseFile ); See also: Adding functionality to your SDM","title":"Adding the transform command to the SDM"},{"location":"developer/transform/#calling-the-command","text":"","title":"Calling the command"},{"location":"developer/transform/#local","text":"To test your command, run your SDM in local mode and then atomist start --local then, in a separate terminal, change directory to one of your repositories under your Atomist project root (usually $HOME/atomist). Then: atomist add apache license file Atomist will create a new branch with the changed code on it. List all your branches to find it: git branch","title":"Local"},{"location":"developer/transform/#team","text":"When you run your SDM in team mode , your command will be available in chat. Go to a channel associated with a repository , and talk to the Atomist bot: @atomist add apache license file Atomist will create a branch and apply the code transform on that branch. It will also create a pull request for the commits generated by that branch. By default, the name of the pull request will be the description of the code transform. See also: Invoking commands","title":"Team"},{"location":"developer/transform/#adding-parameters-to-the-code-transform-command","text":"Sometimes you need additional input after issuing the command to transform a certain piece of code. Say that we wish to make the license file transformation a bit more flexible and allow of different types of licences. First we need to define the data structure that will hold the parameters. @Parameters () class AddApacheLicenseFileParameters { @Parameter ({ displayName : \"License type\" , validInput : \"apache20, gpl, lgpl\" , pattern : /(apache20|gpl|lgpl)/ , required : false , }) public license : \"apache20\" | \"gpl\" | \"lgpl\" = \"apache20\" ; } Next we need to make the transform aware of the new parameters and alter the internal logic in order to take those parameters into account. export const AddApacheLicenseFileTransform : CodeTransform < AddApacheLicenseFileParameters > = async ( p , params ) => { const licenses = { apache20 : \"https://www.apache.org/licenses/LICENSE-2.0.txt\" , gpl : \"https://www.gnu.org/licenses/gpl-2.0.txt\" , lgpl : \"https://www.gnu.org/licenses/lgpl-3.0.txt\" , }; const httpClient = DefaultHttpClientFactory . create (); const license = await httpClient . exchange ( licenses [ params . parameters . license ]); return p . addFile ( \"LICENSE\" , license . body as string ); }; Finally, we need to alter the command registration so that it recognizes the command parameters and prompt for their values if they are required. export const AddApacheLicenseFile : CodeTransformRegistration < AddApacheLicenseFileParameters > = { transform : AddApacheLicenseFileTransform , paramsMaker : AddApacheLicenseFileParameters , name : \"add apache license file\" , description : `Add Apache 2.0 license file` , intent : [ \"add apache license file\" , \"add license file\" ], }; When issuing the command, it will prompt for the parameters values that are required. You can still issue the values for non-required parameters like this: @atomist add apache license file license=gpl","title":"Adding parameters to the code transform command"},{"location":"developer/transform/#changing-the-branch-and-generated-pull-request","text":"If you want, you can alter the contents of the pull request by defining a transformPresentation on the code transform. export const AddApacheLicenseFile: CodeTransformRegistration<AddApacheLicenseFileParameters> = { transform: AddApacheLicenseFileTransform, paramsMaker: AddApacheLicenseFileParameters, name: \"add apache license file\", description: `Add Apache 2.0 license file`, intent: [\"add apache license file\", \"add license file\"], transformPresentation: () => new editModes.PullRequest(\"license-file\", \"Add license file\"), }; This will cause the transform to be run on the license-file branch and the resulting pull request have Add license file as a title.","title":"Changing the branch and generated pull request"},{"location":"developer/transform/#defer-pull-request-creation-based-on-build-outcome","text":"Atomist will automatically create a pull request when executing a code transform. However, the goal set execution can still fail. To mitigate unneeded unstable pull request creation, you can wrap your code transform registration in the makeBuildAware function. export const AddApacheLicenseFile : CodeTransformRegistration < AddApacheLicenseFileParameters > = makeBuildAware ({ transform : AddApacheLicenseFileTransform , paramsMaker : AddApacheLicenseFileParameters , name : \"add apache license file\" , description : `Add Apache 2.0 license file` , intent : [ \"add apache license file\" , \"add license file\" ], });","title":"Defer pull request creation based on build outcome"},{"location":"developer/transform/#enabling-auto-merge-of-pull-request-based-on-build-outcome","text":"By default, you still need to manually merge the pull request. You can however configure code transforms to auto merge on a successful goalset execution. You can achieve this by pressing the Enable Auto Merge button that is shown in Slack in the pull request message. This will add a certain label ( auto-merge:on-check-success ) to the pull request, which indicates to Atomist that the pull request needs to be merged on a succesful goalset execution. You can also add that label manually in Github if you want to. Adding labels to Github If the labels are missing in Github, issue the @atomist add auto merge labels command in the channel linked to a repository","title":"Enabling auto merge of pull request based on build outcome"},{"location":"developer/transform/#changing-merge-behavior-of-pull-requests","text":"By default, Atomist will merge a pull request by adding the commits to the target branch using a merge commit. It is however also capable of using different merge strategies, like rebase or squash. In order to do this, you can add different labels to the pull request. The following labels are supported: auto-merge-method:merge : use a merge commit auto-merge-method:rebase : rebase the commits onto the target branch * auto-merge-method:squash : squash all the commits into a single commit In the event of a squash, the commit message of the new commit will be the title of the pull request. Adding labels to Github If the labels are missing in Github, issue the @atomist add auto merge labels command in the channel linked to a repository","title":"Changing merge behavior of pull requests"},{"location":"pack/","text":"Section content not yet populated Sorry, we haven\u2019t written this part of the documentation yet. Will you tell us what questions are important to you? We\u2019re happy to help in the #support channel in Atomist community Slack . You can also contribute to this guide with an issue or pull request on the docs repository .","title":"Extension Packs"},{"location":"pack/changelog/","text":"Section content not yet populated Sorry, we haven\u2019t written this part of the documentation yet. Will you tell us what questions are important to you? We\u2019re happy to help in the #support channel in Atomist community Slack . You can also contribute to this guide with an issue or pull request on the docs repository .","title":"Changelog"},{"location":"pack/checkstyle/","text":"Section content not yet populated Sorry, we haven\u2019t written this part of the documentation yet. Will you tell us what questions are important to you? We\u2019re happy to help in the #support channel in Atomist community Slack . You can also contribute to this guide with an issue or pull request on the docs repository .","title":"Checkstyle"},{"location":"pack/docker/","text":"Section content not yet populated Sorry, we haven\u2019t written this part of the documentation yet. Will you tell us what questions are important to you? We\u2019re happy to help in the #support channel in Atomist community Slack . You can also contribute to this guide with an issue or pull request on the docs repository .","title":"Docker"},{"location":"pack/fingerprint/","text":"Section content not yet populated Sorry, we haven\u2019t written this part of the documentation yet. Will you tell us what questions are important to you? We\u2019re happy to help in the #support channel in Atomist community Slack . You can also contribute to this guide with an issue or pull request on the docs repository .","title":"Fingerprints"},{"location":"pack/issue/","text":"Section content not yet populated Sorry, we haven\u2019t written this part of the documentation yet. Will you tell us what questions are important to you? We\u2019re happy to help in the #support channel in Atomist community Slack . You can also contribute to this guide with an issue or pull request on the docs repository .","title":"Issue"},{"location":"pack/kubernetes/","text":"Section content not yet populated Sorry, we haven\u2019t written this part of the documentation yet. Will you tell us what questions are important to you? We\u2019re happy to help in the #support channel in Atomist community Slack . You can also contribute to this guide with an issue or pull request on the docs repository .","title":"Kubernetes"},{"location":"pack/node/","text":"Section content not yet populated Sorry, we haven\u2019t written this part of the documentation yet. Will you tell us what questions are important to you? We\u2019re happy to help in the #support channel in Atomist community Slack . You can also contribute to this guide with an issue or pull request on the docs repository .","title":"Node"},{"location":"pack/pcf/","text":"Section content not yet populated Sorry, we haven\u2019t written this part of the documentation yet. Will you tell us what questions are important to you? We\u2019re happy to help in the #support channel in Atomist community Slack . You can also contribute to this guide with an issue or pull request on the docs repository .","title":"Cloud Foundry"},{"location":"pack/sloc/","text":"Section content not yet populated Sorry, we haven\u2019t written this part of the documentation yet. Will you tell us what questions are important to you? We\u2019re happy to help in the #support channel in Atomist community Slack . You can also contribute to this guide with an issue or pull request on the docs repository .","title":"Lines of Code"},{"location":"pack/sonarqube/","text":"Section content not yet populated Sorry, we haven\u2019t written this part of the documentation yet. Will you tell us what questions are important to you? We\u2019re happy to help in the #support channel in Atomist community Slack . You can also contribute to this guide with an issue or pull request on the docs repository .","title":"Sonarqube"},{"location":"pack/spring/","text":"Section content not yet populated Sorry, we haven\u2019t written this part of the documentation yet. Will you tell us what questions are important to you? We\u2019re happy to help in the #support channel in Atomist community Slack . You can also contribute to this guide with an issue or pull request on the docs repository .","title":"Spring"},{"location":"user/","text":"Atomist is here to help you smooth your development flow. Start with our web console; see consolidated event notifications. Add ChatOps with Slack if you have it. Spawn your own software delivery machine, and integrate with other tools as you choose. This page describes enrollment with Atomist as a service. When you enroll in the Atomist service, you get built-in automations such as Lifecycle Messages (Slack notifications on code push, PR, issue etc with action buttons) and commands like \u201ccreate issue\u201d. And your own Software Delivery Machines will work on events and commands from your whole organization. You can also use a Software Delivery Machine (SDM) on your laptop, individually, without enrolling in the service. To get going with a Local SDM, see the quick start guide . This page describes how to create an Atomist workspace . An Atomist workspace connects your code, build, deployment, and runtime platforms into a single, cohesive model of how your team provides value: delivering great solutions. Prerequisites You must have a Git source code management account, either GitHub.com, GitHub Enterprise (GHE), or BitBucket. If you want to use Atomist with GHE or BitBucket, please contact Atomist . The remainder of these instructions assume you have a GitHub.com account. If you do not already have a GitHub.com account, you can create one . For the whole shebang, it helps to have a GitHub organization and a Slack workspace. You can create these for free and have full admin powers, if you want to experiment. Hello Atomist Follow the instructions in the sign up or trial invitation email you received. When you first sign up, you\u2019ll be asked to authenticate with GitHub. Once you\u2019ve authenticated, you\u2019ll create a new Atomist workspace. Associate a GitHub organization with the Atomist workspace to start getting events. Atomist will ask your permission to create the needed webhook(s). For more information on how Atomist integrates with GitHub, see the GitHub integration documentation. The Atomist web dashboard will show you events, e.g., new commits and issue and pull request activity, from GitHub. Next steps Now that you have an Atomist workspace, you can Connect Atomist with your Slack workspace Connect Atomist with your continuous integration solution Connect Atomist with your Kubernetes clusters Configure the built-in chat integration You can also customize Atomist, molding it to your team\u2019s delivery model. Make Atomist respond to your own events and commands by creating your Software Delivery Machine. See the developer documentation to learn how to create and run your own Software Delivery machine!","title":"Getting Started"},{"location":"user/#prerequisites","text":"You must have a Git source code management account, either GitHub.com, GitHub Enterprise (GHE), or BitBucket. If you want to use Atomist with GHE or BitBucket, please contact Atomist . The remainder of these instructions assume you have a GitHub.com account. If you do not already have a GitHub.com account, you can create one . For the whole shebang, it helps to have a GitHub organization and a Slack workspace. You can create these for free and have full admin powers, if you want to experiment.","title":"Prerequisites"},{"location":"user/#hello-atomist","text":"Follow the instructions in the sign up or trial invitation email you received. When you first sign up, you\u2019ll be asked to authenticate with GitHub. Once you\u2019ve authenticated, you\u2019ll create a new Atomist workspace. Associate a GitHub organization with the Atomist workspace to start getting events. Atomist will ask your permission to create the needed webhook(s). For more information on how Atomist integrates with GitHub, see the GitHub integration documentation. The Atomist web dashboard will show you events, e.g., new commits and issue and pull request activity, from GitHub.","title":"Hello Atomist"},{"location":"user/#next-steps","text":"Now that you have an Atomist workspace, you can Connect Atomist with your Slack workspace Connect Atomist with your continuous integration solution Connect Atomist with your Kubernetes clusters Configure the built-in chat integration You can also customize Atomist, molding it to your team\u2019s delivery model. Make Atomist respond to your own events and commands by creating your Software Delivery Machine. See the developer documentation to learn how to create and run your own Software Delivery machine!","title":"Next steps"},{"location":"user/ci/","text":"Atomist natively supports several continuous integration (CI) platforms, listening for CI events, correlating them with the commits that triggered the build, and showing contextualized notifications in a Slack channel linked to the repository. To enable this capability, just add the desired Atomist CI webhook URL to your CI configuration. Note In the examples below, replace WORKSPACE_ID with your workspace ID. CircleCI To send events from CircleCI to Atomist, add the following snippet to your .circleci/config.yml configuration file. notify : webhooks : - url : https://webhook.atomist.com/atomist/circle/teams/WORKSPACE_ID Jenkins You can send events from Jenkins to Atomist using the notification plugin , configuring it to send its payload to https://webhook.atomist.com/atomist/jenkins/teams/WORKSPACE_ID , replacing WORKSPACE_ID with your Atomist workspace ID. If you configure your build using a Jenkinsfile , add the following function to your Jenkinsfile . import groovy.json.JsonOutput /** * Notify the Atomist services about the status of a build based from a * git repository. */ def notifyAtomist ( String workspaceIds , String buildStatus , String buildPhase = \"FINALIZED\" ) { if (! workspaceIds ) { echo 'No Atomist workspace IDs, not sending build notification' return } def payload = JsonOutput . toJson ( [ name: env . JOB_NAME , duration: currentBuild . duration , build: [ number: env . BUILD_NUMBER , phase: buildPhase , status: buildStatus , full_url: env . BUILD_URL , scm: [ url: env . GIT_URL , branch: env . COMMIT_BRANCH , commit: env . COMMIT_SHA ] ] ] ) workspaceIds . split ( ',' ). each { workspaceId -> String endpoint = \"https://webhook.atomist.com/atomist/jenkins/teams/${workspaceId}\" sh \"curl --silent -X POST -H 'Content-Type: application/json' -d '${payload}' ${endpoint}\" } } Ensure your build has an environment variable named ATOMIST_WORKSPACES whose value is your Atomist workspace ID or, if you want to send the event to more than one Atomist workspace, the value should be a comma-separated list of your Atomist workspace IDs. Then call notifyAtomist when the build starts (in the first stage) and ends (in the post block), sending the appropriate status and phase. Start: notifyAtomist(env.ATOMIST_WORKSPACES, \"STARTED\", \"STARTED\") Succesful: notifyAtomist(env.ATOMIST_WORKSPACES, \"SUCCESS\") Unstable: notifyAtomist(env.ATOMIST_WORKSPACES, \"UNSTABLE\") Failure: notifyAtomist(env.ATOMIST_WORKSPACES, \"FAILURE\") Here is a simple example Jenkinsfile pipeline that sends the appropriate webhook payloads at the appropriate time. /** * Simple Jenkins pipeline for Maven builds */ pipeline { agent any environment { MVN = 'mvn -B -V' } stages { stage ( 'Notify' ) { steps { echo 'Sending build start...' notifyAtomist ( env . ATOMIST_WORKSPACES , 'STARTED' , 'STARTED' ) } } stage ( 'Set version' ) { steps { echo 'Setting version...' sh \"${env.MVN} versions:set -DnewVersion=${env.COMMIT_SHA} versions:commit\" } } stage ( 'Build, Test, and Package' ) { steps { echo 'Building, testing, and packaging...' sh \"${env.MVN} clean package\" } } } post { always { echo 'Post notification...' notifyAtomist ( env . ATOMIST_WORKSPACES , currentBuild . currentResult ) } } } Travis CI To send events from Travis CI to Atomist, add the following snippet to your .travis.yml configuration file. notifications : webhooks : urls : - https://webhook.atomist.com/atomist/travis/teams/WORKSPACE_ID on_success : always on_failure : always on_start : always on_cancel : always on_error : always Other If you use a different CI tool than those listed above, you can send your build payload to Atomist using its generic build payload webhook endpoint. Atomist provides a helper Bash script you can call from your CI solution to post webhook payloads to Atomist. The script can be found in the Atomist utilities repository and can be invoked as follows: bash atomist-post-webhook.bash build WORKSPACE_ID If your CI platform is not supported by the above script or you prefer to use your own script, below is an example of how to send the necessary JSON payload using curl . curl -s -f -X POST -H \"Content-Type: application/json\" \\ --data-binary \"{\\\"branch\\\":\\\"BRANCH\\\",\\\"repository\\\":{\\\"owner_name\\\":\\\"REPO_OWNER\\\",\\\"name\\\":\\\"REPO_NAME\\\"},\\\"commit\\\":\\\"SHA\\\",\\\"status\\\":\\\"STATUS\\\",\\\"type\\\":\\\"TYPE\\\"}\" \\ https://webhook.atomist.com/atomist/build/teams/WORKSPACE_ID When using the above command, replace the ALL_CAPS strings as follows: String Description BRANCH Branch of commit being built REPO_OWNER Owner, i.e., organization or user, of repository REPO_NAME Name of repository SHA Full commit SHA STATUS Build status: \u201cstarted\u201d, \u201cfailed\u201d, \u201cerror\u201d, \u201cpassed\u201d, \u201ccanceled\u201d TYPE Build trigger: \u201cpush\u201d, \u201cpull_request\u201d, \u201ctag\u201d, \u201ccron\u201d, \u201cmanual\u201d There are other optional elements you can include in your webhook POST payload. Here is the complete list of build payload elements. Property JSON Type Description branch string Branch of commit (required if build type is \u201cpush\u201d) build_url string Web URL for build report/log commit string Full commit SHA (required) compare_url string Commit comparison URL showing changes id string Build ID, must be unique among all builds associated with a given repository name string Name for build number number Build number provider string Name of CI provider pull_request_number number Pull request number (only valid and required if build type is \u201cpull_request\u201d) repository.owner_name string Owner, i.e., organization or user, of repository (required) repository.name string Name of repository (required) status string Build status: \u201cstarted\u201d, \u201cfailed\u201d, \u201cerror\u201d, \u201cpassed\u201d, \u201ccanceled\u201d (required) tag string Tag being build, only valid and required if build type is \u201ctag\u201d type string Build trigger: \u201cpush\u201d, \u201cpull_request\u201d, \u201ctag\u201d, \u201ccron\u201d, \u201cmanual\u201d (required) See the build webhook documentation for more details.","title":"Integrations"},{"location":"user/ci/#circleci","text":"To send events from CircleCI to Atomist, add the following snippet to your .circleci/config.yml configuration file. notify : webhooks : - url : https://webhook.atomist.com/atomist/circle/teams/WORKSPACE_ID","title":"CircleCI"},{"location":"user/ci/#jenkins","text":"You can send events from Jenkins to Atomist using the notification plugin , configuring it to send its payload to https://webhook.atomist.com/atomist/jenkins/teams/WORKSPACE_ID , replacing WORKSPACE_ID with your Atomist workspace ID. If you configure your build using a Jenkinsfile , add the following function to your Jenkinsfile . import groovy.json.JsonOutput /** * Notify the Atomist services about the status of a build based from a * git repository. */ def notifyAtomist ( String workspaceIds , String buildStatus , String buildPhase = \"FINALIZED\" ) { if (! workspaceIds ) { echo 'No Atomist workspace IDs, not sending build notification' return } def payload = JsonOutput . toJson ( [ name: env . JOB_NAME , duration: currentBuild . duration , build: [ number: env . BUILD_NUMBER , phase: buildPhase , status: buildStatus , full_url: env . BUILD_URL , scm: [ url: env . GIT_URL , branch: env . COMMIT_BRANCH , commit: env . COMMIT_SHA ] ] ] ) workspaceIds . split ( ',' ). each { workspaceId -> String endpoint = \"https://webhook.atomist.com/atomist/jenkins/teams/${workspaceId}\" sh \"curl --silent -X POST -H 'Content-Type: application/json' -d '${payload}' ${endpoint}\" } } Ensure your build has an environment variable named ATOMIST_WORKSPACES whose value is your Atomist workspace ID or, if you want to send the event to more than one Atomist workspace, the value should be a comma-separated list of your Atomist workspace IDs. Then call notifyAtomist when the build starts (in the first stage) and ends (in the post block), sending the appropriate status and phase. Start: notifyAtomist(env.ATOMIST_WORKSPACES, \"STARTED\", \"STARTED\") Succesful: notifyAtomist(env.ATOMIST_WORKSPACES, \"SUCCESS\") Unstable: notifyAtomist(env.ATOMIST_WORKSPACES, \"UNSTABLE\") Failure: notifyAtomist(env.ATOMIST_WORKSPACES, \"FAILURE\") Here is a simple example Jenkinsfile pipeline that sends the appropriate webhook payloads at the appropriate time. /** * Simple Jenkins pipeline for Maven builds */ pipeline { agent any environment { MVN = 'mvn -B -V' } stages { stage ( 'Notify' ) { steps { echo 'Sending build start...' notifyAtomist ( env . ATOMIST_WORKSPACES , 'STARTED' , 'STARTED' ) } } stage ( 'Set version' ) { steps { echo 'Setting version...' sh \"${env.MVN} versions:set -DnewVersion=${env.COMMIT_SHA} versions:commit\" } } stage ( 'Build, Test, and Package' ) { steps { echo 'Building, testing, and packaging...' sh \"${env.MVN} clean package\" } } } post { always { echo 'Post notification...' notifyAtomist ( env . ATOMIST_WORKSPACES , currentBuild . currentResult ) } } }","title":"Jenkins"},{"location":"user/ci/#travis-ci","text":"To send events from Travis CI to Atomist, add the following snippet to your .travis.yml configuration file. notifications : webhooks : urls : - https://webhook.atomist.com/atomist/travis/teams/WORKSPACE_ID on_success : always on_failure : always on_start : always on_cancel : always on_error : always","title":"Travis CI"},{"location":"user/ci/#other","text":"If you use a different CI tool than those listed above, you can send your build payload to Atomist using its generic build payload webhook endpoint. Atomist provides a helper Bash script you can call from your CI solution to post webhook payloads to Atomist. The script can be found in the Atomist utilities repository and can be invoked as follows: bash atomist-post-webhook.bash build WORKSPACE_ID If your CI platform is not supported by the above script or you prefer to use your own script, below is an example of how to send the necessary JSON payload using curl . curl -s -f -X POST -H \"Content-Type: application/json\" \\ --data-binary \"{\\\"branch\\\":\\\"BRANCH\\\",\\\"repository\\\":{\\\"owner_name\\\":\\\"REPO_OWNER\\\",\\\"name\\\":\\\"REPO_NAME\\\"},\\\"commit\\\":\\\"SHA\\\",\\\"status\\\":\\\"STATUS\\\",\\\"type\\\":\\\"TYPE\\\"}\" \\ https://webhook.atomist.com/atomist/build/teams/WORKSPACE_ID When using the above command, replace the ALL_CAPS strings as follows: String Description BRANCH Branch of commit being built REPO_OWNER Owner, i.e., organization or user, of repository REPO_NAME Name of repository SHA Full commit SHA STATUS Build status: \u201cstarted\u201d, \u201cfailed\u201d, \u201cerror\u201d, \u201cpassed\u201d, \u201ccanceled\u201d TYPE Build trigger: \u201cpush\u201d, \u201cpull_request\u201d, \u201ctag\u201d, \u201ccron\u201d, \u201cmanual\u201d There are other optional elements you can include in your webhook POST payload. Here is the complete list of build payload elements. Property JSON Type Description branch string Branch of commit (required if build type is \u201cpush\u201d) build_url string Web URL for build report/log commit string Full commit SHA (required) compare_url string Commit comparison URL showing changes id string Build ID, must be unique among all builds associated with a given repository name string Name for build number number Build number provider string Name of CI provider pull_request_number number Pull request number (only valid and required if build type is \u201cpull_request\u201d) repository.owner_name string Owner, i.e., organization or user, of repository (required) repository.name string Name of repository (required) status string Build status: \u201cstarted\u201d, \u201cfailed\u201d, \u201cerror\u201d, \u201cpassed\u201d, \u201ccanceled\u201d (required) tag string Tag being build, only valid and required if build type is \u201ctag\u201d type string Build trigger: \u201cpush\u201d, \u201cpull_request\u201d, \u201ctag\u201d, \u201ccron\u201d, \u201cmanual\u201d (required) See the build webhook documentation for more details.","title":"Other"},{"location":"user/github/","text":"Atomist helps you work with GitHub in two ways: Atomist surfaces your team\u2019s development activity, such as pushes, pull requests, or issues, in the Atomist dashboard in chat. This visibility is enabled via webhooks. Atomist allows you to take action in your repositories, creating issues, merging pull requests, even releasing services to production, from the Atomist dashboard or in chat. To release the full ChatOps power of Atomist, each user on your team will independently authorize Atomist \u2013 this means that your users remain within the boundaries of the existing GitHub security model. Atomist acts on behalf of your users, not instead of them. Webhooks Atomist receives its information from GitHub via webhooks . To ease adoption across your organization, installing an organization webhook is recommended. To try Atomist out on a small scale, you can install webhooks repository by repository. Organization webhooks GitHub organization members that have the owner role , are allowed to configure organization webhooks. This is convenient because it only has to be configured once; however, you will require a user who has the Owner role in your GitHub organization. you> @atomist enroll org When you choose to enroll a GitHub organization, you will most likely be prompted to authorize a new scope (Atomist only asks for new scopes when explicitly required). The admin:org_hook is required when enrolling a new GitHub organization. If you are a member of more than one GitHub organization, Atomist asks you to choose which organization to enroll. Repository webhooks If your team does not use a GitHub organization account, you can choose to configure webhooks on individual repositories owned by your user account. GitHub user authorization When the Atomist bot first arrives in a Slack workspace, it will send a direct message to the authorizing user, requesting that they authorize Atomist to access GitHub on their behalf. This same dialog will be shown to users anytime Atomist detects that an automation needs to access GitHub as that user. Every member of the workspace must individually opt in. Atomist will display this option each time an un-authorized user runs a command that requires a GitHub authorization. Users can ask for their current GitHub authorization status by running: you> @atomist github Atomist will send a direct message to this user with their current GitHub authorization status.","title":"Source Control"},{"location":"user/github/#webhooks","text":"Atomist receives its information from GitHub via webhooks . To ease adoption across your organization, installing an organization webhook is recommended. To try Atomist out on a small scale, you can install webhooks repository by repository.","title":"Webhooks"},{"location":"user/github/#organization-webhooks","text":"GitHub organization members that have the owner role , are allowed to configure organization webhooks. This is convenient because it only has to be configured once; however, you will require a user who has the Owner role in your GitHub organization. you> @atomist enroll org When you choose to enroll a GitHub organization, you will most likely be prompted to authorize a new scope (Atomist only asks for new scopes when explicitly required). The admin:org_hook is required when enrolling a new GitHub organization. If you are a member of more than one GitHub organization, Atomist asks you to choose which organization to enroll.","title":"Organization webhooks"},{"location":"user/github/#repository-webhooks","text":"If your team does not use a GitHub organization account, you can choose to configure webhooks on individual repositories owned by your user account.","title":"Repository webhooks"},{"location":"user/github/#github-user-authorization","text":"When the Atomist bot first arrives in a Slack workspace, it will send a direct message to the authorizing user, requesting that they authorize Atomist to access GitHub on their behalf. This same dialog will be shown to users anytime Atomist detects that an automation needs to access GitHub as that user. Every member of the workspace must individually opt in. Atomist will display this option each time an un-authorized user runs a command that requires a GitHub authorization. Users can ask for their current GitHub authorization status by running: you> @atomist github Atomist will send a direct message to this user with their current GitHub authorization status.","title":"GitHub user authorization"},{"location":"user/integrations/","text":"Atomist receives events from and performs operations on many systems, including version control, CI systems, Slack, and more. Atomist uses the native integration technology for each platform or tool. For example, to integrate with GitHub and Travis CI, Atomist uses webhooks; to integrate with Slack it uses their event API. For each platform Atomist integrates with, it requests the minimal set of permissions required. If you use a system or tool Atomist does not natively support, you can implement your own integrations. You can use whatever tools and libraries you want to communicate with your systems, and then register these custom event types with Atomist so it can properly connect them with other events. Chat Integrations Send messages to channels and people, receive commands, query people for command parameters, update messages, and include buttons on messages. Slack MS Teams (experimental) Version Control Integrations Atomist receives events for Pushes and Pull Requests (PRs). The built-in integrations include action buttons to create and merge PRs and add labels, reviewers, and comments to PRs. GitHub GitHub Enterprise BitBucket BitBucket Cloud GitLab Issue Tracking Integrations Atomist receives events for issue and issue comment creation and update. GitHub Issues CI Integrations Any build system can be integrated with Atomist. We have some pre-built functionality for receiving events from: Jenkins Travis CI Team City Section content not yet populated Sorry, we haven\u2019t written this part of the documentation yet. Will you tell us what questions are important to you? We\u2019re happy to help in the #support channel in Atomist community Slack . You can also contribute to this guide with an issue or pull request on the docs repository .","title":"Supported Integrations"},{"location":"user/integrations/#chat-integrations","text":"Send messages to channels and people, receive commands, query people for command parameters, update messages, and include buttons on messages. Slack MS Teams (experimental)","title":"Chat Integrations"},{"location":"user/integrations/#version-control-integrations","text":"Atomist receives events for Pushes and Pull Requests (PRs). The built-in integrations include action buttons to create and merge PRs and add labels, reviewers, and comments to PRs. GitHub GitHub Enterprise BitBucket BitBucket Cloud GitLab","title":"Version Control Integrations"},{"location":"user/integrations/#issue-tracking-integrations","text":"Atomist receives events for issue and issue comment creation and update. GitHub Issues","title":"Issue Tracking Integrations"},{"location":"user/integrations/#ci-integrations","text":"Any build system can be integrated with Atomist. We have some pre-built functionality for receiving events from: Jenkins Travis CI Team City Section content not yet populated Sorry, we haven\u2019t written this part of the documentation yet. Will you tell us what questions are important to you? We\u2019re happy to help in the #support channel in Atomist community Slack . You can also contribute to this guide with an issue or pull request on the docs repository .","title":"CI Integrations"},{"location":"user/kubernetes/","text":"Atomist provides the easiest and most flexible way to get from ideas and customer requests to a solution deployed in Kubernetes . Once deployed, Atomist provides feedback on the health of running applications and uses standard Kubernetes mechanism for zero-downtime deployments. Overview Before getting started, it is helpful to provide some information about how Atomist interacts with Kubernetes. Atomist is able to deploy and update applications to Kubernetes as well as report back on the health of those applications, providing feedback in the Atomist dashboard or Slack on deployments running containers across clusters and namespaces in the concise, correlated manner users of Atomist expect. Deploying and updating applications The Atomist k8-automation utility manages deploying and updating applications. It is able to create deployments to manage the runtime of the application container, services to provide standard Kubernetes discovery capabilities, and ingresses to provide the properly hosted and secured external access to services. The k8-automation utility runs inside each Kubernetes cluster you want to deploy applications to, using a Kubernetes service account with only the permissions needed to create, read, update, and delete namespaces, deployments, services, and ingresses. Container status The Atomist k8vent utility watches pods in your Kubernetes cluster and sends change events, e.g., container started and container crashed, back to Atomist. Like k8-automation, the k8vent utility runs inside each Kubernetes cluster you want events from, using a Kubernetes service account with only the permissions needed to watch pod events. Role-Based Access Control (RBAC) To perform their tasks, the Atomist utilities running within a Kubernetes cluster need access to do so. In modern, i.e., version 1.6 or greater, Kubernetes clusters, this access is provided using role-based access control (RBAC) . Briefly, a service account is created and bound to roles with the appropriate privileges. The pod is then configured to use the service account when accessing the Kubernetes API using the in-cluster client. Part of deploying the Atomist utilities to your Kubernetes cluster is creating the needed RBAC resources. To create RBAC resources, your Kubernetes user needs admin privileges. If your Kubernetes user does not have admin privileges in the cluster or a namespace, someone whose Kuberetes user has those privileges will need to deploy the Atomist utilities. If you see errors like the following when you try to deploy the Atomist utilities to your Kubernetes cluster, Error from server (Forbidden): error when creating \"rbac.yaml\": clusterroles.rbac.authorization.k8s.io \"k8-automation-clusterrole\" is forbidden: attempt to grant extra privileges: [...] user=&{YOUR_USER [system:authenticated] map[]} ownerrules=[PolicyRule{Resources:[\"selfsubjectaccessreviews\"], APIGroups:[\"authorization.k8s.io\"], Verbs:[\"create\"]} PolicyRule{NonResourceURLs:[\"/api\" \"/api/*\" \"/apis\" \"/apis/*\" \"/healthz\" \"/swagger-2.0.0.pb-v1\" \"/swagger.json\" \"/swaggerapi\" \"/swaggerapi/*\" \"/version\"], Verbs:[\"get\"]}] ruleResolutionErrors=[] then your Kubernetes user does not have administrative privileges on your cluster/namespace. You will either need to ask someone who has admin privileges on the cluster/namespace to create the RBAC resources or try to escalate your privileges in the cluster/namespace. In the following commands, replace USER with your Kubernetes user name. To attempt to provide your Kubernetes user with cluster admin privileges, run: kubectl create clusterrolebinding USER-cluster-admin-binding \\ --clusterrole=cluster-admin --user=USER To attempt to provide your Kubernetes user with namespace admin privileges, run: kubectl create --namespace=NAMESPACE rolebinding USER-admin-binding \\ --clusterrole=admin --user=USER Then run the command to deploy the Atomist utilities again. GKE and RBAC By default, the user you authenticate with a GKE cluster does not have sufficient permissions to install the Atomist Kubernetes utilities. To grant your user the necessary permissions, run the cluster-wide command above replacing USER in the commands above with $(gcloud config get-value account) : kubectl create clusterrolebinding \\ $(gcloud config get-value account)-cluster-admin-binding \\ --clusterrole=cluster-admin --user=$(gcloud config get-value account) If you see errors like the following when you try to deploy the Atomist utilities to your Kubernetes cluster, unable to decode \"https://raw.githubusercontent.com/atomist/k8vent/master/kube/kubectl/cluster-wide.yaml\": no kind \"ClusterRole\" is registered for version \"rbac.authorization.k8s.io/v1beta1\" unable to decode \"https://raw.githubusercontent.com/atomist/k8vent/master/kube/kubectl/cluster-wide.yaml\": no kind \"ClusterRoleBinding\" is registered for version \"rbac.authorization.k8s.io/v1beta1\" then either your kubectl CLI, Kubernetes cluster, or both are too old and do not support RBAC. Upgrade your kubectl CLI and Kubernetes cluster or contact us for help in deploying the Atomist utilities. Cluster vs. namespace The Atomist utilities can run in two modes: cluster wide and namespace scoped. If your Kubernetes user has cluster-admin role access, which is typically the case if you created the cluster, you can and probably should deploy Atomist utilities in cluster-wide mode. This allows these utilities to manage and report on applications across all namespaces in your cluster. If you are limited to managing Kubernetes resources in a single namespace and your user has admin role access to that namespace, you should probably install in namespace-scoped mode. If your Kubernetes user has neither cluster-admin or admin role access, you will need to ask someone who does to install the Atomist utilities in your cluster. If you want the Atomist Kubernetes utilities to report on and manage resources in several but not all namespaces, you can deploy the Atomist utilities using namespace-scoped mode multiple times, one time for each namespace you want reported on and managed. Cluster environment The Atomist Kubernetes utilities use the concept of a cluster environment . While the cluster environment is an arbitrary description of the Kubernetes cluster to which you are deploying the Atomist Kubernetes utilities, it is used to link application deployment requests and cluster activity to the other activity in your development flow. Therefore it should be meaningful to you and your team and unique across your organization\u2019s Kubernetes clusters. Examples of good cluster environments are \u201cproduction\u201d, \u201cend-user\u201d, \u201cuat\u201d, \u201cstaging\u201d, etc. The cluster environment you provide when installing the Atomist Kubernetes utilities will be used when reporting on Kubernetes pod container activity in development lifecycle messages. For example, the following image shows the containers that are running a specific Docker image from a specific commit and build in various namespaces in the Kubernetes cluster environment \u201cgke-int-demo\u201d. The cluster environment is used by k8-automation and your software delivery machine (SDM) to coordinate application deployments and upgrades. Since you may be deploying k8-automation to multiple Kubernetes clusters, the cluster environment is used as part of the application deployment/update request to select the Kubernetes cluster. Prerequisites Before you connect Atomist and your Kubernetes cluster(s), you need a few prerequisites. Atomist workspace You must have an Atomist workspace. If you do not already have one, you can create one following the instructions in the getting started documentation . Kubernetes cluster You must have a Kubernetes cluster and access to that cluster as a user with either cluster-admin role privileges to run in cluster-wide mode or admin role privileges within a namespace to run in namespace-scoped mode. If you do not have access to a Kubernetes cluster, you can create one on your local system using minikube . Installation Several different methods for installing the Atomist Kubernetes utilities are supported. Choose the one that makes sense for your situation. If you aren\u2019t sure how to proceed, try the Atomist CLI approach as it is the easiest. Atomist CLI To use the Atomist CLI to install the Atomist Kubernetes utilities, you must have the Atomist CLI installed and configured . You will also need the Kubernetes kubectl command-line utility installed and configured to access your Kubernetes cluster with the needed privileges. Once you have the Atomist and Kubernetes CLIs installed and configured, you can install the Atomist Kubernetes utilities one the following commands. Be sure to replace CLUSTER_ENV with a meaningful name for you Kubernetes cluster/namespace and, if deploying in namespace-scoped mode, NAMESPACE with the existing namespace you want to deploy the utilities to. Cluster-wide mode To install the Atomist Kubernetes utilities in cluster-wide mode, able to report on and manage resources in all namespaces, run the following command. atomist kube --environment=\"CLUSTER_ENV\" Namespace-scoped mode To install the Atomist Kubernetes utilities in namespace-scoped mode, run the following command for each namespace you want to deploy them to. Replace NAMESPACE with the namespace you want to deploy the utilities to. atomist kube --namespace=\"NAMESPACE\" --environment=\"CLUSTER_ENV\" Kubernetes CLI If you have the kubectl command-line utility installed and configured to access your Kubernetes cluster with the needed privileges, you can install the needed Atomist utilities with the proper configuration using the following commands. Be sure to replace CLUSTER_ENV with a meaningful name for you Kubernetes cluster/namespace, WORKSPACE_ID with your Atomist workspace ID, and API_KEY with a valid Atomist API key. See the developer prerequisites for more information on Atomist workspace IDs and API keys. Cluster-wide mode k8vent To deploy k8vent in cluster-wide mode and have it report on changes to all pod containers, run the following command. kubectl apply --filename=https://raw.githubusercontent.com/atomist/k8vent/master/kube/kubectl/cluster-wide.yaml kubectl create secret --namespace=k8vent generic k8vent --from-literal=environment=\"CLUSTER_ENV\" \\ --from-literal=webhooks=\"https://webhook.atomist.com/atomist/kube/teams/WORKSPACE_ID\" k8-automation To deploy k8-automation in cluster-wide mode with the ability to manage applications in all namespaces, run the following command. kubectl apply --filename=https://raw.githubusercontent.com/atomist/k8-automation/master/assets/kubectl/cluster-wide.yaml kubectl create secret --namespace=k8-automation generic automation \\ --from-literal=config=\"{\\\"workspaceIds\\\":[\\\"WORKSPACE_ID\\\"],\\\"apiKey\\\":\\\"API_KEY\\\",\\\"environment\\\":\\\"CLUSTER_ENV\\\"}\" Namespace-scoped mode In the commands below, replace NAMESPACE with the namespace you want to deploy the utilities to. k8vent To deploy k8vent in namespace-scoped mode such that it will only report on pod containers in a single namespace, run the following commands. kubectl create secret --namespace=\"NAMESPACE\" generic k8vent \\ --from-literal=environment=\"CLUSTER_ENV\" \\ --from-literal=webhooks=\"https://webhook.atomist.com/atomist/kube/teams/WORKSPACE_ID\" kubectl apply --namespace=\"NAMESPACE\" \\ --filename=https://raw.githubusercontent.com/atomist/k8vent/master/kube/kubectl/namespace-scoped.yaml k8-automation To deploy k8-automation in namespace-scoped mode such that it will only deploy and update resources in a single Kubernetes cluster namespace, run the following commands. kubectl create secret --namespace=\"NAMESPACE\" generic automation \\ --from-literal=config=\"{\\\"workspaceIds\\\":[\\\"WORKSPACE_ID\\\"],\\\"apiKey\\\":\\\"API_KEY\\\",\\\"environment\\\":\\\"CLUSTER_ENV\\\",\\\"kubernetes\\\":{\\\"mode\\\":\\\"namespace\\\"}}\" kubectl apply --namespace=\"NAMESPACE\" \\ --filename=https://raw.githubusercontent.com/atomist/k8-automation/master/assets/kubectl/namespace-scoped.yaml Helm If you manage resources in your Kubernetes cluster with Helm , you can install the Atomist Kubernetes utilities using Helm. Replace API_KEY with an Atomist API key, WORKSPACE_ID with your Atomist workspace ID, and CLUSTER_ENV with a meaningful name for your Kubernetes cluster/namespace. Helm and Minikube Due to a bug in the default minikube bootstrapper localkube, kubernetes/helm#3135: Helm 2.7.0 creates RBAC resource fail , if you want to manage RBAC resources using Helm in minikube, you must start minikube using the kubeadm bootstrapper. minikube start --bootstrapper kubeadm You can make kubeadm your default bootstrapper by running the following command. minikube config set bootstrapper kubeadm Cluster-wide mode To install all of the Atomist Kubernetes utilities in cluster-wide mode, run the following helm command. helm upgrade --install --namespace=atomist atomist-utilities \\ --repo=https://atomist.github.io/helm-charts atomist-utilities \\ --set=global.atomist.apiKey=\"API_KEY\" \\ --set=global.atomist.workspaceIds=\"{WORKSPACE_ID}\" \\ --set=global.atomist.environment=\"CLUSTER_ENV\" Namespace-scoped mode To install all of the Atomist Kubernetes utilities in namespace-scoped mode, run the following helm command for each namespace you want to deploy them to. Replace NAMESPACE with the namespace you want to deploy the utilities to. helm upgrade --install --namespace=\"NAMESPACE\" \"atomist-utilities-NAMESPACE\" \\ --repo=https://atomist.github.io/helm-charts atomist-utilities \\ --set=global.atomist.apiKey=\"API_KEY\" \\ --set=global.atomist.workspaceIds=\"{WORKSPACE_ID}\" \\ --set=global.atomist.environment=\"CLUSTER_ENV\" \\ --set=global.atomist.mode=namespace Updating You can update to a new version of the Atomist Kubernetes utilities using standard Kubernetes approaches. If you installed the Atomist utilities using the Atomist CLI or Helm, simply re-run the same command you ran to install them. If you are using kubectl you can run the following commands, replacing NAMESPACE and M.N.P as appropriate. kubectl set image --namespace=NAMESPACE \\ deployment/k8vent k8vent=atomist/k8vent:M.N.P kubectl set image --namespace=NAMESPACE \\ deployment/k8-automation k8-automation=atomist/k8-automation:M.N.P You can always find the latest versions of k8-automation and k8vent on their release pages.","title":"Kubernetes"},{"location":"user/kubernetes/#overview","text":"Before getting started, it is helpful to provide some information about how Atomist interacts with Kubernetes. Atomist is able to deploy and update applications to Kubernetes as well as report back on the health of those applications, providing feedback in the Atomist dashboard or Slack on deployments running containers across clusters and namespaces in the concise, correlated manner users of Atomist expect.","title":"Overview"},{"location":"user/kubernetes/#deploying-and-updating-applications","text":"The Atomist k8-automation utility manages deploying and updating applications. It is able to create deployments to manage the runtime of the application container, services to provide standard Kubernetes discovery capabilities, and ingresses to provide the properly hosted and secured external access to services. The k8-automation utility runs inside each Kubernetes cluster you want to deploy applications to, using a Kubernetes service account with only the permissions needed to create, read, update, and delete namespaces, deployments, services, and ingresses.","title":"Deploying and updating applications"},{"location":"user/kubernetes/#container-status","text":"The Atomist k8vent utility watches pods in your Kubernetes cluster and sends change events, e.g., container started and container crashed, back to Atomist. Like k8-automation, the k8vent utility runs inside each Kubernetes cluster you want events from, using a Kubernetes service account with only the permissions needed to watch pod events.","title":"Container status"},{"location":"user/kubernetes/#role-based-access-control-rbac","text":"To perform their tasks, the Atomist utilities running within a Kubernetes cluster need access to do so. In modern, i.e., version 1.6 or greater, Kubernetes clusters, this access is provided using role-based access control (RBAC) . Briefly, a service account is created and bound to roles with the appropriate privileges. The pod is then configured to use the service account when accessing the Kubernetes API using the in-cluster client. Part of deploying the Atomist utilities to your Kubernetes cluster is creating the needed RBAC resources. To create RBAC resources, your Kubernetes user needs admin privileges. If your Kubernetes user does not have admin privileges in the cluster or a namespace, someone whose Kuberetes user has those privileges will need to deploy the Atomist utilities. If you see errors like the following when you try to deploy the Atomist utilities to your Kubernetes cluster, Error from server (Forbidden): error when creating \"rbac.yaml\": clusterroles.rbac.authorization.k8s.io \"k8-automation-clusterrole\" is forbidden: attempt to grant extra privileges: [...] user=&{YOUR_USER [system:authenticated] map[]} ownerrules=[PolicyRule{Resources:[\"selfsubjectaccessreviews\"], APIGroups:[\"authorization.k8s.io\"], Verbs:[\"create\"]} PolicyRule{NonResourceURLs:[\"/api\" \"/api/*\" \"/apis\" \"/apis/*\" \"/healthz\" \"/swagger-2.0.0.pb-v1\" \"/swagger.json\" \"/swaggerapi\" \"/swaggerapi/*\" \"/version\"], Verbs:[\"get\"]}] ruleResolutionErrors=[] then your Kubernetes user does not have administrative privileges on your cluster/namespace. You will either need to ask someone who has admin privileges on the cluster/namespace to create the RBAC resources or try to escalate your privileges in the cluster/namespace. In the following commands, replace USER with your Kubernetes user name. To attempt to provide your Kubernetes user with cluster admin privileges, run: kubectl create clusterrolebinding USER-cluster-admin-binding \\ --clusterrole=cluster-admin --user=USER To attempt to provide your Kubernetes user with namespace admin privileges, run: kubectl create --namespace=NAMESPACE rolebinding USER-admin-binding \\ --clusterrole=admin --user=USER Then run the command to deploy the Atomist utilities again. GKE and RBAC By default, the user you authenticate with a GKE cluster does not have sufficient permissions to install the Atomist Kubernetes utilities. To grant your user the necessary permissions, run the cluster-wide command above replacing USER in the commands above with $(gcloud config get-value account) : kubectl create clusterrolebinding \\ $(gcloud config get-value account)-cluster-admin-binding \\ --clusterrole=cluster-admin --user=$(gcloud config get-value account) If you see errors like the following when you try to deploy the Atomist utilities to your Kubernetes cluster, unable to decode \"https://raw.githubusercontent.com/atomist/k8vent/master/kube/kubectl/cluster-wide.yaml\": no kind \"ClusterRole\" is registered for version \"rbac.authorization.k8s.io/v1beta1\" unable to decode \"https://raw.githubusercontent.com/atomist/k8vent/master/kube/kubectl/cluster-wide.yaml\": no kind \"ClusterRoleBinding\" is registered for version \"rbac.authorization.k8s.io/v1beta1\" then either your kubectl CLI, Kubernetes cluster, or both are too old and do not support RBAC. Upgrade your kubectl CLI and Kubernetes cluster or contact us for help in deploying the Atomist utilities.","title":"Role-Based Access Control (RBAC)"},{"location":"user/kubernetes/#cluster-vs-namespace","text":"The Atomist utilities can run in two modes: cluster wide and namespace scoped. If your Kubernetes user has cluster-admin role access, which is typically the case if you created the cluster, you can and probably should deploy Atomist utilities in cluster-wide mode. This allows these utilities to manage and report on applications across all namespaces in your cluster. If you are limited to managing Kubernetes resources in a single namespace and your user has admin role access to that namespace, you should probably install in namespace-scoped mode. If your Kubernetes user has neither cluster-admin or admin role access, you will need to ask someone who does to install the Atomist utilities in your cluster. If you want the Atomist Kubernetes utilities to report on and manage resources in several but not all namespaces, you can deploy the Atomist utilities using namespace-scoped mode multiple times, one time for each namespace you want reported on and managed.","title":"Cluster vs. namespace"},{"location":"user/kubernetes/#cluster-environment","text":"The Atomist Kubernetes utilities use the concept of a cluster environment . While the cluster environment is an arbitrary description of the Kubernetes cluster to which you are deploying the Atomist Kubernetes utilities, it is used to link application deployment requests and cluster activity to the other activity in your development flow. Therefore it should be meaningful to you and your team and unique across your organization\u2019s Kubernetes clusters. Examples of good cluster environments are \u201cproduction\u201d, \u201cend-user\u201d, \u201cuat\u201d, \u201cstaging\u201d, etc. The cluster environment you provide when installing the Atomist Kubernetes utilities will be used when reporting on Kubernetes pod container activity in development lifecycle messages. For example, the following image shows the containers that are running a specific Docker image from a specific commit and build in various namespaces in the Kubernetes cluster environment \u201cgke-int-demo\u201d. The cluster environment is used by k8-automation and your software delivery machine (SDM) to coordinate application deployments and upgrades. Since you may be deploying k8-automation to multiple Kubernetes clusters, the cluster environment is used as part of the application deployment/update request to select the Kubernetes cluster.","title":"Cluster environment"},{"location":"user/kubernetes/#prerequisites","text":"Before you connect Atomist and your Kubernetes cluster(s), you need a few prerequisites.","title":"Prerequisites"},{"location":"user/kubernetes/#atomist-workspace","text":"You must have an Atomist workspace. If you do not already have one, you can create one following the instructions in the getting started documentation .","title":"Atomist workspace"},{"location":"user/kubernetes/#kubernetes-cluster","text":"You must have a Kubernetes cluster and access to that cluster as a user with either cluster-admin role privileges to run in cluster-wide mode or admin role privileges within a namespace to run in namespace-scoped mode. If you do not have access to a Kubernetes cluster, you can create one on your local system using minikube .","title":"Kubernetes cluster"},{"location":"user/kubernetes/#installation","text":"Several different methods for installing the Atomist Kubernetes utilities are supported. Choose the one that makes sense for your situation. If you aren\u2019t sure how to proceed, try the Atomist CLI approach as it is the easiest.","title":"Installation"},{"location":"user/kubernetes/#atomist-cli","text":"To use the Atomist CLI to install the Atomist Kubernetes utilities, you must have the Atomist CLI installed and configured . You will also need the Kubernetes kubectl command-line utility installed and configured to access your Kubernetes cluster with the needed privileges. Once you have the Atomist and Kubernetes CLIs installed and configured, you can install the Atomist Kubernetes utilities one the following commands. Be sure to replace CLUSTER_ENV with a meaningful name for you Kubernetes cluster/namespace and, if deploying in namespace-scoped mode, NAMESPACE with the existing namespace you want to deploy the utilities to.","title":"Atomist CLI"},{"location":"user/kubernetes/#cluster-wide-mode","text":"To install the Atomist Kubernetes utilities in cluster-wide mode, able to report on and manage resources in all namespaces, run the following command. atomist kube --environment=\"CLUSTER_ENV\"","title":"Cluster-wide mode"},{"location":"user/kubernetes/#namespace-scoped-mode","text":"To install the Atomist Kubernetes utilities in namespace-scoped mode, run the following command for each namespace you want to deploy them to. Replace NAMESPACE with the namespace you want to deploy the utilities to. atomist kube --namespace=\"NAMESPACE\" --environment=\"CLUSTER_ENV\"","title":"Namespace-scoped mode"},{"location":"user/kubernetes/#kubernetes-cli","text":"If you have the kubectl command-line utility installed and configured to access your Kubernetes cluster with the needed privileges, you can install the needed Atomist utilities with the proper configuration using the following commands. Be sure to replace CLUSTER_ENV with a meaningful name for you Kubernetes cluster/namespace, WORKSPACE_ID with your Atomist workspace ID, and API_KEY with a valid Atomist API key. See the developer prerequisites for more information on Atomist workspace IDs and API keys.","title":"Kubernetes CLI"},{"location":"user/kubernetes/#cluster-wide-mode_1","text":"","title":"Cluster-wide mode"},{"location":"user/kubernetes/#k8vent","text":"To deploy k8vent in cluster-wide mode and have it report on changes to all pod containers, run the following command. kubectl apply --filename=https://raw.githubusercontent.com/atomist/k8vent/master/kube/kubectl/cluster-wide.yaml kubectl create secret --namespace=k8vent generic k8vent --from-literal=environment=\"CLUSTER_ENV\" \\ --from-literal=webhooks=\"https://webhook.atomist.com/atomist/kube/teams/WORKSPACE_ID\"","title":"k8vent"},{"location":"user/kubernetes/#k8-automation","text":"To deploy k8-automation in cluster-wide mode with the ability to manage applications in all namespaces, run the following command. kubectl apply --filename=https://raw.githubusercontent.com/atomist/k8-automation/master/assets/kubectl/cluster-wide.yaml kubectl create secret --namespace=k8-automation generic automation \\ --from-literal=config=\"{\\\"workspaceIds\\\":[\\\"WORKSPACE_ID\\\"],\\\"apiKey\\\":\\\"API_KEY\\\",\\\"environment\\\":\\\"CLUSTER_ENV\\\"}\"","title":"k8-automation"},{"location":"user/kubernetes/#namespace-scoped-mode_1","text":"In the commands below, replace NAMESPACE with the namespace you want to deploy the utilities to.","title":"Namespace-scoped mode"},{"location":"user/kubernetes/#k8vent_1","text":"To deploy k8vent in namespace-scoped mode such that it will only report on pod containers in a single namespace, run the following commands. kubectl create secret --namespace=\"NAMESPACE\" generic k8vent \\ --from-literal=environment=\"CLUSTER_ENV\" \\ --from-literal=webhooks=\"https://webhook.atomist.com/atomist/kube/teams/WORKSPACE_ID\" kubectl apply --namespace=\"NAMESPACE\" \\ --filename=https://raw.githubusercontent.com/atomist/k8vent/master/kube/kubectl/namespace-scoped.yaml","title":"k8vent"},{"location":"user/kubernetes/#k8-automation_1","text":"To deploy k8-automation in namespace-scoped mode such that it will only deploy and update resources in a single Kubernetes cluster namespace, run the following commands. kubectl create secret --namespace=\"NAMESPACE\" generic automation \\ --from-literal=config=\"{\\\"workspaceIds\\\":[\\\"WORKSPACE_ID\\\"],\\\"apiKey\\\":\\\"API_KEY\\\",\\\"environment\\\":\\\"CLUSTER_ENV\\\",\\\"kubernetes\\\":{\\\"mode\\\":\\\"namespace\\\"}}\" kubectl apply --namespace=\"NAMESPACE\" \\ --filename=https://raw.githubusercontent.com/atomist/k8-automation/master/assets/kubectl/namespace-scoped.yaml","title":"k8-automation"},{"location":"user/kubernetes/#helm","text":"If you manage resources in your Kubernetes cluster with Helm , you can install the Atomist Kubernetes utilities using Helm. Replace API_KEY with an Atomist API key, WORKSPACE_ID with your Atomist workspace ID, and CLUSTER_ENV with a meaningful name for your Kubernetes cluster/namespace. Helm and Minikube Due to a bug in the default minikube bootstrapper localkube, kubernetes/helm#3135: Helm 2.7.0 creates RBAC resource fail , if you want to manage RBAC resources using Helm in minikube, you must start minikube using the kubeadm bootstrapper. minikube start --bootstrapper kubeadm You can make kubeadm your default bootstrapper by running the following command. minikube config set bootstrapper kubeadm","title":"Helm"},{"location":"user/kubernetes/#cluster-wide-mode_2","text":"To install all of the Atomist Kubernetes utilities in cluster-wide mode, run the following helm command. helm upgrade --install --namespace=atomist atomist-utilities \\ --repo=https://atomist.github.io/helm-charts atomist-utilities \\ --set=global.atomist.apiKey=\"API_KEY\" \\ --set=global.atomist.workspaceIds=\"{WORKSPACE_ID}\" \\ --set=global.atomist.environment=\"CLUSTER_ENV\"","title":"Cluster-wide mode"},{"location":"user/kubernetes/#namespace-scoped-mode_2","text":"To install all of the Atomist Kubernetes utilities in namespace-scoped mode, run the following helm command for each namespace you want to deploy them to. Replace NAMESPACE with the namespace you want to deploy the utilities to. helm upgrade --install --namespace=\"NAMESPACE\" \"atomist-utilities-NAMESPACE\" \\ --repo=https://atomist.github.io/helm-charts atomist-utilities \\ --set=global.atomist.apiKey=\"API_KEY\" \\ --set=global.atomist.workspaceIds=\"{WORKSPACE_ID}\" \\ --set=global.atomist.environment=\"CLUSTER_ENV\" \\ --set=global.atomist.mode=namespace","title":"Namespace-scoped mode"},{"location":"user/kubernetes/#updating","text":"You can update to a new version of the Atomist Kubernetes utilities using standard Kubernetes approaches. If you installed the Atomist utilities using the Atomist CLI or Helm, simply re-run the same command you ran to install them. If you are using kubectl you can run the following commands, replacing NAMESPACE and M.N.P as appropriate. kubectl set image --namespace=NAMESPACE \\ deployment/k8vent k8vent=atomist/k8vent:M.N.P kubectl set image --namespace=NAMESPACE \\ deployment/k8-automation k8-automation=atomist/k8-automation:M.N.P You can always find the latest versions of k8-automation and k8vent on their release pages.","title":"Updating"},{"location":"user/slack/","text":"Atomist has a powerful Slack integration to help your team access the power of ChatOps. Enroll Slack bot Click the \u201cAdd to Slack\u201d button below to invite the Atomist bot into your Slack workspace. Slack\u2019s default configuration allows all workspace members to add new Slack applications. However, your workspaces\u2019 admins may restrict the applications that can can be added in your workspace. The permissions management page has an \u201cApproved Apps\u201d setting to control this. If your workspace requires approval for new apps and you\u2019re not a Slack administrator, Slack helps you request approval from your Slack workspace\u2019 administrators to install the Atomist application. Currently the authorization process asks you to authorize two things: The Atomist app adds a bot user named \u201c@atomist\u201d to your workspace. Members can \\invite the Atomist bot to channels to access the full functionality of Atomist. Bot users cannot create channels, cannot join channels unless they are invited by a non-bot channel member, and cannot see messages in channels where they are not a member. Atomist requests a scope called \u201cModify public channels\u201d. This scope allows Atomist to help you setup channels. For example, when you create a project in a new repository, Atomist can create a Slack channel to go with it. Note The Atomist app creates new channels on behalf of the user who first authorizes Atomist. Removing Atomist from Slack You can remove the bot from all your channels instantly by revoking access to the \u201cAtomist\u201d application. We certainly hope it doesn\u2019t come to this! The App Manage page has a \u201cRemove App\u201d button at the bottom of the page. Please let us know if there\u2019s anything we can do to clarify how the bot works within your Slack workspace. Linking repositories & Slack channels Now that you you have Slack connected with Atomist, you should \u201clink\u201d your source code repositories with Slack channels so you can see and control your project\u2019s activity from Slack. All you need to do is invite the Atomist bot to a Slack channel and then send it repo . /invite @atomist @atomist repo The bot will open a thread and ask you what repository you want to link to the channel. If you added an organization webhook, you can link any repository in your organization. If you added webhooks to individual repositories, you will only be able to link those repositories. /** * Function that tracks a click on an outbound link in Analytics. * * We want to track clicks on 'Add to Slack' */ var trackOutboundLink = function(url) { ga('send', 'event', 'outbound', 'click', url, { 'transport': 'beacon', 'hitCallback': function(){document.location = url;} }); }","title":"Slack"},{"location":"user/slack/#enroll-slack-bot","text":"Click the \u201cAdd to Slack\u201d button below to invite the Atomist bot into your Slack workspace. Slack\u2019s default configuration allows all workspace members to add new Slack applications. However, your workspaces\u2019 admins may restrict the applications that can can be added in your workspace. The permissions management page has an \u201cApproved Apps\u201d setting to control this. If your workspace requires approval for new apps and you\u2019re not a Slack administrator, Slack helps you request approval from your Slack workspace\u2019 administrators to install the Atomist application. Currently the authorization process asks you to authorize two things: The Atomist app adds a bot user named \u201c@atomist\u201d to your workspace. Members can \\invite the Atomist bot to channels to access the full functionality of Atomist. Bot users cannot create channels, cannot join channels unless they are invited by a non-bot channel member, and cannot see messages in channels where they are not a member. Atomist requests a scope called \u201cModify public channels\u201d. This scope allows Atomist to help you setup channels. For example, when you create a project in a new repository, Atomist can create a Slack channel to go with it. Note The Atomist app creates new channels on behalf of the user who first authorizes Atomist.","title":"Enroll Slack bot"},{"location":"user/slack/#removing-atomist-from-slack","text":"You can remove the bot from all your channels instantly by revoking access to the \u201cAtomist\u201d application. We certainly hope it doesn\u2019t come to this! The App Manage page has a \u201cRemove App\u201d button at the bottom of the page. Please let us know if there\u2019s anything we can do to clarify how the bot works within your Slack workspace.","title":"Removing Atomist from Slack"},{"location":"user/slack/#linking-repositories-slack-channels","text":"Now that you you have Slack connected with Atomist, you should \u201clink\u201d your source code repositories with Slack channels so you can see and control your project\u2019s activity from Slack. All you need to do is invite the Atomist bot to a Slack channel and then send it repo . /invite @atomist @atomist repo The bot will open a thread and ask you what repository you want to link to the channel. If you added an organization webhook, you can link any repository in your organization. If you added webhooks to individual repositories, you will only be able to link those repositories. /** * Function that tracks a click on an outbound link in Analytics. * * We want to track clicks on 'Add to Slack' */ var trackOutboundLink = function(url) { ga('send', 'event', 'outbound', 'click', url, { 'transport': 'beacon', 'hitCallback': function(){document.location = url;} }); }","title":"Linking repositories &amp; Slack channels"},{"location":"user/spring/","text":"Section content not yet populated Sorry, we haven\u2019t written this part of the documentation yet. Will you tell us what questions are important to you? We\u2019re happy to help in the #support channel in Atomist community Slack . You can also contribute to this guide with an issue or pull request on the docs repository .","title":"Spring"}]}